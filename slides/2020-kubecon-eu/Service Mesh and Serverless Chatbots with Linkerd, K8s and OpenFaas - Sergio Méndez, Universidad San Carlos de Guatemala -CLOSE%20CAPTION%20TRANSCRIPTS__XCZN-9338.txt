Service Mesh and Serverless Chatbots with Linkerd, K8s and OpenFaas: XCZN-9338 - events@cncf.io - Thursday, August 20, 2020 11:58 AM - 152 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:01:41 [W] Hi, welcome to the cubic calling you on clown Eddie calm 2020.
00:08:16 [W] So let's get start.
00:08:19 [W] So the title of this session is servicemeshcon serverless chatbots with linkerd eks and open fast. I am Sergio Mendes.
00:08:25 [W] About me I an operating system Professor.
00:08:32 [W] I am tripping or die have a parade called Cloud Society.
00:08:35 [W] So it's about join open source communities and that kind of things.
00:08:43 [W] So I am a clown ATM to see us. I am working as a SRE a twice line.
00:08:48 [W] I am meeting organizer of a clown Eddie + GT and it's really awesome to share clown native Technologies with the people. So let's get
00:08:56 [W] The it infrastructure and evolution. So there are several steps in the evolution of the Technologies or maybe the different steps that you are juicing to deploy your application. So for
00:09:11 [W] Sad that you are juicing to deploy your application. So for example, maybe you are deploying an application in and monolithic architecture.
00:09:20 [W] So you suppose that you are juicing a house.
00:09:29 [W] So you are close to the bare metal and you are installing like a kind of hyper visor down you are deploying your application in a built on machine.
00:09:34 [W] So maybe you has maybe you have some control in all
00:09:37 [W] talking about of the operating system. So maybe you are just in containers. So that containers doesn't do somehow hypervisor that is associated with that kind of virtualization in the bare metal.
00:09:51 [W] Home, maybe you are packaging or the logic of your application inside that container. So you don't you have less control in difference with the monolithic architecture because you are maybe two playing
00:10:07 [W] Container art you are only have that control in the container.
00:10:19 [W] So in the serverless, you don't have control about the host John Lee deploying a small part of code, and that's it.
00:10:22 [W] So there's no server there.
00:10:29 [W] So in the basic concepts first the clown knative so clown native is taking approach to building applications using that cloud computing models of do you are paying for that services in the cloud so
00:10:36 [W] Concept about Cloud native. So in that cloud computing model.
00:10:45 [W] Do you are juicing containers, maybe microservices or servicemeshcon taking advantage of that cloud computing model.
00:10:58 [W] So that's essentially the clown knative thing and I can mention the clown native apps that uses the 12 factor to to build their applications old.
00:11:02 [W] Serverless, we'll do our tekton approach of software solution that you are deploying only the small part of the function at you are running in some transient servers of grpc n what you juice in that moment.
00:11:20 [W] So in that environment could be very elastic so you don't have to operate or to pay attention to the Cerberus but because of the concept that don't have servers so
00:11:32 [W] Serverless has a high level of abstraction of the service of generally deployed that small part of the code so you don't have to worry about the service anymore.
00:11:47 [W] So that's the really cool thing about serverless.
00:11:49 [W] So serverless provides you some features for example, the even driven things. So the serverless start when you are receiving
00:12:02 [W] Blood confirms some when you are receiving that request the service turned off after the few minutes that service die. So only lips during the time of the request so
00:12:18 [W] With die, so only leaves during the time of the request so provides you some kind of streaming data and our scaling kind of service and fault tolerance.
00:12:27 [W] So the good things and the bad things are the good things are cheaper.
00:12:35 [W] It's cheaper than traditional cloud services is a scalable you read those will reduce the obstacles you are focusing morning. They just experienced am depth. So
00:12:43 [W] So in the but there's a bender looking thing because you have to adapt adapt your logic orders over to them serverless service that your cloud provider gives you. So there is a learning
00:12:57 [W] There's Stan how your Cloud provide their employment serverless.
00:13:10 [W] There's not suitable for long-term task because that serverless functions only lives for a short time.
00:13:15 [W] So depending on your provider maybe don't support the language that you want to create your serverless Venture.
00:13:25 [W] So about controlling the system. You don't have more control.
00:13:27 [W] Roll or well, you have less control on that on that infrastructure.
00:13:42 [W] So you don't have access to the server. So that kind of thing so do our own little I need your code in that platform. So you can use serverless in the in Internet of Things of to create
00:13:49 [W] Assistance or for IP is some kind of streaming Zone parlament service for image manipulation or even processing or multi-language applications or to implement some kind of ci/cd depending on the case.
00:14:04 [W] What is servicemeshcon soul servicemeshcon Lee is like a kind of service build that lips in the service area. So lips like a site container of beside card together with just
00:14:20 [W] Area so lips like a side container of beside card together with just service. So this side card with you're looking here this your pre multiplication and decide cards of the
00:14:28 [W] Side guard when you are looking here this your Prima application and decide cards of the sidecut receives all the traffic as a proxies of that side side cards perform us as a proxy. So
00:14:37 [W] Reside all the traffic and decide what to do with that traffic to forward to the original application of drop the traffic. So in this graph, you can see for example in the kubernative content context support could have
00:14:52 [W] And containers one container is the servicemeshcon resides the traffic and forward to to um, the original microservices. So the servicemeshcon has two components the data plane and the control
00:15:08 [W] So it's really awesome.
00:15:24 [W] So in the data plane is leaving your application. So the green squared could represent your original container allowed the the blue squared could represent the sidecar or the proxy element of the sidecar that receives
00:15:26 [W] when they receive the traffic forward or asked to the control plane what to do with that traffic or generates metrics and apply some policy and show that information in the UI so
00:15:43 [W] Show that information in the UI so linkerd e is an ultra-light servicemeshcon.
00:15:49 [W] So it's really really easy to use to implementing kubernative.
00:15:59 [W] So gives you that kind of observability reliability or Implement that security between your different microservices without coaching. So this really awesome.
00:16:06 [W] So has the same architecture the when we
00:16:08 [W] Are talking to the basic concepts of the implementation of servicemeshcon.
00:16:15 [W] So has some control plane and data planes so has different components for example implemented tap Identity or maybe somebody Gators just an API so you can access that API with the CLI has
00:16:27 [W] To show the graphics are maybe a recording some metrics infirmities and showing the graphs using graph Anna and in the data plane is your original application with that linkerd haproxy or the psyche card.
00:16:43 [W] Soups the traffic and that throw is to the control pain to decide what to do with that traffic.
00:16:53 [W] So what linkerd id Uso linkerd eme gives you that observability and reliability and security thing.
00:17:04 [W] So with the observability gives you that power to generate gold and metrics like success rates latency through output and showed you in the in the panel that service dependencies or topologies to implement that kind of
00:17:13 [W] A mouse or soup with breaking when you are traffic splitting or that kind of things Diplomatic Security and secured the communication between your containers using TLS and that kind of thing.
00:17:29 [W] So why should you like cared about who can do servicemeshcon school be used by see SRS and Architects because they Implement observability and some security Primitives
00:17:41 [W] Very critical to Cloud native applications of architectures and the funny part is that you don't have to modify your application to get that benefit. So that's the really cool thing about linkerd e so open fast isn't
00:17:57 [W] and if it's so that's the really cool thing about linkerd e so open fast is an open-source serverless platform that we can mention about open fancies that keeps you that platform to implement services servicemeshcon
00:18:07 [W] You that platform to implement services servicemeshcon to create that even driven function. So so these functions are created as a microservices packages with Docker
00:18:18 [W] Giver natives but there are different versions how you can deploy up and fast, for example, there is a version that you don't use kubernative only containerd e there's another version that you can deploy open fast
00:18:33 [W] Leah's fire gate non-open fast provide you that after scaling and metrics for this juror serverless function without limits of execution like lambdas on that kind of thing. So the features are
00:18:49 [W] openfaas provides you that that ECU iportal to package the food your functions to provide you portability to move your functions provide you a CLI to manage that functions and some jumped on coffee for
00:19:06 [W] Some options in your functions and provide you that outer scale in front 0 to like Land.
00:19:15 [W] Mm. Oh, it depends how you configured your function. So there is some reference architectures about openfaas o open files internally juice a lot of so, we're there. For example Nats to create that some cues permit you to
00:19:30 [W] Riggs to showing through graph on and different components so it's really awesome.
00:19:37 [W] So in a serverless real use cases in area I can mention that in my past job and Telco company.
00:19:47 [W] We were creating chatbots tools of this tool was the mission of this tool was to create custom chatbots and they are executing using slack telegram WhatsApp or Facebook.
00:20:01 [W] So right now I am trying to remain sober observability on soft Canary ployment stew that chatbots. Oh
00:20:07 [W] And this Telco company and their requirements of their application is to prevent the brand-new locking. So they agreed to use open source Technologies to implement some fast integration about these Technologies the short time of development time
00:20:23 [W] Devops and ci/cd to spend less money and smart great could be the performance there is silence system and observability.
00:20:39 [W] So this over like linkerd e an open-faced provide these things so essentially the solution has opened fast that serverless open source platform linkerd e 2 masses servicemeshcon Clemente observability and the canary or
00:20:48 [W] That serverless open source platform linkerd e the masses servicemeshcon Clemente observability and the canary or blue-green deployments and kubernative to orchestrate the different containers created by open fast and scale
00:20:56 [W] Narrated by open fast and scale provide that data scaling thing in the system. So about this is like I'm in kind of execution diagram know how the chatbots
00:21:07 [W] All I can mention the artificial intelligence theory about agents. So when we are talking about agents dajun interacts with an environment so has some perceptions of
00:21:23 [W] Interacts with an environment so has some perceptions of the environment capturing by that sensors and this agent decide what to do with that perceptions to action to the environment.
00:21:35 [W] So it does that actions with the factors.
00:21:47 [W] So the things that provides that perception in the environment that are the instant Messengers all the chats all the text and that kind of things that I received the agent.
00:21:49 [W] They're foreigners a container the playing kubernative deploying using open fast and linkerd you recollect some metrics and do that traffic splitting for the application.
00:22:03 [W] Some is really awesome in that way.
00:22:07 [W] So to be in context a canary on blog redeployment.
00:22:09 [W] So the blue-green employment you are deploying that basically to version at the same time. So you are splitting the traffic between version a and division beam.
00:22:18 [W] And the canary employment you are gradually shifting traffic between a version A and B for some service.
00:22:27 [W] So in the architecture of the demo so I can Implement so blue the blue green deployment of canary plane went with 50 and 50 percent of the traffic for each service.
00:22:42 [W] So to implement this you have to use a dummy function called root.
00:22:49 [W] Is it really awesome in that way?
00:22:54 [W] So to be in context a canary on blue-gray deployment. So the book Reemployment you are deploying basically to version at the same time.
00:22:56 [W] So you are splitting the traffic between version a and division beef and the canary employment.
00:22:56 [W] You are gradually shifting traffic between a version A and B for some service. So in the architecture of the demo so I can Implement so
00:23:00 [W] And blue the blue green deployment of canary ployment free with 50 and 50 percent of the traffic for each service.
00:23:04 [W] So to implement this you have to use a dummy function called root.
00:23:04 [W] So I in this demo I call it chatbots route and the chatbots ring and the chatbots blue, but it's the same logic
00:23:05 [W] The benefits of the solution is that this 0 Bender locking there's a fast integration with Technologies. You are using technology that gives you that ability to provide that ci/cd platform and you are spending less money
00:23:13 [W] the same logic
00:23:13 [W] the benefits of the solution is that this 0 Bender locking there is a fast integration with Technologies. You are using technology that gives you that ability to provide that ci/cd platform and you are spending less money
00:23:15 [W] Asian using open source of JuJu don't expect some Bender locking.
00:23:28 [W] It's very silent and Implement observability without modified your application.
00:23:36 [W] So the demo shows Claudia and select chatbots that is living in my slack meet up. So I'm going to show you the templates of open fast to create functions some Integrations and functionality of linkerd E.
00:23:43 [W] Can I redeployment? So Bluegreen deployments to show you how linkerd e works and they observability thing of linkerd e so here is a repository that I gonna deploy this demo. So you want to check it, so it's really
00:23:59 [W] So let's start with the demo. So in this part, I can show you the linkerd E the link at the dashboard.
00:24:16 [W] I supposed I have configured like the cube CTL to connect to the cluster.
00:24:22 [W] So now here is the linkerd E dashboard is really really really cool. So in this next place of kubernative, the open fast offend is publish all my functions, so
00:24:29 [W] So you can expect to find the chatbots Greenlee like say that the blue green and the chatbots is the dummy service this blue and green service called the microservices you every time
00:24:44 [W] So you can expect to find the chatbots ring like say that the blue green and the chatbots.
00:24:45 [W] that is a dummy service this blue and green service called The microservices Who every time when that I wrote when I write cubic on you in the chatbots O called the
00:24:51 [W] Road will nag right and cubic on you in the chatbots O called the microservices and I am doing a traffic splitting between these services.
00:24:58 [W] So let's get right in the chatbots.
00:25:01 [W] for example cubic on you.
00:25:03 [W] This cubic on you again.
00:25:08 [W] This is cubic on you, or maybe hi. So maybe you are seeing like there is passing the traffic like more or less 50 and 15.
00:25:22 [W] This is the blue chatbots and degree chatbots.
00:25:36 [W] And this is the idea of the container that is executing this logic. So there is all turning the request between 50 and 50. So let's generate more traffic that calls my
00:25:39 [W] Microsoft service service. So let's reload this part of the panel so you can I can show you the dependency of of the different service. So chatbots crinkles microservices every time
00:25:54 [W] And keep it going to you and they blew those the same so I can show you the traffic split for this thing.
00:26:07 [W] So in real time, I want are you gonna try to show you if they change for example?
00:26:12 [W] or hello cubic on you there is changing in that time. So it's really awesome is Charron changing so high?
00:26:24 [W] Yeah, so it's changing in real time.
00:26:30 [W] So let me show you another thing. For example this blue this calling microservices.
00:26:39 [W] So the blue calls microservices. Let me try and so cubic on you.
00:26:43 [W] So cubic Kang you again?
00:26:47 [W] So maybe Cubed come you.
00:26:59 [W] Yeah, this right now is changing so he would come you.
00:27:01 [W] So let me again Q account you.
00:27:09 [W] So in the same time well delay.
00:27:16 [W] Real time.
00:27:29 [W] how is deploying the different things so I want to show you the graph.
00:27:33 [W] fauna the Griffon dashboard. So here is the graph on a dashboard and shows you some information about the different micro service and information that is recollecting.
00:27:47 [W] So, it's pretty pretty awesome. So here is the open fast portal so
00:27:54 [W] So in this portal well talking about open files.
00:28:02 [W] I can see my different serverless functions and their URL to access that function. For example, here's an example or function that Returns the information of the host
00:28:13 [W] Well talking about open first.
00:28:14 [W] I can see my different serverless functions and their URL to access that function. For example, here's an example or function that Returns the information of the host
00:28:15 [W] Really really nice.
00:28:18 [W] They are counting.
00:28:21 [W] How many times do you are requesting this dysfunction and you can deploy new function functions here that you can you can also delete the function and that kind of things.
00:28:35 [W] I want to show you more or less than the code the code of well, let me access to This Server here to show you more or less the structure of this function. So here
00:28:50 [W] More let me check this.
00:28:54 [W] so
00:28:57 [W] in this directory, I can show you the different parts of this for example in the stack.
00:29:12 [W] There is the get way that we are accessing.
00:29:15 [W] This is this this portal is a get way.
00:29:27 [W] So the image that we are juicing they match that we are publishing in the docker Hub. So, let's see that different templates. So for example,
00:29:31 [W] well, here it is them bites and three flasks and
00:29:36 [W] templates so essentially gives you a Docker Docker file that you can modify the template and in the index function with example of how to execute that
00:29:52 [W] Shelly's container that is executed like serverless function. So it's really awesome and tufin allies.
00:30:08 [W] Here's a repository in is not the final repository of final repositories the URL that I've been showing in the presentation.
00:30:16 [W] So here the open fast has some CLI, for example here you download the template and you are creating the project to create your serverless.
00:30:23 [W] Functions in this part you are deploying your serverless function with the fast CLI. So here's the chatbots green blue and root here are
00:30:38 [W] See that we are injecting the sidecar to the original function. So essentially you are getting the jam of of that deployment that you are adding some
00:30:54 [W] Another container has a sidecar.
00:31:02 [W] So essentially the service has really played an assertive with outside card inside.
00:31:08 [W] So to implement the traffic splitting is very easy like this. For example, this file you can see that they match this service and and you can describe
00:31:18 [W] come many traffic goes through every service for example, 50 and 50 and that's a great that is very easy to implement the open source serverless functions
00:31:34 [W] Ability you sound linkerd e on us, so that's it.
00:31:41 [W] That's the demo.
00:31:45 [W] So just to continue.
00:31:49 [W] Well I have here. I have some references that you can visit and the repo so you can follow me in the social networks with Sergio
00:32:00 [W] L you can find me on LinkedIn Twitter and that kind of social networks, and thanks, so I think that we pass to the questions and thank you very much.
00:32:13 [W] ks.
00:32:14 [W] Welcome.
00:32:23 [W] Well this time to questions if you have any question, I can ask where right now you have a box in the left in the QA section. So if you ever have questions about the application of linkerd e using chatbots
00:32:34 [W] Right. Now you have a box in the left in the QA section. So if you ever have questions about the application of linkerd e using chatbots or how to create chatbots with open
00:32:39 [W] Rate chatbots with open fast.
00:32:45 [W] You can write me the question and I am here right now for resolved your old your dubs and that things well, there is a
00:32:52 [W] Our repository on GitHub you can find that as Sergio Aram GPL you can find dared my my repository.
00:33:11 [W] I think that I can't write my username here in the chat. So
00:33:14 [W] and if you have questions
00:33:18 [W] I will also be at the slack at the channel of cubic and 2 - cubic on - servicemeshcon.
00:33:34 [W] If you can has asked something later.
00:33:39 [W] Or if you have questions about the Repository.
00:33:46 [W] so
00:34:02 [W] servicemeshcon
00:34:10 [W] if you can has asked something later.
00:34:11 [W] Or if you have questions about the Repository.
00:34:13 [W] so
00:34:16 [W] well
00:34:49 [W] Oh, there's a question say it's hi Sergio when I can't get a beginner examples of linkerd e well for the beginner examples of linkerd in my repository.
00:35:15 [W] I have some basic examples of how to apply linkerd E.
00:35:23 [W] I also have their some repositories about observability.
00:35:27 [W] So I think that is very beginner beginner kind of
00:35:28 [W] p**** Tory you can check that repository there.
00:35:34 [W] Oh, there is a question say it's hi Sergio when I can't get a beginner examples of linkerd e well for a beginner examples of linkerd in my repository.
00:35:41 [W] I have some basic examples of how to apply linkerd E.
00:35:42 [W] I also have their some repositories about observability.
00:35:43 [W] So I think that is very beginner beginner kind of Repository.
00:35:43 [W] Read you can check that repository there.
00:35:45 [W] I want answered their land to all the people here.
00:35:46 [W] You can find me at Sergio your REM D PL at GitHub and there are a lot of public repositories so you can find that repository as cubic on you 2020 - linkerd e -
00:35:52 [W] Aram DPL at GitHub and there are a lot of public repositories so you can find that repository as cubic on you 2020 - linkerd e bash up fast.
00:35:55 [W] That's the name of rare the Repository.
00:35:57 [W] So I know that observability themes and servicemeshcon ings are the little bit could be confusing or complex or relative Like A New Concept. So
00:36:12 [W] With our really beginner examples in my Repository.
00:36:23 [W] You can also check the linkerd E site. There are a very beginner examples of running in my repository. You can find a very basic example of how to create a chatbots.
00:36:32 [W] Because it's very popular art. I think that it will work for you. If you can use that example to create a chatbots slack.
00:36:47 [W] So well in the in this light you can find to their world has lights are the inside the Repository.
00:36:54 [W] So I trying to add some Theory a Bluegreen repository and you can read slowly get that concept.
00:37:02 [W] steps and play with that so
00:37:05 [W] I don't know if if you have another question how to applicate that.
00:37:17 [W] Well, the cool thing about linkerd e is that is very easy to use and that's my reason to to just sell linkerd e maybe linkerd ich will be your first step to to play with a servicemeshcon.
00:37:33 [W] And then maybe you can try another servicemeshcon like instill that kind of thing and you can also play with Machinery Machinery is another tool to install servicemeshcon really easy way.
00:37:51 [W] Let me find if there is another question.
00:38:27 [W] Well, well, well, here's another question says skill are healed.
00:38:43 [W] Hi.
00:38:44 [W] Thanks for Telco.
00:38:44 [W] Thank you very much.
00:38:47 [W] So have you worker with the Connelly Bluegreen releases with a websocket based chatbots latter form work?
00:38:54 [W] and servicemeshcon
00:39:33 [W] old skip on own boat and in bone parts, so we'll linkerd it. You have to use that options when you are injecting your pot.
00:39:47 [W] So you have to pay attention to that because maybe well maybe you are using idea RTP or websocket Library.
00:39:58 [W] You have to open that board and play with that to don't lose the connections. So you have to pay attention to that when you are
00:40:04 [W] Using a servicemeshcon general because it performs us a fire will Mark not not really as a fire will bore blocks. Your connection said you have to do some exceptions.
00:40:17 [W] Find something similar with another servicemeshcon.
00:40:38 [W] I don't know if you have another question.
00:41:51 [W] The linkerd E.
00:42:03 [W] Anynines luck, so you can't go to the linkerd E website join us at slack.
00:42:13 [W] I am like the small contributor is speaking and sharing this technology.
00:42:23 [W] So if you have another questions or maybe something more technically to implement your architecture where we we can help you in the linkerd E. The linkerd E aslak you can find
00:42:29 [W] That in the linkerd E dot IO.
00:42:32 [W] Okay, so if there is no more questions, I think we've got 900. Let me check out.
00:43:28 [W] Thank you Taylor Carpenter.
00:43:31 [W] So tufin a like I can invite you to join us at the linkerd E community.
00:43:35 [W] Open fast.
00:43:45 [W] These are really awesome Community to you can't contribute to create some templates to resolve song and other problems with architectures and join open fast.
00:43:49 [W] Nickname and in all the social networks, so thank you very much for this and for my first time here that speaking Us in the cubicle.
00:44:11 [W] So, thank you very much.
00:44:12 [W] Goodbye people.
