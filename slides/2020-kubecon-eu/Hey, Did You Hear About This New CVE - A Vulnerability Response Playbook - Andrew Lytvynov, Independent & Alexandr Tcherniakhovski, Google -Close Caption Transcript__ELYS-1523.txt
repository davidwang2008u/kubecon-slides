Hey, Did You Hear About This New CVE? - A Vulnerability Response Playbook: ELYS-1523 - events@cncf.io - Tuesday, August 18, 2020 12:18 PM - 60 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:07:20 [W] Hello and welcome to our talk. My name is Alex. Show me whole ski, and I will be co-presenting today with Andrew luck be enough.
00:07:29 [W] For a number of years Andrew and I have worked together on Jackie security team.
00:07:37 [W] I'm still on that team and Andrew recently joined gravitational.
00:07:38 [W] As part of our own called duties Andrew and I mitigating multiple security incidents and we believe that we have learned something from that experience and would like to share it with you today.
00:07:50 [W] But before we start will fly to Tokyo a few years back.
00:07:54 [W] In 1935 Boeing model 299 could fly faster cover longer distances and carry more weight than its competitors.
00:08:06 [W] Therefore the fly competition where the winner would be awarded a defense contract was supposed to be just a formality.
00:08:18 [W] However model 299 crashed during the lat during the demo flight.
00:08:20 [W] Hello and welcome to our talk. My name is Alex. Show me whole ski, and I will be co-presenting today with Andrew luck be enough.
00:12:04 [W] For a number of years Andrew and I have worked together on Jackie security team.
00:12:12 [W] I'm still on the team and Andrew recently joined gravitational.
00:12:14 [W] As part of our own called duties Andrew and I mitigating multiple security incidents and we believe that we have learned something from that experience and would like to share it with you today.
00:12:25 [W] But before we start we'll fly to Tokyo a few years back.
00:12:30 [W] In 1935 Boeing model 299 could fly faster cover longer distances and carry more weight than his competitors.
00:12:42 [W] Therefore the fly competition where the winner would be awarded a defense contract was supposed to be just a formality.
00:12:50 [W] However, model 299 crashed during the lat during the demo flight.
00:12:55 [W] The investigation showed that the crash was due to the pilot error.
00:13:00 [W] This is despite the fact that the pilot major property Hill was one of the most experienced test pilots in the US Europe Air Force at that time.
00:13:09 [W] Hello and welcome to our talk. My name is Alice. Show me a house key and I will be co-presenting today with Andrew little enough.
00:13:22 [W] For a number of years Andrew and I have worked together on Jackie security team.
00:13:23 [W] I'm still on that team and Andrew recently joined gravitational.
00:13:24 [W] As part of our own called duties Andrew and I mitigating multiple security incidents and we believe that we have learned something from that experience and would like to share it with you today.
00:13:26 [W] But before we start will fly to Tokyo a few years back.
00:13:29 [W] In 1935 Boeing model 299 could fly faster cover longer distances and carry more weight than his competitors.
00:13:30 [W] Therefore the fly competition where the winner would be awarded a defense contract was supposed to be just a formality. However model 299 crashed during the delay during the demo flight.
00:13:33 [W] The investigation showed that the crash was due to the pilot error.
00:13:35 [W] This is despite the fact that the pilot major property Hill was one of the most experienced test pilots in the US Europe Air Force at that time for the more than vestigation concluded that the plane was substantially more complex than the previous models.
00:13:37 [W] Boeing did not get the contract.
00:13:38 [W] And almost went bankrupt as the result.
00:13:38 [W] Nevertheless several test pilots were convinced that the plane could be flown safely and proceeded with further investigation and testing.
00:13:39 [W] The result of their investigation was an incredible piece of technology if Li checklist.
00:13:44 [W] In the end checklist allowed model 299 to fly 2.9 Million kilometers without one incident.
00:13:53 [W] Fast forward to Apollo 12 lunar landing and we see the checklist has become a norm in the aviation and space exploration Industries.
00:14:04 [W] Furthermore the value of checklists is now well understood in fields other than a variation.
00:14:10 [W] The Who surgical safety checklist which contains 19 items has shown significant reduction in mortality and is now used by my by majority of surgical providers around the world
00:14:24 [W] So what a checklist have to do was preparing for a security incident.
00:14:30 [W] Gigi security most frequently engaged in mitigating kubernative honor abilities
00:14:36 [W] What we have learned from this experience is that even despite having access to highly skilled engineers and good tooling.
00:14:46 [W] We almost always feel like women is something very basic.
00:14:48 [W] This is when we thought about creating checklists.
00:14:50 [W] Note that we don't want to trivialize the process by definition vulnerabilities are unpredictable and complex does no checklist will replace the need for deep technical expertise in creativity typically required during the
00:15:06 [W] Typically required during the mitigation process.
00:15:07 [W] Please note that in the context of this talk.
00:15:14 [W] We consider the discovery of a vulnerability within any of our production components to be a security incident.
00:15:19 [W] Other security teams may only declare security incidents only after some evidence of an active attack has been produced.
00:15:28 [W] Before sharing some of the pre-incident checklist that we created would like to point out some of the challenges involved in handling incidents and kubenetes.
00:15:38 [W] Fundamentally kubenetes is a distributed system, which implies that a successful attacker will most likely need to Traverse through several Arenas of your infrastructure to reach the ultimate goal, which we assumed to be users data.
00:15:54 [W] Therefore the task of investigating an incident could in many cases be reduced to correlating logs on multiple systems.
00:16:02 [W] The stressing attackers path from exploiting the initial vulnerability to their ultimate Target.
00:16:09 [W] However, as you can see from this list, we have many challenges ahead of us.
00:16:14 [W] We are about to present for pre-incident checklist that we believe will simplify the task of assessing your Readiness as you can see that each checklist corresponds to a layer within kubenetes infrastructure.
00:16:28 [W] Reduced to correlating logs on multiple systems.
00:16:37 [W] The stressing attackers path from exploiting the initial vulnerability to the ultimate Target.
00:16:39 [W] However, as you can see from this list, we have many challenges ahead of us.
00:16:39 [W] We are about to present for pre-incident checklist that we believe will simplify the task of assessing your Readiness as you can see that each checklist corresponds to a layer within kubernative infrastructure.
00:16:42 [W] As we go through this checklist, they will most likely appear to you as some general hardening guidance, but you probably already heard before and indeed. The best strategy for preparing for an incident is to reduce the chances of it happening in the first place
00:16:46 [W] before and indeed, the best strategy for preparing for an incident is to reduce the chances of it happening in the first place and hardening of kubernative infrastructure is the best approach for accomplishing this
00:16:51 [W] In the context of hardening you may have heard about kubernative c as Benchmark, which is in fact a checklist that is designed to assess the overall security posture of your kubernative environment.
00:17:05 [W] In GTE we take say as results very seriously in strive to get to 100% compliance.
00:17:16 [W] So if you are already using say as Benchmark, then that is great.
00:17:18 [W] You already taking advantage of the checklist mentality.
00:17:21 [W] In this talk will take a slightly different view on hardening.
00:17:29 [W] We will Zero in on the configuration settings of kubernative that we believe not only will reduce the chances of a compromise, but are also particularly valuable in generating signals indicative of an attack.
00:17:41 [W] In other words, the checklist that will offer once implemented are meant to force attackers to generate signals, which we could detect and react accordingly.
00:17:53 [W] The last thing that you want to learn when mitigating an incident is that the vulnerable service had sensitive Cube API permissions which which it actually did not need essentially. This is a gift to attackers
00:18:09 [W] For you critical services and ensure that they're assigned the minimum set of permissions required.
00:18:17 [W] How do you do that though?
00:18:19 [W] Well one way to find this out is to enable qpi server or the Vlog and observe. The request that you service is making under normal conditions.
00:18:28 [W] We also need to ensure that access to sensitive resources like Secrets is audited for both successful and failed attempts.
00:18:38 [W] Remember attackers may not know if the compromise component has the permissions for this sensitive resources.
00:18:48 [W] However, they will most likely try accessing them anyway, and this is our opportunity for detection.
00:18:52 [W] Luckily attackers can control which component of a service is exposed to vulnerability.
00:19:03 [W] Therefore most likely they will need to Pivot from a vulnerable component which may not be of any direct interest to them that their ultimate Target in this act of letter of traversal attackers will attempt to establish network connections to the surrounding
00:19:14 [W] And this is again our opportunity for detection.
00:19:18 [W] If we know that components X and Y within a service and not supposed to talk to each other then such connection attempts are strong signals of an ongoing incident.
00:19:30 [W] However to collect such signals we need to have thorough understanding of the expected Network patterns within our services.
00:19:37 [W] The second check on the list is very much related to the first one and assumes that we can recognize drug Network requests.
00:19:46 [W] However, we still need to make sure that we are collecting exporting and retaining such Network logs.
00:19:52 [W] Note that raw log records may not be sufficient.
00:20:03 [W] I remember that kubernative Xin kubenetes internal IP addresses are not guaranteed to persist there for additional metadata me need to be attached to the to the network records.
00:20:11 [W] For example, attaching a pot name will definitely be more helpful than just looking at some random IP address.
00:20:16 [W] Kubernative Network policies is the mechanism that allows us to produce Ash logs.
00:20:26 [W] Further on never policy. We are the logging mode could be also used to produce a network flow diagrams for your services.
00:20:33 [W] One more thing for the network checklist, make sure not to enable host network setting in the pots back unless you have very strong reasons to do. So, we noticed that this setting is often used to simplify internal Communications.
00:21:04 [W] However, in addition to removing the protection afforded by the network space isolation the setting also makes Network log analysis much harder because Source addresses of all components that are running in host network name space will be
00:21:20 [W] that of the host
00:21:22 [W] thus making it more difficult to detect Rogue network connections.
00:21:27 [W] Running containers is root, which is unfortunate that the default is rarely necessary for the more such containers are more susceptible to escape attacks.
00:21:41 [W] You probably already knew that.
00:21:47 [W] However, what we also learned is that this default also makes it harder to examine OS audit logs at the end of the day containers are still processes and when they all run as the same root user it makes it more difficult to audit them.
00:21:56 [W] Regarding Linux capabilities. Our experience has shown that the capabilities included in the default Docker profile are too permissive.
00:22:07 [W] This default profile contains many capabilities that are not required by most applications.
00:22:12 [W] However containers keep a tax May utilize this default capabilities to their advantage.
00:22:18 [W] Hence, we recommend dropping them unless you application has some very specific requirements from the incident preparedness point of view when containers are running without these default capabilities.
00:22:34 [W] We expect that continue Escape attacks will generate access denied errors, which will be recorded by the Linux or the subsystem this works to our advantage.
00:22:43 [W] However, container skip attacks May utilize this default capabilities to their advantage.
00:22:50 [W] Hence, we recommend dropping them unless you application has some very specific requirements.
00:22:51 [W] From the incident preparedness point of view when containers are running without these default capabilities.
00:22:52 [W] We expect that continue Escape attacks will generate access denied errors, which will be recorded by the Linux or the subsystem this works to our advantage.
00:22:54 [W] Allow privilege escalation is related to Linux capabilities when enabled it guarantees that the Linux kernel will not Grant any additional capabilities to the process once it is started.
00:22:57 [W] I'm personally a bit conflicted about the setting on one hand.
00:23:04 [W] This is a great way to ensure that your application even under the corrosion of an attacker will not expand.
00:23:09 [W] It says it set of privileges.
00:23:10 [W] However, on the other hand security-conscious developers may follow the principle of just in time capabilities and programmatically request and drop capabilities from the colonel. This is how creators of the capabilities Envision them being used.
00:23:27 [W] Unfortunately this setting brace such security-conscious applications.
00:23:32 [W] However in practice such capability aware applications on rare and therefore it is probably safe to enable this setting on most applications.
00:23:42 [W] Building Docker images on top of distress or scratch is the well-established security practice since it reduces the attack surface of our containers.
00:23:53 [W] Furthermore destroys containers make it more difficult for attackers to perform lateral traversal via exacting into the surrounding containers.
00:24:02 [W] Distance containers also remove the need of solving a tricky problem of having to log all commands executed within our production containers.
00:24:16 [W] Having a tricky problem of having to log all commands executed within our production containers. Let me explain this point.
00:24:21 [W] We know that attackers would try to exact into the surrounding containers once they enter into our environment.
00:24:24 [W] Therefore we need to collect logs of all commands executed inside our containers.
00:24:30 [W] However, this is not a simple task.
00:24:32 [W] After thinking more about this, we realized that transitioning to this troilus could remove this requirement recall that this rule is containers or or containers built on scratch do not have a shell into which attackers could exact.
00:24:48 [W] One less point on destroys containers in jiki will almost exclusively use Go destroy these containers.
00:25:00 [W] Since go is our preferred language.
00:25:11 [W] However, when using this tool as containers for scripting languages, like python, for example attackers may still be able to execute scripts inside such containers. So, please keep this in mind.
00:25:15 [W] The second check the link between the binaries running in production and they are manifest requires a little bit more background.
00:25:26 [W] Let me first Define what we mean by build manifest.
00:25:31 [W] Build manifest among many other things should contain the list of dependencies or libraries that make up the output.
00:25:41 [W] acquired to build a goal artifact
00:25:53 [W] Of course the versions of the dependencies are very important as well. Since owner abilities are often applicable only to specific versions.
00:26:02 [W] So the question is given a Docker image or rather Docker image ID.
00:26:14 [W] Could we tell if the packaged application depends on the problematic Library?
00:26:17 [W] Furthermore during the mitigation stage your incident response Commander will for sure ask this question.
00:26:27 [W] how many nodes or maybe clusters are running with this problematic Library?
00:26:32 [W] Consciousness questions, we clearly need to have a way to go from the image identifier to the build manifest and you certainly don't want to start figuring out how to go from A to B during an incident.
00:26:47 [W] The mechanics behind the linkage may depend on your build and deployment systems so we can go into the details here.
00:26:59 [W] However, we do encourage you to go through an exercise where you pick a production binary and try to answer a question on what libraries does it depend on.
00:27:08 [W] So you have done your homework checked all the boxes.
00:27:15 [W] You have your heart in infrastructure, but audit log streaming.
00:27:17 [W] That's great.
00:27:19 [W] As you probably expect you just need to follow another checklist.
00:27:24 [W] There is one fundamental difference between the checklists that Alex just talked about and the ones we will look at next the pre-incident checklists are trying to centralize all the power and decision making in the hands of the single person who's following them
00:27:39 [W] For the incident itself attempt to decentralize power and force you to communicate with each other.
00:27:51 [W] The the goal here is to split the problem into smaller pieces.
00:27:52 [W] That's small and groups can tackle.
00:27:56 [W] We will break down the incident into five distinct stages and the steps for all of these will actually be written down in your internal Wiki.
00:28:02 [W] When and Uncle engineer gets notified about a new incident.
00:28:10 [W] The first thing to do is reproduce it and figure out the impact.
00:28:13 [W] So you want to know whether this actually affects your production environment, or maybe it's a false alarm due to some funky configuration that you use you give also want to note what the blast radius is.
00:28:25 [W] So what kind of bet they do how much of your infrastructure is exposed how many of your users are exposed and so on I useful tool here is canonical.
00:28:33 [W] Coding a serious a score which is an industry standard for rating security incidents. It gives you a score from 0 to 10 above how bad the issue is after you have successfully reproduced it. You want to write down the steps that you used.
00:28:47 [W] For later on when someone else is rolling out a fix to production and they want to confirm that it actually fixes the problem and one other useful thing to know done is what are the symptoms of an active exploit.
00:29:04 [W] Can you use any of the signals like logs or monitoring to later figure out whether this has actually been abused in your infrastructure?
00:29:12 [W] Now that you have confirmed that the incident is real it's time to start the actual response process.
00:29:22 [W] First thing you want to do is create a communication channels the most useful thing here is a shared document that you can collaborate on with your teammates.
00:29:31 [W] It should usually be copied from some template that you have created out of time.
00:29:35 [W] So you don't have to figure out what sections need to be present.
00:29:39 [W] It's also a very useful tool to onboard new responders and get them of latest information about the incident.
00:29:42 [W] Another Channel another condition channel is a shared chatter. Mm. This is good for just live coordination and some discussion.
00:29:55 [W] But any major decisions you make here should be recording in the dog Carlos.
00:30:02 [W] And finally if you are operating under embargo or perhaps some other reasons to be secretive about the incident. It's good to come up with some code word to refer to it internally without disclosing any details, but this is for the rare
00:30:10 [W] Shared document that you can collaborate on with your teammates.
00:30:12 [W] It should usually be copied from some template that you have created out of time.
00:30:13 [W] So you don't have to figure out what sections need to be present.
00:30:14 [W] It's also a very useful tool to onboard new responders and get them of latest information about the incident.
00:30:14 [W] Another Channel. Another Communication channel is a shared chat room.
00:30:17 [W] This is good for just live coordination and some discussion.
00:30:17 [W] But any major decisions you make here should be recording in the dog Carlos.
00:30:22 [W] And finally if you are operating under embargo or perhaps some other reasons to be secretive about the incident. It's good to come up with some code word to refer to it internally without disclosing any details, but this is for the rare.
00:30:24 [W] Because there are multiple people involved in the incident response is good to establish a clear hierarchy and chain of command so here are just some of the roles that you might Define ahead of time and clearly communicate to people what they should be doing
00:30:29 [W] There are multiple people involved in an incident response is good to establish a clear hierarchy and chain of command so here are just some of the roles that you might Define ahead of time and clearly communicate to people what they should be doing The
00:30:31 [W] Originally and is responsible for driving it from start to finish Communications leads is someone who will communicate externally to your customers or Partners about the incident or any impact it might have on them.
00:30:46 [W] You might want to unboard some subject matter experts people who are intimately familiar with the part of the system that's compromised just to advise the end effects or maybe do the fix themselves and then operations lead is an optional role that
00:31:01 [W] applies when you have a large incident with a lot of moving pieces operationally handles only the mitigation and rollouts and of loads of those concerns from incident commanders plate and after all this prep work, we finally get
00:31:16 [W] There was a part of the system that's compromised just to advise the on the fix or maybe do the things themselves and then operations lead is an optional role that applies when you have a large incident with a lot of moving pieces
00:31:18 [W] So this is pretty straightforward.
00:31:26 [W] You should make a short term fix that stops the bleeding and closes the Gap as soon as possible.
00:31:31 [W] You should also think about some longer-term ideas to fix this properly or maybe you can fix the entire class of own abilities to this represents after you have the fixed end.
00:31:38 [W] It's time to roll out.
00:31:41 [W] You have a choice here between your regular load rollout schedule or a festival out. So this is something very serious that's being actively abused tufin.
00:31:47 [W] You might want to choose to forgo your regular safety checks and get out the door much faster regardless of what you do, you should avoid outages consult with your accessories your devops engineers and make sure that
00:32:02 [W] Doing is not going to bring down the entire service.
00:32:06 [W] And then after the load is complete you can finally call all clear and be done with the incident.
00:32:15 [W] Just kidding.
00:32:15 [W] There's more work to do.
00:32:20 [W] So after you fixed a problem you want to investigate whether it was abused.
00:32:22 [W] So use your audit logs that you have set up before the incident use any other monitoring you can have and figure out how many of your users were affected. You do want to collect the list of users that were affected but that should be a
00:32:36 [W] and public internally should only communicates and aggregate number and obviously if the number of people affected is not 0 you want to follow up with them and to the appropriate next steps, and another useful thing to do
00:32:52 [W] Writing a post mortem.
00:32:57 [W] This is the same post mortem practice that has three zeros for outages and it has been covered extensively in the past.
00:33:02 [W] So here's a link to a place you can start learning about them if you're not familiar, but basically you write down. What went wrong. What happens?
00:33:11 [W] What did you do in response? And how can you improve in the long run?
00:33:15 [W] I hope we have convinced you that checklists are a very valuable tool both before the incident as a way to prepare yourself and during the incident to make sure you have not missed any critical steps.
00:33:30 [W] And remember you can always change them and adapt them if there's something missing a step you wish you a taken add it to the checklist and say and the longer you use them. The easier your incidents will become.
00:33:42 [W] Okay, it's time for Q&A.
00:34:03 [W] You're going to hear me just to start Danny laughs if there's a template for The Comstock and I lent it in the Q&A section as an answer by isil select from slides.
00:34:16 [W] from it
00:34:19 [W] next pull your datastax.
00:34:27 [W] Yeah, I've been thinking how to answer this question in a lot of time. Certainly.
00:34:35 [W] I think there is no simple.
00:34:45 [W] This is actually complicated because you basically we're basically looking at ways to configure Linux audit would it be system and the trick there is
00:34:49 [W] To zero in on the system calls that entire indicative of that tack and also set them up in such a way that you don't overwhelm your operating system.
00:35:04 [W] I think Andrew and I will probably need to pull off with the with the blog item on this on the best practices because we are still trying to figure out the right compromise between logging too much and not enough.
00:35:20 [W] So I think this is a in honest answer to this. It is a still work in progress because we're still trying to figure out the best way to reduce noise at the while at the same time producing actionable
00:35:33 [W] Yeah, just found out the specifically the kubernative started log.
00:35:45 [W] So the log that contains all of the API requests to the kubernative control plane.
00:35:49 [W] If you just collect everything, it's really really chatty.
00:36:01 [W] Like there's a lot of stuff going on in converting this cluster because of all the control is constantly looping and trying to reconcile States and and so on so there's definitely a problem in the kubernative this world of having too much.
00:36:05 [W] Too many signals and filtering out the noise.
00:36:17 [W] So yeah, we'll definitely to follow up on what would be like the minimum recommended set of signals to keep an eye on right?
00:36:23 [W] Yeah specifically for access denied like our current thinking is that will take a look at seccomp profile like seccomp is a very good starting point seccomp removes a lot of Dentures system calls
00:36:34 [W] So I think this will be our starting point.
00:36:39 [W] Well actually start we are logging were logging Cisco was that would have been blown that are being blocked by seccomp.
00:36:46 [W] That's a good starting point.
00:36:49 [W] However, we found that it's even seccomp is a bit too permissive.
00:36:53 [W] So there is more work to be done there to provide an optimal wedding configuration.
00:36:57 [W] So Danielle is asking should your incident response process and vulnerability incident response plan be different or do you think it's better to have note of differences?
00:37:19 [W] So definitely at least with it with our experience in GE the process. We just described in the slides.
00:37:28 [W] It's tailored towards vulnerability patching. So if you have an actual active incidents
00:37:32 [W] Where someone is in your infrastructure the process for that should be different for regular vulnerability patching.
00:37:47 [W] You have a little more time to sort of analyze come up with a better fix like do a lot of extra work to make the response smoother and like have less impact on your customers.
00:37:55 [W] Students in GE the process. We just described in the slides.
00:38:05 [W] It's tailored towards vulnerability patching. So if you have an actual active incident where someone is in your infrastructure the process for that should be different for regular variability patching.
00:38:06 [W] You have a little more time to sort of analyze come up with a better fix like do a lot of extra work to make the response smoother and like have less impact.
00:38:10 [W] On your customers while doing an instant response you want to just get the closed as soon as possible as your top priority and because of the different priorities, there's the process is going to be slightly different.
00:38:13 [W] So yeah, I think that's kind of the the overarching.
00:38:14 [W] Change between the two is that you want to go very fast.
00:38:17 [W] And is it a response and you can be a little more deliberate and safe invulnerability bashing.
00:38:18 [W] And our response that's King the incident checklist looks fairly fairly linear, isn't it better to think about and Implement like gra? She moving from state to state.
00:38:32 [W] So it is that is a good point. The checklist as presented as an Unwritten is linear, but it it shouldn't be treated as such a lot of the steps can be done in parallel.
00:38:49 [W] So you can communicate with customers and be patching at the same time. The reason is like it's not very easy.
00:38:58 [W] It's not easy to write in a dock something.
00:39:00 [W] a checklist for you must check all the boxes, but also kind of make it look parallelizable.
00:39:06 [W] It's kind of like a presentation issue.
00:39:11 [W] But yes, you can definitely paralyze all the steps.
00:39:21 [W] But yeah, that's a great question actually thinking about like creating a workflow for based on those checklists and like spinning up certain tasks in parallel.
00:39:25 [W] So we just looking for some ways to like codify this process and maybe grpc something we need to look at but that's a great question something. We're thinking definitely thinking about that.
00:39:33 [W] We're thinking about like creating a workflow for based on those checklists and like spinning up certain tasks in parallel.
00:39:36 [W] So we're just looking for some ways to like qualify this process and maybe grpc something we need to look at but that's a great question something.
00:39:36 [W] We're thinking definitely thinking about that.
00:39:37 [W] So that's all of the questions in the Q&A section.
00:39:45 [W] So maybe wait for another minute finding else shows up.
00:39:49 [W] Okay, there's no more questions chance. I think we can hand early. We will at least allow personal hang out in the slack channel for the security and identity truck.
00:40:27 [W] So if you come up with any more questions in the next 15 or 20 minutes, he'll free to shoot them there.
00:40:33 [W] try to catch those.
00:40:35 [W] But thank you so much for attending.
00:40:37 [W] Thank you so much. Bye bye.
