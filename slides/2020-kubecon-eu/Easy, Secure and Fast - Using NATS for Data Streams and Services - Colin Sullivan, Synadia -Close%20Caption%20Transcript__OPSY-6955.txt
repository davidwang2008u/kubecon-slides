Easy, Secure and Fast - Using NATS for Data Streams and Services: OPSY-6955 - events@cncf.io - Tuesday, August 18, 2020 12:30 PM - 44 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Hi, welcome to easy secure and fast using Nats that I owe for streams and services.
00:00:10 [W] Let me introduce myself.
00:00:15 [W] My name is Colin Sullivan.
00:00:17 [W] I run product that's knative had at calm. That's an idea.
00:00:26 [W] I'm a net. I've been asked or maintainer for about five years now, and I've been building distributed systems for over 20 years today.
00:00:30 [W] We'll talk about Nats in general will talk about streams and services topology security and then some additional features and the roadmap and throughout this presentation. You'll see how streams and services or applications.
00:00:42 [W] Patterns to biology and security can be put together to make some very powerful Solutions. First off. What is Nats Nats is a ten-year-old production proven Cloud native distributed Communication System.
00:00:57 [W] Nats was made for developers and operators who just want to do their job so you don't want to think about managing a messaging system.
00:01:06 [W] So what's important to us is performance Simplicity security and availability Nats was built from the ground up to be Cloud native Cloud Foundry was
00:01:12 [W] Ali its first use case Nats supports multiple qualities of service, we support multiple communication patterns and over 40 types of clients. So we should have you covered Nats is used for Cloud messaging
00:01:27 [W] This is Services event and data streaming command and control and more and more.
00:01:37 [W] We're finding that people are using Nats and extending out to the edge where there's iot and Edge components with Telemetry sensor data, and again more command and control and also a number of our users are using Nats to augment or replace
00:01:49 [W] Now she's where they might currently have an investment in some Legacy technology, but want to extend out into the cloud and Bridging the Nats for that. We joined cncf as an incubation project in 2018. We're part of the
00:02:04 [W] streaming projects
00:02:07 [W] and we have over a thousand contributors over the last 10 years with a hundred or more with more than ten commits.
00:02:16 [W] We've got quite a few public repositories.
00:02:18 [W] We're hoping to break 20,000 GitHub Stars across all the repositories this year.
00:02:24 [W] We've got about a hundred and thirty million. Dr. Pols between Nats server and a streaming server a very healthy slack community and a good Cadence of nats server release has since 2014 with about five a year.
00:02:37 [W] NASA was created by Darren Collison.
00:02:42 [W] Derek's been solving the really hard problems in distributed computing over the last 30 years around Nats Derek built a highly experienced messaging team. And and from that we have a very very engaged user Community.
00:02:54 [W] Happy with their Nats Community.
00:02:57 [W] It is great to see people jump in and help on slack and watch community members help each other.
00:03:03 [W] In terms of end users.
00:03:09 [W] We really Nats has a very utilitarian type of technology.
00:03:11 [W] So it's very horizontal.
00:03:15 [W] So we've got end-users of all sizes and all different verticals.
00:03:16 [W] Nats is simple the server which is our basic Network element is a single binary.
00:03:26 [W] It's Deployable anywhere.
00:03:37 [W] It's very small with about a 10 megabyte Docker image. This lets it spin up very quickly in the cloud. The protocol itself that Nats uses to speak to the clients is text based.
00:03:40 [W] Don't get that confused that we can send any type of payload, but the very simple protocol makes it easy to write clients and that's why we have so many of them Nats is low configuration.
00:03:48 [W] Client connects to the server.
00:03:53 [W] It doesn't need to know anything about the topology. It just needs a your own credentials servers can autodiscover you can share configuration files among servers and Nats is very easy to code to it's a very simple and straightforward API.
00:04:04 [W] We've got a number of nats clients that are supported by the Nats support Nats maintainers as well as the community with many different languages many different bindings.
00:04:14 [W] It just needs a your own credentials servers can autodiscover you can share configuration files among servers and Nats is very easy to code to it's a very simple and straightforward API.
00:04:26 [W] We've got a number of nats clients that are supported by the Nats support Nats maintainers as well as the community with many different languages many different bindings.
00:04:27 [W] Now let's talk a bit about message patterns. And this is these are our how your applications communicate with each other and we tend to like to think of these into buckets streams and services stream is a flow of data.
00:04:30 [W] It's just a number of messages going out and streams can fan out. You might have a stream of data you fan out to a thousand or ten thousand or a million subscribers. Then we have the concept of services services are where I
00:04:45 [W] You ask an application to do some work and then return the result services are by far the most common that we see and services can be load balanced.
00:04:55 [W] Streams and services at the application Level when you go to code really fall into a couple patterns, which is request reply.
00:05:06 [W] These are your services.
00:05:06 [W] This is your RPC publish/subscribe, which is the basis for request reply, but pure pub/sub is just a stream of data and then you have load-balanced q subscribers where Nats can load balance and we do have a new higher
00:05:21 [W] New higher level API coming that more closely reflects this concept of applications being a stream and or a service.
00:05:29 [W] Before we talk about patterns.
00:05:39 [W] Let's let's talk about subjects and how data gets from one application to another Nats routes data based on interest.
00:05:47 [W] So an application will register a subscriber with the subject indicating interest in something.
00:05:53 [W] So there's a very simple subject your Everlasting Foo example, or let's take something more concrete.
00:05:59 [W] I'm interested in whether so I created a subscriber for whether these can be higher.
00:06:00 [W] Typically token I so food out bar or whether dot u s dot Colorado Denver. This allows you to use wildcard subscriptions to create some very complex filtering and then also you can use unique subjects
00:06:15 [W] logical one to one relationship between two applications
00:06:20 [W] streams are pretty simple.
00:06:27 [W] Nats will fan out publish messages to all interested subscribers in might be one subscriber.
00:06:30 [W] It might be million but Nats takes care of that and you can add or remove subscribers anytime at runtime with no configuration. Nats will just do the right thing and start routing information to them.
00:06:40 [W] The code to set up a stream today is very very simple.
00:06:49 [W] You connect to an app server you subscribe to stream in this case.
00:06:53 [W] I'm interested in data arriving on Foo when that data arrives.
00:06:56 [W] I'm just going to print it out.
00:06:57 [W] That's that log print line and then the corresponding published get that data out onto Foo is just the publishing API.
00:07:06 [W] They're extremely simple.
00:07:09 [W] This is actually could be a working application right here services are your 121?
00:07:14 [W] You can use reneik unique reply subjects where you make a request service does some work and returns a response.
00:07:19 [W] Here's the service API code.
00:07:25 [W] So you connect in this case to a local net server you subscribe. I'm going to be offering a service on the subject of help. And then when someone says can you help I'm going to say yes.
00:07:35 [W] I'm going to respond with a message says I can help and the requester sign.
00:07:41 [W] CPI code so you connect in this case to a local net server you subscribe.
00:07:47 [W] I'm going to be offering a service on the subject of help and then when someone says can you help I'm going to say yes.
00:07:47 [W] I'm going to respond with the message says I can help and the requester sign.
00:07:48 [W] I below I issue a request for help say that I need some help wait a second up to a second for a response and then just print them response when I get it.
00:07:49 [W] That's it. It's very straightforward very easy.
00:07:50 [W] Easy to coat the Nats Nats can also act as a layer 7 load balancer.
00:08:00 [W] So when subscribers subscribe, they can choose to be grouped together in a in a queue group when we call that a cue group.
00:08:06 [W] It's actually more like a work queue.
00:08:08 [W] It's essentially creates creep competing consumer pattern.
00:08:14 [W] But what happens is the Nats server will then randomly distribute messages?
00:08:18 [W] To these subscribers in this allows you to set up a service and set up a number of services that will automatically scale as if it were layer 7 load balancer again, you can add these Services anytime
00:08:34 [W] Them anytime and Nats just as a right thing.
00:08:37 [W] No additional configuration. This allows you to very very easily scale.
00:08:41 [W] So now that we've covered our patterns in the at the application Level.
00:08:50 [W] Let's talk about topology topology is the plumbing or you know think of it like the electrical grid for your messages. This is where messages may arrive.
00:08:56 [W] And Nats has a number of building blocks for topology the lowest common denominator. The simplest thing is your server that's like a network element servers can be grouped together to form one cohesive unit called a cluster that provides higher availability and
00:09:13 [W] Scale clusters can be clustered together to create what we call a super cluster and outside of these clusters are Leaf nodes, which are Nats servers that kind of act as a client.
00:09:29 [W] They aren't part of a cluster but they're connected to it and can and can relay messages to and from it the very very simple setup, which is what most developers will do on their on their machines. Is it single server with a couple Nats clients connected to it?
00:09:41 [W] Clusters when you cluster Nats servers are full hop or full mesh one, huh?
00:09:50 [W] That means Nats servers will always route messages in the shortest number of hops that that are available.
00:09:55 [W] Clusters cluster together our superclusters again. We use what are called Gateway connections between the Clusters Gateway connections are optimized for a way an optimized for low later optimized for higher latency lower bandwidth connections
00:10:10 [W] Any number of clusters can be grouped together in a super cluster.
00:10:16 [W] That's inedia.
00:10:17 [W] We have a massive supercluster spread out across various Cloud vendors over the whole over the globe.
00:10:31 [W] So so you can make these as large or as small as you need to and leaf nodes Leaf nodes is single Nats server extended out from a cluster.
00:10:35 [W] They extend the a hub-and-spoke technology.
00:10:37 [W] They do a couple different things.
00:10:40 [W] They let you bridge differences security domains. So you might use Nats
00:10:41 [W] security within your main deployment and a leaf node might use a different security scheme out on an edge device or remote node.
00:10:56 [W] These are ideal for Edge Computing iot hubs data centers anything that's remote that needs to be connected into a Central Central deployment and then they can also transparently bridge on-premise and Cloud deployments remember
00:11:06 [W] Science don't care about the topology at all. They just know that they're connected to Nance.
00:11:12 [W] Here's a global deployment an example of a global deployment where you might have a Nats cluster running and kubernative in San Diego Nats clustered running on VMS and Berlin and another one in London. I'm kubernative.
00:11:28 [W] You have a remote data center that's clustered together with some Services streams connected into San Diego and then a leaf node that might be like a set-top box with devices connected to it.
00:11:40 [W] Now the third part is security.
00:11:44 [W] And Nats security has some Basics so we have full TLS support mpls we support danns or subject alternative names to be used as identities.
00:11:58 [W] We have standard user password authorization.
00:12:01 [W] You can set permissions on what applications are what users can send and receive and what subjects you can change these at any time with zero downtime.
00:12:13 [W] You can adjust the config have the next server reread it at runtime and it'll do the right thing.
00:12:15 [W] Then with operator bowed in Nats 2.0, which is about a been out for about a year now Nats supports multi-tenancy with operator mode.
00:12:30 [W] And Nats allows you to set up this chain of trust between operators accounts and users within a deployment and The Operators the root of trust for the system.
00:12:52 [W] So that's like an Enterprise underneath the operator you create accounts for account administrators and account represents an organization.
00:13:02 [W] It might be a team it might be a group of microservices.
00:13:04 [W] It might be an IT group that's monitoring the entire Nest employment and income.
00:13:07 [W] Creation would likely be managed by a central group and then underneath the accounts are accounts can expose dreams and services and underneath accounts. You have users that have specific specific credentials and permissions.
00:13:22 [W] So a counter isolated communication context what what accounts do our when you've got multiple accounts on a server applications Connect into those accounts. Those messages will never cross those account boundaries that allows you to
00:13:39 [W] Technology from business-driven use cases that allows you to create data silos based on these accounts.
00:13:50 [W] It's secure and cost-effective.
00:13:51 [W] So one Nats deployment is managed by an operator yet teams can be decentralized and self-managed.
00:14:04 [W] But when data does need to be shared between these accounts you can share them with secure streams and services.
00:14:08 [W] So one account might offer a service on subject food another account might say hey.
00:14:09 [W] Yeah, I want that service.
00:14:11 [W] It will import that service on Foo and suddenly that's available. And only with mutual agreement will data flow between accounts in Nats identities
00:14:26 [W] Service, it will import that service on Foo and suddenly that's available and only with mutual agreement will data flow between accounts.
00:14:27 [W] In Nats identities are represented by n Keys which are housed in jwt's and keys are Edie to 5519 keys made easy and associated with these M.
00:14:39 [W] Keys would be a user and account a cluster or server.
00:14:45 [W] We used 82 5519 because it's fast and resistance side-channel attacks.
00:14:49 [W] We use those to sign and verify and we use them in such a way that
00:14:52 [W] That Nats system will never see private keys without getting into details that server sends announced during connect client signs the knots with its private key and then the server verifies that the client
00:15:07 [W] We use those to sign and verify and we used them in such a way that Nats system will never see private keys without getting into details that server sends announced during connect
00:15:09 [W] By the server long story short, this is letting Nats approach zero trust system and all this stuff is managed by the NSC command line interface.
00:15:21 [W] So it's pretty easy to use to be able to set up these users.
00:15:26 [W] You don't have to worry about these details at all. When you combine topology and security with your application patterns. We create the Adaptive Edge architecture. So
00:15:37 [W] Over time we found as many companies have come to us and users have come to us.
00:15:46 [W] We found a pattern emerge and if you squint they all look the same where you have the Central Central deployment with some streams and services attached to it that's available for everything and then remotes, they might have their own Services their own
00:15:57 [W] Be shared some which might be might not and depends on policy.
00:16:08 [W] But then you have these remote deployments that are all linked together to create a massive Global deployment.
00:16:16 [W] This is essentially the iot or the edge use case and we found that through a combination of leaf nodes clusters and superclusters Nats can handle this very well, and if you look at how this can be
00:16:27 [W] Verticals this pattern is very powerful.
00:16:32 [W] So very very powerful.
00:16:35 [W] So example in retail you might have a regional headquarters.
00:16:39 [W] It will have some add reward programs coupons Logistics centralized inventory where the remotes are the stores and then you have POS device is connected into the remote that then utilizes
00:16:50 [W] Mrs. Or maybe even provides their own streams coming from stores coming back to the central.
00:16:59 [W] This is repeated over and over again for different use cases and we found that you know, again, it's the it's a similar pattern in terms of topology.
00:17:09 [W] changes are your streams and services and your security
00:17:11 [W] here's an example where multiple Airlines our airports multiple airports are super clustered together in the EU and extending out of the supercluster. Our Leaf nodes inside Terminals and
00:17:28 [W] Even planes this is your plumbing. This is your wiring.
00:17:32 [W] But then in terms of data flow, you've got a Weather Service where different airlines and airports can use this weather service, but the airline's themselves will never talk to each other.
00:17:48 [W] These are all set up by accounts and streams streams and service sharing.
00:17:50 [W] Now let's segue into performance and scalability Nats performs extremely well with by 18 million messages a second one server one data stream 80 million messages a second with multiple Services some of this is
00:18:08 [W] Trick but it translates into scalability and resource utilization.
00:18:18 [W] So if a single net server can handle 18 million messages a second.
00:18:27 [W] That means if you only need a few thousand messages and second are 20,000 must use a second a single net servers going to do you well for a long time.
00:18:31 [W] You aren't going to have to scale for a while and also you can use less compute resources to do the same thing. You might be able to with a different system.
00:18:39 [W] the health and availability of the system in the hole is prioritized in Nats traditional messaging systems would would spend resources on trying to make sure that a poorly behaving application
00:18:54 [W] That doesn't work in Cloud.
00:18:56 [W] So to that end the Nats server performs selfish optimization. If there is a poorly behaving client or poorly behaving server the Nats server will cut it off and then at that point an operator will look at it.
00:19:11 [W] We've got full mesh luster and internet servers and the server and client connection cell field. This creates a low-maintenance always on always available deployment for that.
00:19:22 [W] Nats also has Auto Discovery what this means is as you scale up or scale down net servers in a cluster. This information is shared with the other Nats serverless. You don't have to do additional configuration.
00:19:40 [W] You don't have to bring anything down or bring it back up again to change your topology and this information is also shared with clients.
00:19:46 [W] means clients can fail over to servers. They were never originally configured with and these are great for ruling upgrades or you know, even swapping out your back end with different machines.
00:19:55 [W] If you need to upgrade machines do whatever you need to do your clients can remain running.
00:20:00 [W] We have a couple different message guarantees at its core we support at most once where there's no guarantee of delivery or messages can be lost. This sounds harsh, but it's how the internet works today
00:20:16 [W] Swats, which are where a message will always be delivered in certain cases certain error conditions.
00:20:24 [W] It can be delivered more than once.
00:20:25 [W] I've always said in the past exactly once it's unnecessary complex.
00:20:29 [W] It's always slow but due to popular demand. We're going to support it in jet stream.
00:20:36 [W] Jet stream is the next generation of nats streaming. It supports there's a lot of overlap with that streaming but also supports Wild Card support Nats 2.0 security. So it's street. It's account aware.
00:20:52 [W] It's got data at rest encryption.
00:20:56 [W] You can cleanse specific messages.
00:20:57 [W] So then this was a request that really helps out with GPR and horizontal scalability.
00:21:06 [W] as you need to scale you just launched more reject stream servers and
00:21:07 [W] Like that streaming you can replace messages by timer sequence.
00:21:11 [W] So there is an overlap Nats jimin continue to be supported.
00:21:19 [W] We've got millions and millions of dr.
00:21:21 [W] Downloads. We know it's deployed globally in production So to that end will provide bug fixes and security fixes until June of 2022.
00:21:34 [W] 2022 that being said moving forward new Nats enabled applications that need streaming should prefer jet stream will provide a migration path and new Nats development as it relates to streaming will occur inject strimzi.
00:21:43 [W] Nats human continue to be supported we've got millions and millions of dr.
00:21:47 [W] Downloads. We know it's deployed globally in production So to that end will provide bug fixes and security fixes until June of 2022. That being said moving forward new Nats enabled applications that need streaming should
00:21:49 [W] We have distributed tracing we use opentracing we've got reference architectures in Java and go and this allows you to use Nats to trace messages in your application across, you know, microservices or
00:22:03 [W] We've got a number of Integrations into spring Kafka.
00:22:11 [W] We're working on a JMS bridge right now and we do have an M Q Series adapter or Bridge.
00:22:18 [W] We have Nats surveyor.
00:22:22 [W] So surveyor can monitor your entire entire deployment from one entry point into Nats?
00:22:29 [W] It provides a comprehensive view of the entire Nats deployment.
00:22:33 [W] So if I've got surveyor running on my laptop, I just connect to my Nats deployment.
00:22:33 [W] And I can see everything so long as I have the right credentials.
00:22:42 [W] This makes this prevents you from having to install a lot of sidecars to monitor Nats.
00:22:43 [W] And we use Griffon as a dashboard.
00:22:49 [W] We provide centralized visualization, but you can also drill down into and look at individual servers and then we work well in kubernative we've got single command line to install a full
00:23:03 [W] Sure, and if kubernative deployment is a false and installs Nats as a stateful set and along with that we give you a surveyor installation so you can see what's going on and a roadmap moving forward in the latest release.
00:23:19 [W] Export the Nats server. We've got a websocket client number of leaf nodes improvements coming up in Q3 will be the ga release of jet stream.
00:23:32 [W] It has been in Tech preview for a while.
00:23:33 [W] We've gotten some excellent feedback and the ga release will be will support clustering with high availability fault tolerance and then scalability as well.
00:23:46 [W] We are we have added message headers or we're in the process of adding message headers. We're doing this in such a way that it will not
00:23:50 [W] Not affect the fast path. So you'll get the same performance.
00:23:55 [W] You've always gotten out of nats.
00:23:56 [W] We've got added to the protocol.
00:24:03 [W] We have a Nats GMS bridge and then we've got those service and streams apis.
00:24:03 [W] I talked about earlier in Q4.
00:24:09 [W] We're going to support knative mqtt 311.
00:24:13 [W] There's a lot of mqt deployments. We found that in bridging iot and devices and Edge compute with the cloud. Nats is a just a really cool solution.
00:24:20 [W] Do that. So we're going to adopt mqtt as knative natively supported in the net server.
00:24:29 [W] Well monitor enhancements Nats Kafka bridge and hands minutes and we're going to do some additional things to get from edge-to-edge zero trust security and then the first half of next year further investment into mqtt
00:24:43 [W] Lee support in the Nats ecosystem where the Nats deployment might be able to run small sections of code that can act as a small application or filter messages and then as always we're providing additional option
00:24:59 [W] Messages and then as always we're providing additional option Dev tooling with additional distributed tracing and then system-wide the bug tooling.
00:25:04 [W] So I thank you so much for your time and you know just like to open it up for any questions that you might have.
00:25:14 [W] Okay, so some questions that have been asked is does Nats account for a client dropping away in this in the load balance setup will retry another client.
00:25:35 [W] It really depends on whether you're using coordinates or streaming with cornets that that happens at the application layer. So you make a request in to a service and that request might time.
00:25:47 [W] Out and then you would try retry the request on the backside. If let's say responding to the request your application drops crashes. What have you that request will simply remain unfulfilled.
00:26:02 [W] It's up to the requester to retry.
00:26:04 [W] With if you do use persistence and it's kind of an anti-pattern with request reply but persistence will retry Q subscribers. So if you use jet stream or Nats streaming, it'll retracts you subscribers.
00:26:18 [W] Shouldn't you let the net server know? Hey, I'm going away and then you continue to process the rest of those messages.
00:26:37 [W] You still have kind of activity.
00:26:41 [W] You just won't receive any more and that's a great way to gracefully leave a group another question.
00:26:48 [W] What's the difference between Nats jet stream and Kafka.
00:26:52 [W] This is a we could spend a lot of time on this at a high level.
00:26:56 [W] I'll say that they're both log base persistence.
00:26:58 [W] Jet stream has pull models and push models.
00:27:08 [W] But what I what I would encourage you to do is join our slack group and you know and ask and we can go in depth and learn more about your use case to to further differentiate
00:27:17 [W] Available it is as a tech preview some time in queue for we're going to be GA. But right now it's available as a tech preview. You can download nightly builds play around with it.
00:27:32 [W] like I said, it'll be ready for production fairly soon.
00:27:36 [W] next question when a new subscribers created it can retrieve historical messages from the stream or only messages from that point in time going forward it can do either so you can create a new subscriber and say hey we play me
00:27:51 [W] Whether it's from the beginning of history or the last hour, or you can create What's called the durable subscriber and a durable subscriber just picks up where it left off.
00:28:03 [W] So that's that's really your choice. And with jet stream one really cool feature is that you can replay messages with temporal context in that it will replay messages in the
00:28:16 [W] Cool feature is that you can replay messages with temporal context in that it will replay messages in the same burstiness. If you will at the same rate it was originally
00:28:21 [W] Burstiness, if you will at the same rate it was originally the message is originally arrived, which is really good for for stress testing for QA and just in case that you do need to know the
00:28:33 [W] Messages are coming in.
00:28:35 [W] Let's see about scalability and kubernative.
00:28:43 [W] He's if you scale up and kubernative.
00:28:45 [W] He's from two to three pods is it needed to update the convenient fat map where the DNS of the pods are defined?
00:28:57 [W] No, it's not. So when you scale up, let's talk about two cases first you're scaling up servers when you scale up servers the server's talk to each other and they
00:29:05 [W] And they share their topology with each other. This topologies also shared with the clients. So a client can receive this information about the new server and it knows how to connect to it then so the client can original should feel over.
00:29:21 [W] Was never originally configured with in terms of clients.
00:29:31 [W] All the client needs to do is connect to internet. So let's say I'm scaling up a service. I wrote One the service connects.
00:29:41 [W] There's location transparency and Nats. So you only really care about the subject not necessarily where that service is located.
00:29:50 [W] In fact that servicemeshcon act even be in kubermatic. If you have a leaf node deployment outside of kubernative leafed in it can be there all that.
00:29:52 [W] It is entirely transparent to your applications.
00:29:55 [W] Let's see.
00:30:03 [W] Is there a way that Nats could guarantee the order of events?
00:30:06 [W] Yes by default Nats guarantees producer order by producer.
00:30:16 [W] So if you have a single producer multiple consumers, they're all going to see those messages in the same order. If you have multiple producers, those messages might be mixed up depending on how they flow through the system, but in terms of
00:30:26 [W] In from they will always be in that same order by producer.
00:30:31 [W] Could you shed more light on what applications need to do to ensure no event as lost so in jet stream.
00:30:44 [W] It's as simple as enabling Jetstream turning it on and what will happen is jet stream will re deliver messages that are not acknowledged by the application.
00:30:54 [W] So that's really your decision whether to use cornets which is spire and forget or to use jet stream which provides persistence.
00:30:59 [W] How does Nats compared to Kafka and your opinion?
00:31:09 [W] This is a this is a very this could be a very long conversation in it at a high level.
00:31:18 [W] Kafka is really just a publish/subscribe system. Nats has the request reply on top of that.
00:31:22 [W] So Nats is a little different there in terms of persistence. Kafka's log based Nats is log based when you enable persistence, so there's the
00:31:31 [W] A similar there.
00:31:35 [W] There's some feature differences here and there generally Kafka has more features right now.
00:31:42 [W] Ask we add webassembly.
00:31:47 [W] Nats we tend to like to think of things as it's an an conversation. So users can choose to use Nats on their own they can choose to use only Nats or if they already have a very heavy Kafka investment,
00:32:12 [W] Enhance that with very lightweight messaging we do have Kafka bridge to allow that so we work very well with Kafka as well.
00:32:21 [W] Okay.
00:32:30 [W] Let's see here.
00:32:34 [W] Can you elaborate on what the Nats cloudevents?
00:32:38 [W] Well, basically that's if you already have a solution that's using cloudevents. Then you can you know, you have that schema by default Nats is payload agnostic.
00:32:55 [W] It will just send a series of bytes.
00:32:58 [W] It's up to your applications to agree upon what format those come in cloudevents provides a really really nice way to define.
00:33:08 [W] Hey, here's what an event looks like. Here's what it means. Here's what the
00:33:10 [W] Fields mean and when you add cloudevents internet's you enrich Nats to provide that that schema that meaning behind messages.
00:33:20 [W] It looks like that's about it for questions right now.
00:33:31 [W] You know, I just want to say thank you so much.
00:33:38 [W] Listening to this, please.
00:33:47 [W] How about a slap community?
00:33:50 [W] And you know if you're interested in learning more about Nats always happy to talk.
