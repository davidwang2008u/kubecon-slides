Introduction to Windows ContainText_Transcript_DAOE-9340.txters in Kubernetes: DAOE-9340 - events@cncf.io - Thursday, August 20, 2020 11:20 AM - 193 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:16 [W] Hello everybody and welcome to an introduction to Windows containers in kubernative.
00:00:22 [W] My name is Michael Michael and I am one of the co-chairs of the sick Windows special interest group in kubernative and our sysdig.
00:00:42 [W] And I've been a chair of the Sig since then hopping it traversed through the lifecycle of Windows containers and kubernative in my day job.
00:00:52 [W] also a director of product management at VMware and you can find me on the kubernative slack account under the Alias M2.
00:00:59 [W] So our agenda today is we're going to talk a little bit about where we are today.
00:01:10 [W] Some of the continuous Improvement that we've done is a Sig to kind of Advance the vision of Windows containers and kubernative.
00:01:12 [W] We're going to do a quick Deep dive on CSI and a high level overview and containerd E took a level perf updates and our future roadmap.
00:01:25 [W] I want to stress here that we have one more session on Windows containers that Moss one of our key contributors on containerd DM myself did so I stress that you also follow that
00:01:29 [W] Causes that presentation that's a deep dive specifically around containerd e supports if you're interested what containerd e and the effort that you're doing on improving the compute runtime for Windows containers.
00:01:44 [W] I highly encourage that session stick a look at first on why do users and customers do play Windows and kubernative.
00:01:55 [W] Our vision has always been to make kubernative truly ubiquitous and continue to lead us the top container.
00:01:59 [W] And platform.
00:02:02 [W] So goal is kind of to enable users operators administrators to leverage the same operational efficiencies on Windows as they are have today in Linux.
00:02:15 [W] That means the same knowledge the same training that you have a kubernative supplies from Windows.
00:02:18 [W] You get to have a scalable platform that can span multiple operating systems both Linux and windows the most importantly your developers are asking for a self-service containerd.
00:02:29 [W] The service style platform they want to take advantage of cloud native tools the new way of building deploying applications new way of scaling applications and kubernative delivers on that promise for both developers and operators
00:02:44 [W] But that the key capability of Windows containers and kubernative is that you get to retain the benefits of application availability while decreasing costs and that's super important in scenarios where you get to containerize existing
00:02:59 [W] Or Legacy 2008 or Windows applications because either you want to eliminate Hardware or you want to eliminate underutilized servers most importantly if you want to stream let the migration of applications from and of support operating
00:03:14 [W] X into a newer operating system kubernative our window support and a new way of building applications is really the right way to go.
00:03:24 [W] Think about this you go from a different way of deploying management applications to putting everything into a simple Docker file that you get to build an update over time and through that Docker file you have this
00:03:38 [W] Programmatic way to define what should your application look like by modifying a few young male files? And Json files this amazing. It's great to actually have that support.
00:03:49 [W] Let's take a look at first some things to consider.
00:03:57 [W] And then after that we're going to go into a road map here and and we're being we want to make sure that everyone that's looking to Windows containers in kubernative at the read the documentation.
00:04:09 [W] It's very important to understand the differences between Windows containers and Linux containers as it pertains to kubernative as a special interest group.
00:04:20 [W] Our goal has always been to make sure that we keep in lockstep all the features are happening Linux with Windows.
00:04:21 [W] That's not always easy.
00:04:22 [W] And it's very important to understand where there's differentiation where they can win these communities ahead and what is behind on certain features?
00:04:30 [W] Second most important to look at the fact that in Windows unlike Linux containers. You have to enforce the host and guest compatibility.
00:04:46 [W] So the Windows Server kernel version the major version shoe much for now with the version of your guests containerd that's running on the host.
00:04:57 [W] So if you build it on Windows Server 2000 19 you was around the container on Windows Server 2008 in
00:05:02 [W] Post and how you achieve that by using node selectors and whether they knew not selector called Windows build that includes the windows built-in it you can use tense and colorations.
00:05:16 [W] And as as of the last couple of releases you can leverage runtime class, which you can Define once per cluster to simplify the steering of Windows or Linux pots the appropriate nodes and in the other presentation, I mentioned earlier
00:05:26 [W] We'll also talk about hyper-v isolation.
00:05:29 [W] What's that gonna look like and it's coming soon.
00:05:33 [W] We're working on that actively right now.
00:05:35 [W] This is as I seek. The last part is resource consumption Windows containers require higher limits and a higher memory and they have a higher memory footprint because of Windows background services and other artifacts that are running
00:05:48 [W] inside the container
00:05:50 [W] kind of looking at our history where we were and where we came from when we started Windows containers back in 2016 shift the first release at the end of the year 1.5.
00:06:04 [W] Those are alpha release and essentially basically ported the kubelet in the queue proxy to run on Windows.
00:06:10 [W] was great work very buggy had a lot of limitations but it essentially showed the art of the possible to everyone and rally the community to come in and contribute and make this a reality with
00:06:21 [W] Nine year later with our Beta release tremendous updates.
00:06:26 [W] We had cni-genie.
00:06:28 [W] I've been running.
00:06:30 [W] So a lots of work came in from the community.
00:06:37 [W] You're going to notice here. The big circles include huge huge updates that you had 114 who had are stable release.
00:06:41 [W] release. This was the first release where we had support for production workloads running Windows on kubernative and we supported Windows Server 2000 19, which is the long-term service from Channel coming from Microsoft.
00:06:50 [W] since then it's been for more releases of kubernative one, 15 16 17 and 18, but we've made advancements in Cuba DM C SI Runners username and and we took some of those advancements
00:07:05 [W] Informal releases of communities one 15 16 17 and 18 but of made advancements in Cuba DM C SI Runners username and and we took some of those advancements to Beta as well
00:07:08 [W] 18 we've made two significant advancements to g a g MSA and Runners username and both of those capabilities enable Windows containers developers to Define an identity
00:07:23 [W] Containerd will carry on the network really critical part for running Enterprise line of business applications on Windows in kubernative.
00:07:36 [W] We also took you by DM 2 Beta cluster API to Alpha CSI, proxy 12 containerd e 2 alpha 1 18 was probably our biggest releases since 1.14 and then 119 came along and now we
00:07:49 [W] To better we have containerd D2 better. We have networking enhancements like like DSR and end point slices and then additional stability and performance improvements.
00:08:01 [W] All right.
00:08:04 [W] Let's talk a little bit about CSI and some of the updates to the work that happened in the community.
00:08:16 [W] If you're not familiar with CSI, it's really the standard for exposing blog and file storage to containerize workloads on kubernative and it's an out of three provider model that enables CSI drivers and providers to
00:08:24 [W] operate and release independently of the core kubernetes recycle and the way that it works from an architectural standpoint has a controller plug in and anode plug-in and the note plug-in requires direct access to the
00:08:39 [W] For making storage operations, like calling block devices file systems file system calls in Windows that note plug-in cannot operate as expected and this is because on Windows containers you don't
00:08:54 [W] Support for privilege containers which is of the containers that have higher level of access on the Node and because this node plug-in needs to run with this elevated privileges.
00:09:10 [W] We couldn't really follow the same architecture for CSI support as it exists today in Linux.
00:09:14 [W] So to solve that we create a new component called CSI proxy. So it kind of bypasses that regular pipeline so that note plugins can now be deployed as and
00:09:24 [W] aged pods and then use the proxy to perform a lot of the privilege storageos lated operations are needed on the Node.
00:09:33 [W] So kind of allows us to bypass that that existing mode of how CSI plugins work.
00:09:42 [W] So with 119 who have moving our CSI support and CSI proxy to Beta so we've had a tremendous amount of updates here.
00:09:53 [W] We've added support for API versioning and also version API groups to support disk volume SMP operations.
00:09:54 [W] You cannot know this is Cassie is not here because we're waiting for feedback from the community to see if it's we need to support iSCSI but an enhancement in kubelet C SI no driver registered.
00:10:10 [W] So forth for a direct win32 API, so I October's and a lot of other things and with this release we are CSI proxy beta will support two types of csis as your disk and
00:10:22 [W] Disqualify volume driver, what's next going to continue innovating in this work?
00:10:35 [W] We plan to have a full ci/cd engine as well as additional CSI providers like vsphere AWS and so on and so forth.
00:10:39 [W] So if you're interested in that work come and help us enable that so now let's take a look at the CE s architecture diagram like I mentioned we you have you have Docker and kubelet and standard components and kubernative and in order for some of the storage
00:10:52 [W] Operations to to be handled at the higher privilege that it required what this new componentconfig CSI proxy that is able to make the calls to the storage volumes to the file system to the file volumes
00:11:07 [W] On behalf of the CSI node part. So in the CNO pod you have your no driver as well as anode plug-in like I mentioned earlier they're calling to the CSI proxy that bypasses and compromise see some of those requests down to the file systems
00:11:22 [W] and then on the right side, you have your windows part of the different containers that can be attached to persistent volume that's taken in storage down from the CSI providers that do support in this case the AWS the Azure as well as
00:11:37 [W] a gcpd
00:11:39 [W] the next area that we're taking to Beta with with our latest release for 119 is containerd e so, why did you do container D like I mentioned earlier, please attend the other session on Windows because we do a deep dive on containerd E, but
00:11:56 [W] Kennedy essentially allows us to align the direction of our investment with the rest of the kubernative community as well as the other active Investments are happening across the both the cri-o.
00:12:26 [W] One is it's going to enable hyper-v isolated containers to run and kubernative.
00:12:32 [W] That means that you're going to be able to have a secure multi-tenant boundary across Windows containers on kubernative.
00:12:38 [W] This is huge.
00:12:42 [W] It's going to enable a new class of use cases for the users who are multi-tenancy is an important aspect of their delivery in the kubernative environment. And then we don't have today is GMS a support and a plan to add it if you
00:12:53 [W] Earlier when I mentioned the GSA is stands for group managed service account and it enables Windows containers to carry Windows Active Directory identity on the network today.
00:13:09 [W] It's not working for containerd e, but we're actively working to enable that.
00:13:10 [W] Take a look at the runtime architecture of containerd the other high-level the previous architecture using Docker today.
00:13:20 [W] It works by having the kubelet with the embedded Docker. She all-in-one release calling Docker which in turns called HCS version one schema and then it goes down to the container and HCS is a service that Microsoft started
00:13:33 [W] right when they delivered the first release of Windows containers called host Computer Service that basically acts as a as an overlay or the boundary for connecting to the underlying container Engine with containerd e
00:13:48 [W] The first thing that happened was you decouple the containerd E effort from the kubelet.
00:13:56 [W] So now they can be version independently.
00:13:57 [W] They can be released independently and it gives us a lot of flexibility here and the cri-o.
00:14:18 [W] Schema with Docker HC s V1 schema was only one no supported the V2 schema was experimental while in this case suppose the V2 schema allowing us to advance the vision of Windows containers and also support new
00:14:33 [W] Call update functionality like hyper-v containers in the future.
00:14:38 [W] Looking at our technology Matrix now.
00:14:42 [W] So what does that mean? When we started 1.14 our first release of GA for Windows containers only supported one operating system and that was Windows Server 2000 19 and that was the LTC release the stands for
00:14:56 [W] long-term servicing Channel That's the release of Windows that supported for many years and Microsoft gives you an option to purchase an extended support agreement as well since then we've made the decision as a Sig Windows
00:15:11 [W] Looking to support one LTC release and to SEC releases with every release of kubernative SE C stands for semiannual Channel release and that's a release of Microsoft shapes twice a year and is supported for 18 months
00:15:26 [W] with version 119 we're supporting server 2000 19 are LTC release and then the two SEC releases 1909 and 2004 2004 is the latest and greatest release of Windows if you are more
00:15:41 [W] Formation around the different service information and the different releases of Windows. There's a link at the bottom of this page that you can follow.
00:15:49 [W] Now of the last parts of 119 is some perfect reliability Improvement of heard from users that Windows containers need to execute better.
00:16:07 [W] We need to improve both the stability reliability of heard your feedback move down a lot of advancements in that area.
00:16:16 [W] The first advancement is in queue proxy direct server returned mode. Now we support DSR in Windows that allows you to
00:16:21 [W] Port scaling to a large number of services efficiently.
00:16:26 [W] not only that but they also know our supporting endpoint slices so you can support services with a large number of n points.
00:16:37 [W] So not only can you support a large number of services but now you can also support a large number of end points.
00:16:46 [W] If you are not familiar with them Point slices they kind of act as a source of Truth for Kube proxy when it comes to how to route internal traffic and kubernative. So when you enable and put slices you should see a performance Improvement for servicemeshcon.
00:16:51 [W] Isis with this large number of inputs, like I mentioned then additional performance Beyond networking Today We Gather a lot of the kubelet metrics through the metric server so Prometheus
00:17:06 [W] Can integrate with that and some of those metrics timeout when you have a large number of Parts on Windows node, that's not great.
00:17:18 [W] That's not a great experience for our users.
00:17:22 [W] So now added support to make that better.
00:17:24 [W] So where will have a much improved performance for the cupolas studs and and summary work that we have and also added support or CPU limits are not respected and windows containers. So if I know this over-provision your
00:17:36 [W] limits are going to be respected and more importantly CPU limits are important because when you think of memory on Windows container, there's no protection due to memory pressure on windows.
00:17:52 [W] So when things get process to page when the page to disk then that means you get slow performance.
00:18:00 [W] So the way to bypass that is to use the kubelet reserve and the system reserved capabilities to to basically allocate some of those resources for
00:18:06 [W] Node processes. So our goal here is to use limits user reserves and we're going to honor those in the scheduler with some of this work that we did.
00:18:15 [W] What's going on past 1.19 in our community as you've seen from a road map earlier when I showed all the different releases as a community.
00:18:32 [W] Thing in areas and we take them from alpha to Beta 2 GA and of kind of segmented this area into three areas.
00:18:45 [W] The first one is compute when I keep investing in containerd E where I get that to GA. We're going to support hyper-v isolated containers, like I mentioned earlier and we're also going to support gpus and windows and that was something that barely missed the cut for 1.19.
00:18:52 [W] But rest assured we're gonna deliver with 1.20 what actually actively working on that right now from a deployment lifecycle management qubit DM and class 3 pi r the de facto ways to lifecycle management of kubernative clusters, and you want to get
00:19:08 [W] Windows supporting them to go to a stable releasable state so that you can take advantage of cluster API for provisioning for first defining and then provision a Windows Server
00:19:22 [W] And cluster nodes in kubernative from a story standpoint.
00:19:34 [W] When a promote the CSI work to stable you can add additional storage providers like vsphere and AWS and you're going to light up Valero support so you can take advantage of CSI snapshots so you can backup are recover
00:19:41 [W] Your Cloud native applications running in kubernative and in turn were also going to deprecate some of our installed in three storage plugins in lieu of the CSI support that we're adding.
00:19:55 [W] How can you contribute come join our weekly meetings every every Tuesday at 12:30 instant?
00:20:04 [W] We have all our conversations are recorded.
00:20:06 [W] Come on hobos, right documentation user stories.
00:20:11 [W] If you want to find some bugs to fix and engage with our community who have a project board look for the bugs out. Ugh, this good first issue. Those are usually the ones with the minimal amount of knowledge that you need to know on Windows containers and kubernative to get started and as
00:20:23 [W] Advance your involvement with the community review open PRS create your own peers can become a contributor or even a technical lead.
00:20:33 [W] We really are an open and welcoming community and most importantly we get to work on pretty much every area of kubernative.
00:20:40 [W] So if you get involved in Windows, you can attach storage compute networking security API.
00:20:50 [W] So if you want to learn kubernative and to end sequence, this is one of the few 6 where you can do that if you want to reach us on the left side we have the
00:20:53 [W] The two co-chairs myself and Mark Rossetti and deep the broiler technical it we have slack and GitHub and how you can connect with us.
00:21:04 [W] And then as I said Windows Community were on slack will have a mailing list with our documentation over here.
00:21:15 [W] We have a GitHub getting started guides. If you want to kind of have a One-Stop shop for everything around windows in kubernative.
00:21:21 [W] We have our YouTube playlist with pretty much every recorded meeting. We've had going back three plus years and then our Zoom
00:21:23 [W] Link for our meetings every Tuesday.
00:21:26 [W] Thank you all for attending. This presentation can open it up for Q&A now.
00:21:31 [W] Thank you so much.
00:21:32 [W] Hello everybody.
00:21:42 [W] How are you today?
00:21:43 [W] All right, so Mark, and I would like to thank you for attending our talk.
00:21:56 [W] Thank you for spending time with us. Whether it's morning afternoon or evening depending on the time zone where you are. We're going to start answering some of the questions that are on the QA right now in addition to that be aware that you can find us on slack and towards
00:22:08 [W] End of this presentation the engineer is going to post a message.
00:22:21 [W] Well, it would be but it's going to be on the cncf slag and it's going to be under the to - cubic on - maintainer Channel.
00:22:25 [W] There's a threat for seek windows and and this meeting a Mark and I are going to be there after this talk.
00:22:28 [W] So feel free to interact with us more you can also find us on the sick Windows channel in kubernative. Like like this slide has indicated you can send us an email in our mailing list.
00:22:38 [W] Or you can come to one of our community meeting. So there's lots of ways to engage with us.
00:22:44 [W] So let's get started answering some of these questions.
00:22:46 [W] All right, I'll start from from the earlier one.
00:22:59 [W] So Mark answer the question is can there be Linux as well as Windows machines on the as working?
00:23:01 [W] Not in the same cluster is yes. That is correct.
00:23:03 [W] We support heterogeneous clusters where you can have multiple nodes be aware that the cni-genie use needs to be compatible with both Linux and windows.
00:23:13 [W] So not all cni-genie Lon support both operating systems.
00:23:16 [W] So be aware of that like for example obvious.
00:23:18 [W] Goddess, Kali goddess and tired has but flannel on the hose kid way.
00:23:26 [W] Next question how kubernative understands that this container has to be scheduled on Windows working node.
00:23:35 [W] Any ways that you can do that actually in previous conversations in our documentation?
00:23:46 [W] we talk about the a couple of critical ways that you can do that is basically setting up the operating system and your in your llamo file to say targeted to Windows.
00:23:56 [W] We've also added a new variable that allows you to define the build of Windows that you want the scheduling to happen on so you can Define it there. You can also use the runtime class which is what do we do?
00:24:06 [W] I commend to you can Define it once and use it cluster wide so that all of your deployment can basically Target the runtime class and the runtime class dictates what the scheduling needs to happen and you can also use taint
00:24:19 [W] And colorations where you basically think every Windows node with a specific.
00:24:34 [W] Let's say you can call it Windows Server 2000 for and then you have to add Toleration on your pot in your llamo file to make sure that the land on the Node marketing has two other thing. I covered all of them,
00:24:39 [W] I was just gonna say if you're deploying kind of charts off Helm or other kinds of deployments where you just kind of grab a pretense deployment.
00:24:54 [W] It is important to either look at the deployment or to add Tansen Tyler reasons to your nodes because most kind of Helm charts that we've seen don't restrict the containers that must run on Linux to run on Linux.
00:25:03 [W] So this is just an easy way to help kind of protect yourself from kind of running into some scheduling issues in your clusters.
00:25:09 [W] Absolutely agree.
00:25:13 [W] All right, the next question how will see an I work on Windows machine will work the same as the linotype machine a fundamentally the way the cni-genie work will be pretty similar.
00:25:30 [W] It can have an agent or a pod of or something running on the Windows note.
00:25:32 [W] It's going to connect with Master component of kubernetes as well so that they can actually connect to the API and no one knew pods are being created when they're working. It needs to be networking components of the others in need to be allocated or English snyk strimzi.
00:25:45 [W] such for some of these pods but like I mentioned earlier be aware that not all seeing eyes have a Windows implementation the ones that do more familiar with in our community are our ovhcloud,
00:26:02 [W] And unfair and not all versions of liner are a g level.
00:26:06 [W] Also, if you're interested members of the Windows containerd networking team at from Microsoft have delivered talks Deep dive talks and how container networking works at past Q cons. So I would recommend looking up those videos on
00:26:22 [W] You're interested in the kind of looking under the hood a little bit.
00:26:26 [W] Actually, if he's also published a blog post what understanding the state of containerd working on Windows in kubernative.
00:26:39 [W] So if I can find it really quickly, here's a composited on the unjust as well Mark if you can answer the next question with the monitoring outside if I can find the blog post sure the next question was how our users monitoring with those
00:26:50 [W] As metrics API reporting the same metrics granularity and as possible for as possible for Linux pods.
00:27:00 [W] The answer is mainly yes.
00:27:03 [W] So there was a lot of changes as Michael mentioned in the talk specifically around helping perf for the metrics apis for Windows nodes most of the general metrics, especially those needed for
00:27:15 [W] Operations like Padres on a pot of sailing are the same as Linux.
00:27:26 [W] If you have kind of more specific questions on that, I'd recommend just reaching out on the psych Channel because I don't have those answers up top of my head though.
00:27:30 [W] Okay, and the next question is are the developments for free open source option to use for Network policies on Windows nodes.
00:27:43 [W] I'm actually not sure about that.
00:27:46 [W] Do you know about that Michael?
00:27:48 [W] One second Mark. I got posted the link the blog post that David created on understanding the state of networking.
00:28:01 [W] So yeah, I put it under the question under house in our office and they can read that when I add one more thing to your monitoring and metrics.
00:28:09 [W] We actually did improve a lot of the metrics apis with 119.
00:28:13 [W] So folks are basically using permitted for example monitoring. They're going to see a improve performance on how monitors are monitoring metrics.
00:28:20 [W] And reported though, both of those have great. We could hear other development for a free open source option to use in our policies and windows knows.
00:28:30 [W] Yes Anthea actually with the latest version 0.85. I'm not mistaken support network policies.
00:28:36 [W] It is free.
00:28:37 [W] Fully open source it if anybody's interested they can code to that Community.
00:28:47 [W] There are only two teammates and windows of the point of our policies one is provided ovhcloud.
00:28:49 [W] The one is to enter a leak. Also type has never apologized for the 800 the paid offering the caligo together and wrote the scripture.
00:28:57 [W] All right.
00:29:04 [W] Thank you Michael. The next question is is it impossible for Windows to become Masters nodes in the future at this point?
00:29:18 [W] I would say I think that most of the components required to run masternodes can technically run but it hasn't really been a focus of the community today to get masternodes running or Windows nodes running as Master simply because there's just
00:29:29 [W] Much work to kind of keep an maintain Windows nodes running as agents and that's where kind of the communities Focus has been. If this is something that you're particularly interested in. There's no reason why you wouldn't be able to
00:29:44 [W] During the community and help kind of move that agenda forward.
00:29:48 [W] Yeah, I know.
00:29:51 [W] So one thing to out there that Mendoza month of testing it for the web and required to actually convert from Linux windows and test everything all over again and it's a non-trivial cost to us as kubernative community on top of
00:30:05 [W] There are signal comes through the different components have made even though the language is portable.
00:30:14 [W] It is written in go there Thomas comes from the master components that are running on a Linux node where that security exemption from.
00:30:19 [W] Otherwise, it is a huge effort. If anyone over users or customers are interested in that. Please be vocal about it.
00:30:27 [W] You can start collecting evidence, but this is time for now. This is not any need to have this hero gold around this.
00:30:32 [W] Roth the question about it Michael working with red hat to the window containerd supported in open 50.
00:30:44 [W] I would like to click contact Microsoft privately about that.
00:30:48 [W] You can pick on that from a community standpoint.
00:30:49 [W] Question number 9 how am I cool items in look like in terms of using Windows servers cluster node and containerd images Mark yours and I the only to find the link on lighting as well to put it more quality talk.
00:31:07 [W] I actually yeah, let's post the link.
00:31:13 [W] I'm not super familiar with this right now, or at least not in a way that I can talk about this I think Microsoft but post solve their licensing terms online and we just encourage you to read that and look at that.
00:31:25 [W] Okay, I'll put that if you can take the next question.
00:31:29 [W] yeah, the next question is are there migration tools to help my great legacy apps to Windows containers the answer to that is there are some I know the Microsoft team has been working on a set of containers
00:31:44 [W] That they've all been made available on GitHub to help with things like logging.
00:31:58 [W] I know the way that Windows traditionally just logging is not very conducive for logging in containers or in container orchestration platforms.
00:32:06 [W] And so there are a set of tools that a lot that will you can install and we'll listen to things like your etw events and publish them as text logs, which you can use other kind of container Monitoring Solutions to look at
00:32:14 [W] At that are to get those out.
00:32:19 [W] Are you or any other one? It's Michael.
00:32:21 [W] No, no, I don't know of anything else.
00:32:25 [W] Yeah, let me let me find a link and post that too.
00:32:30 [W] Ok. I'll take the next question.
00:32:40 [W] We're having Kuma knative cluster on VMware. If we have Windows as workloads mCP nginx VMware will work for Windows worker node.
00:32:42 [W] Not everything will work.
00:32:44 [W] I want to be a little bit clearer their sheer volume will work from a story standpoint for persistent volumes. Then from a compute standpoint.
00:32:54 [W] Obviously, it will work but TSI.
00:32:56 [W] And the new work that you're doing in sequence with the PSI beta dot coming out in 1.19 that will not work on VMware yet.
00:33:07 [W] We're working to enable that so there are some caveats there.
00:33:08 [W] I will know work and if your volume is going to persist in volume you can use
00:33:13 [W] Any other questions we have about two minutes or 1 minute left in our session this mayadata, no questions asked them here or come find that on slag and there's no Community meetings.
00:33:48 [W] We have a lot of ways to engage.
00:33:54 [W] This has been a very Lively discussion with over 125 of you that joined today.
00:33:55 [W] Thank you so much.
00:33:58 [W] is gitops such as Argo Keda possible at this time, you know, I love the stopped and ci/cd tools today use the kubernative pi to connect with communities and enable the STD pipelines Windows containers don't
00:34:14 [W] Different on my pipeline standpoint we use the same kubernative p is you can Target the same artifacts and kubenetes for Windows as you can do on Linux.
00:34:28 [W] So there is no reason why gitops wouldn't work as long as they target the kubernative CPI and you should be able to connect those and leverage public and windows containers and
00:34:38 [W] cops on kubernative
00:34:39 [W] the next question the last question here whether some tips or best practice for migrating Legacy applications to containers.
00:34:51 [W] You know, I'm going to do a shameful plug here, but damn world both us and Europe of last year 2019. If you go and connect you to be able to for free download I did a presentation
00:35:07 [W] You search for my name Michael Michael you find it on how on some best practices for migrating Legacy applications to Containers is a one hour long presentation at what about the caveat some things that may work sometimes I mean no work.
00:35:22 [W] um, it's fairly involved conversation may be given this question might be worthwhile for us to actually do a presentation like that in the next cubicle on so Mark and I will take that under advisement, but please go to
00:35:35 [W] It's vmworld.
00:35:45 [W] Look at as a 19-5. My presentation is the one hour long has lots of good content in there or come to one of our community meetings and we can chat more but it's not the big topic.
00:35:49 [W] right, folks q and current condition flat for additional question.
00:35:54 [W] Thank you.
