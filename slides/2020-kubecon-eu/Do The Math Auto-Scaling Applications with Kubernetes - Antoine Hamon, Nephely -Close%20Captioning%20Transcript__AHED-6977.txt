Do The Math: Auto-Scaling Applications with Kubernetes: AHED-6977 - events@cncf.io - Wednesday, August 19, 2020 6:54 AM - 58 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:04:50 [W] To enamel and I'm very pleased to be here for the first we are to a cubicle to talk about how we could use mathematic to better configure what the scanning.
00:06:16 [W] I'm a freelance clock ticked Endeavors. I'm mainly playing on AWS and openstack and I'm currently working for an american-based company named pipe stream as they were both leader.
00:06:32 [W] She's totally this talk is actually out of an article.
00:06:38 [W] I wrote over a year ago.
00:06:42 [W] So I definitely recommend you to check it out. If you need some more details. There's also the link for the web app created that I'm going to introduce later.
00:06:47 [W] It's not quite a surprise that to microservices architecture continue to innovate just after design.
00:06:58 [W] It's easy to manage easy to develop a smaller team is better attitude during the load.
00:07:05 [W] It's easy to create a chiid appointments and easy to manage upgrades, but the game surely won't be the same without kodox trainers such as kubernative as I bring to the table a lot of useful features to manage the lifecycle of those microservices.
00:07:17 [W] He's and obviously one of them is auto scanning.
00:07:21 [W] What a blessing it is to watch your deployments number of replicates for treating all of his day gently sized to the current load, but don't get me wrong Auto scanning is hard enough parameters are involved in the process such as
00:07:38 [W] And maximum number of replicas obscure threshold the thing period could don't delay is etcetera.
00:07:45 [W] So I wanted instead of keeping those parameters to their default value and set the well-known 80% as the upscale threshold.
00:07:56 [W] Would it be possible to find a more mathematical way of saying Zeus parameters?
00:08:00 [W] First we need to set up some goals.
00:08:06 [W] We want to scale up to be fast enough so users.
00:08:08 [W] do not face any error meaning with a given number of running replicas. If you have a rapid loading quiz, we want the running replicas to be able to handle the load until New replicas are created.
00:08:22 [W] We want to minimal number of replicas to be running.
00:08:27 [W] So this is in order to save some bucks and we want the model to be working for every given load.
00:08:31 [W] That's all times down to functioning the upscale and down sketch threshold.
00:08:38 [W] And as you may know what you meant is as a single parameter.
00:08:41 [W] Let's try to translate through the holes into a more mathematical problem as we said we want the window to be able to work for all type of load variation.
00:08:58 [W] should also include a worse case scenario.
00:09:00 [W] Is doing a resource consuming operation within a short period of time.
00:09:16 [W] Let's say you are a cncf a nice trailer about to release.
00:09:19 [W] Skip Conti Kate's and obviously expecting thousands of users buying them within 30 minutes. Let's set some variables.
00:09:29 [W] Let's say we call a new the number of scissors T taught this to short period of time the function value of T the load generated by a single user and the function filter of t0 generated by all users on the system.
00:09:44 [W] We are also going to introduce some hypothesis.
00:09:51 [W] We are going to suppose that the loodse it is evenly distributed across all replicas that your application is stateless.
00:10:00 [W] Meaning that all requests are round-robin across all beckons. So the average request timing is shorter than the kubenetes load check interval and that you are dealing with a large number of users.
00:10:09 [W] And here we dive in you can get your aspirin really in the mathematical World. Whenever you have a large number of events occurring almost at the same time this even distribution follows a
00:10:25 [W] Shame which has the following formula where Nu is the expected value changing you will actually translate the curve on the horizontal axis.
00:10:39 [W] where Sigma is the standard deviation. Meaning how steep is a curve.
00:10:43 [W] And we are dealing here with our first issue because in the mathematical world, if you want to cover all events, you need to cover an interval from minus infinity to plus infinity and that's obviously not computable.
00:10:59 [W] But if you look at the curve, you will notice that 99.7% of all events will occur between minus 3 Sigma, 's and three sigma's so we can cut it close enough to only consider that interval.
00:11:14 [W] Even though we are choosing the interval minus 3 Sigma has two specific months for this simulation.
00:11:25 [W] We are not going to choose the total term to be equal to six sigma's because as you can see on the graph over 95% of all events occurs within the four segments,
00:11:33 [W] So choosing the total time to be equal to six sigma's will add half the time compared to four signals for only 4 percent of users, which is too few.
00:11:48 [W] Addition new equal to 3/4 of the total time.
00:12:00 [W] We now have redefined the problematic into this following sentence.
00:12:08 [W] We are going to calculate the load generated by 99.7% of all users each one of them performing a resource consuming operation, and we're 95.4% of them are doing it within a short period of time
00:12:20 [W] Sigma and Nu within the gaussian distribution gives us that formula.
00:12:27 [W] And we have a second issue here because we're going to need the integral of the question and there are no mathematical formula for integrating e with a put in an exponent.
00:12:40 [W] To work around the second issue.
00:12:45 [W] We're going to use a Riemann sum we man is a German mathematician who has proven that the integral of the function is equal to an infinite sum of infinitely small rectangles.
00:12:57 [W] And then it's going to be very helpful for us because now we can consider that all users within a small rectangles studies their operation at the same time.
00:13:08 [W] I don't want to go into too much details about the calculation that we can now Define the total load function that's following after replacing variables with their current values gives us that results.
00:13:26 [W] Succeeding in having the total load function define the formula involving the number of users and the usual load function.
00:13:37 [W] All that we need to do now is to use a dichotomy algorithm in order to find the highest obscure threshold where no replica ever reach its resource limits all over the worst-case scenario. Okay
00:13:53 [W] Is it would function or that we need to do now is to use a dichotomy algorithm in order to find the highest upscale special where nor Epica ever reach its resource limits
00:13:55 [W] There's one last thing that I need to cover with you before we do the demo and that is how we could create a user load function.
00:14:05 [W] We have to know it's impossible to have a proper mathematical representation of the load but onto a system by a single user and that is all the muscle true.
00:14:21 [W] If you are not running real-time operating system such as Linux and hoses, but I came up with a procedure that is to me close enough to be varied and the idea is following if you have a large number of users
00:14:31 [W] The same task that slightly different time.
00:14:38 [W] You should see the application resource consumption to be pretty much violence.
00:14:42 [W] So all it takes to calculate the impact of a single user is to divide the resource consumption of the application by the number of users.
00:14:48 [W] Calculate average request timing repeat this procedure for old times that you want to include in your user. Scenario. Add some timing and voila.
00:15:02 [W] All right demo time.
00:15:03 [W] Sparta audiences since the demo is pre-recorded.
00:15:07 [W] Everything's gonna be fine.
00:15:08 [W] We will do two simulations for the first one.
00:15:14 [W] Let's say the resource limits is at 1 CPU.
00:15:19 [W] It takes 30 seconds to starts and we have a minimum number of instance of you.
00:15:22 [W] For the user load function, we will consider a user scenario with only two actions.
00:15:31 [W] The first one will be something similar to a user logging that would take around two seconds and it's quite CPU intensive because of the Quick Tag Rafi.
00:15:40 [W] Their users white sometimes and then upload a file that takes a bit longer but is less CPU intensive.
00:15:51 [W] even number of instance of two
00:16:02 [W] For the user load function, we will consider a user scenario with only two actions.
00:16:02 [W] The first one will be something similar to a user logging at would take around two seconds and it's quite cpu-intensive because of the Quick Tag Rafi.
00:16:04 [W] the users weight sometimes
00:16:04 [W] and then upload a file that takes a bit longer but is less CPU intensive.
00:16:04 [W] In order to lower the computer time, we specify to the application.
00:16:06 [W] How long is a user load function? Then we specify our T tote and Nu
00:16:07 [W] in our case ninety-five percent of a hundred thousand users are doing the action within 15 minutes.
00:16:16 [W] Then we choose the orchestrator.
00:16:20 [W] Those are the default values.
00:16:21 [W] And as soon as you made sure that you had a sufficient number of point for the computation we can run the test.
00:16:28 [W] It takes a bit of time actually cut the video so it doesn't take too long here, but it will eventually get you the results.
00:16:38 [W] The first graphql representation of the you to load function the second graphql presentation of the total load function and the last graph gives you the result the orange curve represents the load per instance,
00:16:56 [W] exhausted full values
00:16:57 [W] And as soon as you made sure that you had a sufficient number of point for the computation we can run the test.
00:16:57 [W] It takes a bit of time actually cut the video so it doesn't take too long here, but it will eventually get you the results.
00:16:58 [W] The first graphql representation of the data load function the second graphql intention of the total load function and the last graph gives you the result the orange curve represents the load per instance,
00:17:00 [W] Of represents a number of replicas that are running and ready and the light blue curve represents a number of instances that are not yet ready.
00:17:07 [W] So the upscale structurally that 54.4% which is quite low the maximum number of replicas that are needed to handle. The load is 78 and we have a maximum load per instance as 94.6%
00:17:23 [W] It's a maximum number of red because it's at the are needed to handle the load is 78 and we have a maximum load per instance as 94.6% We are going to change some of those values so we can highlight
00:17:28 [W] We are going to change some of these values so we can highlight the impact they have on the system. We are going to double the application resource limits.
00:17:34 [W] Decrease the application starts duration and increase the minimum number of replicas since the application takes less time to start. We are going to lower the Readiness delay.
00:17:46 [W] So, let's see what impact this change had first.
00:18:01 [W] We can notice that the upscale threshold as a much higher and acceptable value second.
00:18:05 [W] We see something rather interesting.
00:18:10 [W] We're doubling the resource limit on the application divided by moles and to the maximum number of replicas needed for the simulation as it was previously 78 and it's now 27
00:18:21 [W] I will finish this presentation by giving you some advices on how you could improve the Obscure threshold value.
00:18:30 [W] First is by far the most important also one that has the most impact your application startup time should be very fast the faster the better.
00:18:41 [W] So web creation do not as of yet separate resource requests from resource limits.
00:18:54 [W] And as you may know Community is calculate the auto scaling against the resource requests.
00:18:56 [W] First we can notice that the upscale threshold has a much higher and acceptable value.
00:18:59 [W] Second we see something rather interesting.
00:18:59 [W] We're doubling the resource limit on the application divided by moles and to the maximum number of replicas needed for the simulation as it was previously 78 and it's now 27.
00:19:01 [W] I will finish this presentation by giving you some advices on how you could improve the upscale structured value.
00:19:01 [W] First is by far the most important also one that has the most impact your application startup time should be very fast the faster the better so web application. Do not as of yet separate
00:19:06 [W] Don't you can also increase the minimum number of replicas and this is because the highest load increase per replicas occurs at the beginning of the simulation.
00:19:09 [W] And you can also increase the resource limitation on your application.
00:19:13 [W] That's it for me.
00:19:20 [W] If you have any question, I will be very pleased to answer you.
00:19:21 [W] Thank you guys.
00:19:22 [W] Okay guys if you have any.
00:19:35 [W] Someone asked me for the link and actually showing it right now on the the Q&A window.
00:19:46 [W] So I have someone asked me if I if I ever try to use this mode function.
00:20:30 [W] No, I didn't I only use the Goshen.
00:20:35 [W] And two other two other function, which is that collinear and and the other one is static.
00:20:43 [W] So I'm also ask if that you have a smart algorithm to fight a breaching pod requests.
00:21:10 [W] And limit parameters so that is there is an interesting question because indeed CC application do not separate limits from requests and it considers that
00:21:26 [W] I'm at you thinking about somebody.
00:21:31 [W] Those getting is calculated again.
00:21:47 [W] This is e c requests. It will be it will indeed lower the bar higher the Obscure threshold because it will give you more time if you increase the limit.
00:21:52 [W] It's not yet part of the application.
00:21:57 [W] I will put differently post to see slides on the on my Twitter so you will be able to find it and I think there is a way I can actually send them on this on the on the second conference somewhere.
00:22:26 [W] I have a question about how you recommend a party will work with the new HP app Behavior out of images 8 1.18.
00:22:58 [W] 18. I actually haven't secured take a look at even take a look at it as of yet, but they will definitely follow up on this letter.
00:23:06 [W] I also have another question about to really possible to apply to Cluster scaling purposes.
00:23:20 [W] Is that also something that the simulation is missing?
00:23:24 [W] You see when you create 27 or 78 new replicas of an application at some point you will face resource will have resource limits or resubmitting within your communities closer and that will require
00:23:40 [W] Seven or 78 new replicas of an application at some point you will face resource will have resource limits or which is missing within your comments culture and that will require standing up the
00:23:43 [W] the number of nodes
00:23:44 [W] that other team not taking into account as of today will be possible to apply it to the tester scaling purpose.
00:23:54 [W] For the number of nodes, I guess it will.
00:23:59 [W] Yes, it's beyond a bicycle.
00:24:04 [W] I guess it will possible but the application is application definite designed for that purpose because obviously all parameters are very different.
00:24:17 [W] Julia asked the puzzling thing was not mentioned directed first part of the presentation.
00:24:35 [W] How does that come into play into the simulation?
00:24:42 [W] The first particle presentation is just to Define how we could simulate the user load of a load induced by your group of users onto the system.
00:24:48 [W] And the application transcribe Zeus load.
00:24:52 [W] to the to the birds
00:24:55 [W] So it's only only the application take cares about about the here time delay, but the Readiness delay, but we as a perspective just to to have a mathematical representation of
00:25:11 [W] the loads on the system
00:25:14 [W] I'm asked if I think that this approach about the ceiling will perform better than predictive analysis.
00:25:39 [W] I don't think so.
00:25:45 [W] My my Approach was to think about the worst case scenario.
00:25:50 [W] And because this is something that you actually cannot predict as I said if you are here cncf any story and about to release some tickets.
00:25:54 [W] I mean, you're pretty cute. Anyway, I won't do anything. I'm one predict anything because it's not regular or this is something new.
00:26:03 [W] And what this is, is that the calculation?
00:26:08 [W] I'm asked what I really recommend is when I could say Microsoft based architecture deployed on kubenetes using dot Network.
00:26:43 [W] I'm definitely not working with Microsoft.
00:26:44 [W] So I'm very much familiar with Microsoft ecosystem story.
00:26:44 [W] I'm asked how did networking production?
00:26:53 [W] Against the the whole idea about this simulation is to create like a worst-case scenario where you're actually sure that we Stephen given ever given load variation including the including. This were casting I use at your auto scanning going to work and you want and your
00:27:08 [W] Every given load variation including the including this work getting I use at your auto scanning going to work and you want and your users won't face any error.
00:27:10 [W] They just a simulation it basically helps you to configure all those parameters.
00:27:18 [W] have like a correct, which correct figures too.
00:27:21 [W] Your production system affect any error or you just gonna production system affecting air?
00:27:28 [W] We Clash night niak nice. Very Spire of Mexican state your name.
00:28:25 [W] is asking.
00:28:26 [W] How do I fix a number of votes per nodes?
00:28:37 [W] Rajesh night and Yak night Thursday April of next Wednesday to me. He's asking
00:28:41 [W] How do I fix the number of code per nodes?
00:28:42 [W] For example at any point of time it will be ideal to have 20 points and I wouldn't want to schedule yet 0:20 because of optimizing and I'm sure to understand the question if if you want to accommodate or give it more details, please.
00:28:47 [W] The sum total asking you I have any tea for two for apps that takes longer to test out so you have maps that takes five minutes to get ready and that's a very big issue and I keep thinking whether it's an issue with my current company why take some
00:29:44 [W] Welcome to choose asking you.
00:29:47 [W] I have any tea for two for obstetrics longer to test out so you have some apps that take five minutes to get ready.
00:29:48 [W] And that's a very big issue and actually taking credit an issue with my current company like take some application up to 50 minutes of stuff.
00:29:49 [W] He says that I can give you it to get everything that you can do to minimize that.
00:29:56 [W] That's a set of time.
00:30:02 [W] We actually thinking about reorganizing a we are considering a lot of things to get this under Fitness and we're under the thinnest.
00:30:07 [W] But besides besides besides that no, I don't have any other advice instead of time is definitely the biggest.
00:30:17 [W] Each other two different is the biggest impact on auto scaling by far.
00:30:24 [W] So search because well is asking do I have a I have a I tried the formula with custom metrics and that's actually the whole idea about discrimination is metric agnostic. You can do this Dimension with any type of Matrix.
00:30:44 [W] And that's basically Works.
00:30:50 [W] Obviously the way you calculate your user load function going to be tied to the Matrix you're going to use.
00:30:52 [W] but the mathematical
00:30:59 [W] not a presentation, but the medical procedure is different is essential.
00:31:06 [W] Are you open to men is asking what is the load function?
00:31:26 [W] And what does it represent? So we are talking about two loads function one is a total load function and one is to use a lot of action.
00:31:32 [W] Who paid you to make it a little creepier?
00:31:39 [W] The user long should function is a which represents the load put onto the system by a single user and the total load function is the zero loodse input by all users onto a system and
00:31:51 [W] Magical formula is about to Total load function and how we could create a formula to represent these.
00:31:58 [W] Research actually, give some more details about this question is saying if my requirement is to have a fixed number of codes for note. What is the best practice to configure auto-scaling?
00:32:43 [W] I actually don't know how you could do it with the same with this number for the standards the whole number of replicas so we obviously have a different number of pulse panels.
00:33:00 [W] I'm done with all this question.
00:33:31 [W] if you guys have other questions that you ask
00:33:35 [W] I think I went over all the questions.
00:33:58 [W] I'm good. Definitely gonna publish slides and the link either on this Q&A or
00:34:05 [W] That's it to come Chef boulders.
00:34:08 [W] Feel free to if you free to reach out to me on Twitter.
00:34:15 [W] And I will definitely answer you guys there.
00:34:18 [W] I have one last question.
00:34:34 [W] Do you have example of the JavaScript expression the application is actually hosted on tiptoe on GitHub site and is available to the public so you can definitely hear the click on it and play with it as you actually
00:34:45 [W] And there was different amounts of the garter.
00:34:52 [W] I have one last question.
00:34:53 [W] Do you have example of the JavaScript function the application is actually hosted on keep Telco on GitHub.
00:34:54 [W] site and is available to the public so you can definitely a secular clone it and play with it as you as you like.
00:34:55 [W] I think her synchronous operation.
00:35:18 [W] Thank you very much guys again if you want to reach out to me these Dunes here.
00:35:22 [W] He on the Twitter. I will be happy to answer you.
