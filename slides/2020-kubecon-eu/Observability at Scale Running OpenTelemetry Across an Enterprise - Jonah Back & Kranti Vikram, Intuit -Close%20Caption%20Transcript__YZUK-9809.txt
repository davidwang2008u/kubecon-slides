Observability at Scale: Running OpenTelemetry Across an Enterprise: YZUK-9809 - events@cncf.io - Tuesday, August 18, 2020 12:33 PM - 3 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:31 [W] Hello, everyone.
00:00:35 [W] Good evening.
00:00:37 [W] My name is Jonah back.
00:00:39 [W] I'm a principal software engineer at into it and presenting to with me. Today is County Vikram a staff software engineer into it.
00:00:45 [W] And today we're going to be talking about their ability at scale running opentelemetry across the Enterprise a look at into its journey of adopting opentelemetry to power our distribute racing and other observability Solutions.
00:00:58 [W] First let's take a look at the agenda for today's talk.
00:01:02 [W] First we're going to be talking about the journey into a Tad's towards adopting opentelemetry and distribute racing.
00:01:14 [W] You know, we're really going to talk about kind of the state. We were in about 18 to 24 months ago the problems that are engineer's and our on-call Engineers were facing the solutions that they were using.
00:01:23 [W] You know, we're really going to talk about kind of the state. We were in about 18 to 24 months ago the problems that our engineer is and our on-call Engineers were facing the solutions that they were using and
00:01:25 [W] You how adopting tools Like opentelemetry Jaeger and other vendor tools has really enabled into it to solve some of those problems from there.
00:01:37 [W] We'll go into collection instrumentation of Trace data.
00:01:41 [W] So we'll talk about how we've managed to collect all of the data from the service is running it into it and how we instrumented those services in a pretty easy way so that they could collect Trace data then we'll talk about some of the
00:01:53 [W] And how we instrumented those services in a pretty easy way so that they could collect race data.
00:01:55 [W] Then we'll talk about some of the processors we've built on top of opentelemetry specifically how we are able to extract metrics from our Trace data.
00:02:05 [W] And finally, we'll talk about tracings role in reducing mttr 22d that mean time to repair and meantime to detect for our services.
00:02:10 [W] Okay. So first let's look at kind of the state into it within 18 to 24 months ago.
00:02:17 [W] We were in a state 18 to 24 months ago.
00:02:20 [W] We're not too far from where we are today, but we had Services running in a in a huge polyglot environment, you know, we had teams running services in kubernative.
00:02:33 [W] He's in AWS.
00:02:40 [W] We had teams running just on bare metal ec2 instances. We had teams running serverless functions.
00:02:41 [W] We had teams running in an on-prem Data Center and we had a variety of tools that these services and teens were interacting with you know, we had an issue.
00:02:48 [W] Servicemeshcon dynamodb resources already asked resources really a really truly polyglot stack and our Engineers.
00:03:00 [W] Well this give them a lot of flexibility.
00:03:05 [W] We started to notice some pretty common problems across teams.
