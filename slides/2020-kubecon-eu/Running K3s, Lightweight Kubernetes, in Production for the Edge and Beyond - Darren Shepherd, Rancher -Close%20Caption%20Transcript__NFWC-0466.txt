Running K3s, Lightweight Kubernetes, in Production for the Edge and Beyond: NFWC-0466 - events@cncf.io - Tuesday, August 18, 2020 11:33 AM - 64 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:06:35 [W] All right.
00:06:38 [W] Welcome everyone. This is a
00:06:40 [W] Running k3s lightweight kubernative Xin production for the end.
00:11:50 [W] All right.
00:11:53 [W] Welcome everyone.
00:11:56 [W] This is a running k3s lightweight kubernative Xin production for the edge and Beyond sorry, it's really bad title.
00:12:06 [W] I'm not exactly sure what I was thinking when I proposed that one.
00:12:08 [W] But yeah kind of excited to be doing this.
00:12:11 [W] It's a little awkward.
00:12:18 [W] I'm just going to like just go like one straight cut like nobody know whatever try to keep this authentic.
00:12:21 [W] So I'll probably say some stupid things.
00:12:21 [W] Should be fun.
00:12:26 [W] Welcome to my home office.
00:12:30 [W] running k3s lightweight kubernative Xin production for the
00:12:34 [W] All right.
00:12:34 [W] Welcome everyone.
00:12:35 [W] This is a running k3s lightweight kubernative is in production for the edge and Beyond sorry, it's really bad title.
00:12:36 [W] I'm not exactly sure what I was thinking when I proposed that one.
00:12:36 [W] But yeah kind of excited to be doing this.
00:12:36 [W] It's a little awkward. I'm just going to like just go like one straight cut like nobody know whatever try to keep this authentic.
00:12:38 [W] So I'll probably say some stupid things.
00:12:39 [W] Should be fun.
00:12:42 [W] Welcome to my home office.
00:12:42 [W] You might be thinking to yourself like that kind of looks like a closet.
00:12:42 [W] I'd like to refer you to sign. My daughter made. It says this is my office.
00:12:43 [W] So it's clearly not a closet.
00:12:43 [W] This is my home office. All right, so let's get going.
00:12:43 [W] Let's go to the first slide here.
00:12:48 [W] So just want to do on our start off and do a quick overview of k3s.
00:12:49 [W] I mean, there's only 25 minutes. So it's I can't go super deep.
00:12:51 [W] Really anything I did a talk on k3s.
00:12:55 [W] UConn North America in 2019.
00:13:04 [W] That was the last coupon. So, you know that was roughly three years ago or something.
00:13:14 [W] So I did talk on k3s out there that was pretty much a deep dive into what k3s is so I really refer you to that talk and you'll get a lot of the technical details of what k3s is I'm just going to go over just a high-level.
00:13:21 [W] kind of you understand what the goals are and everything and talk about some pointers about about the project.
00:13:25 [W] And then specifically what this talk is.
00:13:33 [W] I'm going to go into these three use cases and these are use cases where k3s kind of shines and people have had good success running k3s in these different things and just you know, kind of plan on how people are doing this.
00:13:42 [W] You know, what are the I don't know what a kind of pros and cons are conscious or whatever.
00:13:47 [W] So we'll talk about Edge app cluster or application clusters.
00:13:53 [W] I'll explain that more when we get to it and then kind of how people are fitting k3s in the pipeline.
00:13:55 [W] Okay. So before I get started just a little bit about me.
00:14:00 [W] Is my office so it's clearly not a closet.
00:14:04 [W] This is my home office.
00:14:04 [W] All right, so let's get going.
00:14:05 [W] Let's go to the first slide here.
00:14:05 [W] So just want to do on our start off and do a quick overview of k3s.
00:14:05 [W] I mean, there's only 25 minutes.
00:14:06 [W] So it's I can't go super deep on really anything.
00:14:06 [W] I did a talk on k3s.
00:14:06 [W] Que con North America by 2019 that was the last coupon. So, you know that was roughly three years ago or something.
00:14:08 [W] So I did talk on k3s out there. That was pretty much a deep dive into what k3s is so I really refer you to that talk and you'll get a lot of the technical details of what k3s is I'm just going to go over just a high-level just kind of understand what
00:14:12 [W] The cloud on Twitter if you ever want to get a hold of me or talk to me or anything Twitter is really the only thing I've ever really respond to so you can DM me there.
00:14:17 [W] That's totally fine.
00:14:18 [W] Or you can follow me.
00:14:20 [W] I just complained about everything.
00:14:25 [W] So basically I'm creating k3s and some other Rancher projects but k3s kind of like my that's kind of like my baby or something.
00:14:32 [W] But basically I've been doing caught over station for quite a while. So
00:14:34 [W] Before containers it was like virtual machines and stuff is Cossack openstack that kind of world and then before that different forms of bare metal and virtualization and stuff like that.
00:14:49 [W] Okay.
00:14:56 [W] So one thing I want to call out is as of as of as of when this session has been recorded or doesn't make sense as of today my time, not your time. We just k3s was just
00:15:04 [W] Loaded through to be accepted as a cncf Sandbox project.
00:15:10 [W] So we are going through that process of getting k3s into cncf as a Sandbox project and then you know as quickly as you can will graduate through we're really excited about this.
00:15:23 [W] I mean k3s, it is really not that old of a project.
00:15:26 [W] It's only like, I don't know year and a half or so.
00:15:27 [W] It's less than two years old, but it's growing so fast.
00:15:32 [W] going so many users. This is just kind of the next logical step.
00:15:34 [W] Of moving it to a foundation trying to get more collaboration from more people in the industry.
00:15:41 [W] We are going through that process of getting k3s into cncf as a Sandbox project and then you know as quickly as we can and will graduate through we're really excited about this.
00:15:44 [W] I mean k3s it is really not that old of a project.
00:15:44 [W] It's only like I know you're and a half or so it's less than two years old, but it's growing so fast.
00:15:45 [W] It's going so many users.
00:15:45 [W] This is just kind of the next logical step of moving it to a foundation trying to get more collaboration from more people in.
00:15:46 [W] The industry it's just kind of a win-win situation.
00:15:47 [W] So we're really excited about that.
00:15:48 [W] Just you know, kind of like our little project has grown up and do something really quite big and its really used by quite a quite a few people and lots lots.
00:15:53 [W] I mean, it's quite amazing. So I'm pretty excited about that.
00:15:56 [W] okay, so let's talk about first what is k3s, so it's lightweight kubernative that's like a primary purpose most of the decisions and stuff that we do like what we do in kubernative right components we package or
00:16:11 [W] I mean, it's quite amazing. So I'm pretty excited about that.
00:16:12 [W] Okay, so let's talk about first what is k3s, so it's lightweight kubernative.
00:16:12 [W] that's like a primary purpose most of the decisions and stuff that we do like what we do in kubernative right components we package or what would like, you know, the approaches we take is really focused on a lightweight resource-constrained environment.
00:16:19 [W] You know tend to pick lighter weight components or you know, maybe they're ones that are scale massively fire something because that's not our use case.
00:16:33 [W] So we do focus in on this. So the binary is very small like k3s spectres is a single binary the memory size is you know, the kind of like the initial memory footprint of k3s is probably like half the size of kubernative in general you can
00:16:42 [W] You just like run k3s versus like kind kind has like more of the traditional Upstream model running everything, you know, it's going to take up like twice as much memory.
00:16:56 [W] This is just the way we package it and stuff basically k3s is perfect for the edge.
00:17:02 [W] It really lines up really well with the edges cases, but really in practice, it's used just about everywhere.
00:17:10 [W] It's like it's really super popular like in Dev and test it's taking up a lot in those areas, but also people are even running at chronosphere.
00:17:13 [W] Cloud data center. A lot of just random use cases that like kind of fill in gaps that the kind of traditional instana finds call anything kubernative strategical this point, but like but just kind of like the cloud data center model that that's
00:17:28 [W] Or kubernative shined k3s find different use cases that by filling gaps there.
00:17:35 [W] What kind of the things that is really resonate with a lot of people's kind of like this idea of like low cognitive load.
00:17:42 [W] It's like it's just easy to run k3s.
00:17:44 [W] You don't have to think a lot about it.
00:17:46 [W] And that's one of the reasons I think why it's caught on so so quickly k3s is designed for production.
00:17:55 [W] This is a very important thing is like what sets it apart from a lot of other like simple small kubernative projects this from the very beginning was always targeted for production. This is not a toy it is a fun toy, but but it's but it is
00:18:05 [W] It is it is designed for production. Like it's secure, you know, we do Patrick like we track see the ease and security issues and you know, we're serious about all this so we have like real customers and and actually like very
00:18:20 [W] Clouds or whatever run on can you know, they're running k3s.
00:18:29 [W] So because of that it's fully cncf certified.
00:18:38 [W] We pass the conformance tests. We do that all of our releases like every major minor releases their always certified in past the conformance tests for everything.
00:18:40 [W] It's everything secure by default, you know, as best as we can.
00:18:44 [W] I think we do a pretty good job there.
00:18:47 [W] There's any issues there's no security disclosures and stuff like that too. You know, we'll fix that. It's important to us.
00:18:51 [W] But we do our best to like, you know, it's like all the TLs is proper sentence properly set up by default, you know, like at rest encryption.
00:19:01 [W] I think we even do that by default and things like that.
00:19:05 [W] So in general we just try to follow like best practices, you know. So again, that's kind of hard like the low cognitive load is like it should just kind of work what we think is the best approach for lightweight kubernative.
00:19:16 [W] So because we kind of narrow in on a certain use case we can kind of make a lot of choices for the user ahead of time.
00:19:21 [W] Like yeah, you kind of want to work this way.
00:19:30 [W] And so I default it does kind of the right thing for a lot of you know deployments in this in the realm of work a theorists. It's the last thing is it is a kubernative distribution.
00:19:35 [W] That's like fundamentally what it is.
00:19:39 [W] So k3s has no goal of like becoming something else like larger or it's like it's a like the intention is just to give you a kubernative distribution.
00:19:50 [W] So it is very opinionated. We do things a certain way, which is great.
00:19:59 [W] Like if you don't like the opinion, there's plenty of the distributions out there. In fact, like Rancher Labs company, you know my company wherever we have two more distributions. You can pick up if you want.
00:20:11 [W] It is considered like it's like complete like the idea is like when you turn it on you get pretty much a fully functioning clusters.
00:20:17 [W] So it has like all the network network policy Ingress storage like everything just kind of like all the kubernative apis just
00:20:21 [W] work out of the box again kind of optimize for our use case.
00:20:26 [W] And we're just very very focused on Simplicity.
00:20:31 [W] Okay. So these are some random points because as we talk about different use cases, I want to call out like
00:20:39 [W] You know, it's like I'm just going to talk about a couple of use cases that that we're k3s is kind of shiny or whatever. But but there's a lot of other things like random things that you can be doing.
00:20:55 [W] And so and the reason why some of these are some little things that we've done with k3s of why it kind of like to surgery Sparks people's imagination of like solutions that could solve with k3s.
00:21:05 [W] So one of the things is like, it's just it's really really really easy to run is just a single binary. You just copied onto a server we even have a little curls
00:21:10 [W] And then if you want a second one, you just run k3s agent on another machine and you use a token as kind of a shared secret between the two to set up the certificates and all that.
00:21:34 [W] And then that's that's basically it. So it's just super super easy to run and like because of that it kind of like removes that barrier of as like, well it would be really cool if we had kubernative his but it's just too much effort.
00:21:46 [W] It's like well no like for these use cases you can have it for example, okay. So not only is it really simple to install?
00:21:51 [W] Run is really easy to bundle applications with it.
00:21:56 [W] This is a couple little features that we added to k3s that just make it that much easier.
00:22:01 [W] So there's a special manifest directory that if you put anything in that directory, it just gets loaded.
00:22:09 [W] So if you're you know, more kubernative Savvy or extra Revenue might know about poddisruptionbudgets pod static Padma and manifest folder for the kubelet. So works very similar to that where like the kubelet would look for Padma manifests in a directory and this automatically start them.
00:22:20 [W] them. So this is like anything you put
00:22:21 [W] That directory we're going to load it into kubernative.
00:22:29 [W] So that means that if you want to package your application, like let's say like you want to build like an image, you know, because you're going to put this on a device like that.
00:22:35 [W] You just have to put some manifests in a directory and then put the k3s by knative there and then on Startup Builders deploy the application for you, like so like know much more Automation and stuff.
00:22:49 [W] Cubelet some works very similar to that where like the kubelet would look for Padma manifests in a directory and this automatically start them.
00:22:51 [W] So this is like anything you put into that directory.
00:22:51 [W] We're going to load it into kubernative.
00:22:53 [W] So that means that if you want to package your application, like let's say like you want to build like an image, you know, because you're going to put this on a device or some like that you just have to put some manifests in a directory and then put the k3s by needs are and then on Startup they'll just deploy the application
00:22:54 [W] So you can then put images like any oci or Docker image tarball.
00:22:59 [W] So there's an O'Shea format and a doctor format, but will take either format. You just put the tar ball into that directory on Startup. Will then just pick the like just a what will load those basically into containerd e
00:23:09 [W] So those protecting?
00:23:14 [W] So with those two things like you can kind of just packaged up an application really easy for like fully air-gapped and everything.
00:23:27 [W] There's also little hooks in the image directory of had a pre pull things on starts like they're not pull. Dynamically.
00:23:32 [W] I didn't want to call it just in general like k3s does not really tried to address a lot of the when you talk about Edge and stuff.
00:23:37 [W] We don't try to address the distribution of images that much kind of look at that as a slightly different problem. So if there's gonna be any questions about like a deal
00:23:45 [W] Optimized image delivering some like that k3s is not really focused in the area right now, but you know just ran up there. So the last thing is we have a built-in type in k3s for a Helm chart.
00:23:59 [W] So we're like we have a built-in controller like a Helm controller.
00:24:02 [W] like it's a separate project from from Rancher. It's a very simple Helm controller very similar to like, let's say the one from weaveworks, which is actually more popular within the community than than ours. But this one is very simple that we get embedded into k3s.
00:24:14 [W] Really focused in the area right now, but you know just ran up there.
00:24:25 [W] So the last thing is we have a built-in type in k3s for a Helm chart.
00:24:26 [W] So we're like we have a built-in controller like a Helm controller.
00:24:26 [W] It's like it's a separate project from from Rancher.
00:24:28 [W] It's a very simple Helm controller very similar to like, let's say the one from weaveworks, which is actually more popular within the community than than ours. But this one is very simple that we get embedded into k3s and this one so,
00:24:29 [W] It's like since we can deploy any manifest and then your manifest describe describes a home chart.
00:24:33 [W] It's really simple to get Helm charts into their to so you'll have to run like tiller if you were doing Helm to which hopefully nobody's doing this point anymore or or you can yeah, so you'll have to be running out like Helm the command line
00:24:37 [W] We're doing Helm to which hopefully nobody's doing it this one anymore or or you can so you don't have to be running help like Helm the command line and you know doing all that setting up repo and bowling and are updating all that
00:24:40 [W] okay, so other thing about this is basically it's like when you look at when you look at kubernative, he's like really your biggest operational overhead actually is at CD
00:24:56 [W] Kubernative he's like really your biggest operational overhead actually is at CD in it's in it's not like there's anything wrong with that CD.
00:25:00 [W] It's just the idea of running a persistent system and a corn-based persistent system like that. You know, you have to worry about losing Quorum and and stuff like that.
00:25:08 [W] k3s introduces other options for the data store because we recognize like that's the biggest operational issue or headache of running k3s is running at CD so we support
00:25:20 [W] SQL Lite embedded MySQL and postgres for an external database SQL server and Oracle are coming soon. Like those are I think there's PRS out there for those maybe by the time you hear this they've been merged but like you can just get a manage DB.
00:25:35 [W] That's like one of the biggest reasons people think like, oh, why is like my SQL better than at CD and it's really not bad.
00:25:46 [W] It's like it's not comparing like that's actually like apples and oranges are two different things the whole point of like why you might want to go with like MySQL and postgres.
00:25:52 [W] You can very easily just by it and not have to worry about it.
00:25:56 [W] So like removes almost all the operational concerns of running a cluster given that we also handle the security on that stuff.
00:26:03 [W] And so this in general is enabled by this component. It's actually a separate component called componentconfig.
00:26:06 [W] Fine and you can use this actually with any kubernetes cluster doesn't have to be k3s.
00:26:12 [W] Like you're doing Cube ADM. You can just add Etsy like you could add my SQL support to a cube ATM cluster using kind so but it's just k3s embeds that directly in but it does is like a separate project.
00:26:25 [W] Supporting all these kind of traditional or relational databases.
00:26:32 [W] We also still do regular CD.
00:26:32 [W] It's just kubernative. So you can do normal at CD. You can do your traditional external set up like that's not fun and that kind of stinks to run on the edge.
00:26:46 [W] Then there's another option and this is one we before had a solution based on DQ light ran into some issues with that mostly I mean, there's nothing really wrong with TQ light is just more of those two made a lot more sense to go that CD route.
00:26:54 [W] And so the last option we have here.
00:26:56 [W] Here is running at CD embedded withinside of k3s so you can just run like three k3s servers and they just join the NCD cluster and k3s kind of manages itself.
00:27:11 [W] So it's more like Docker swarm thing ones run that it's a very very simple setup that we just put on to master in k3s in the middle of the sea, July and
00:27:21 [W] A sometime this year probably like October time frame.
00:27:25 [W] Okay.
00:27:29 [W] Okay. So let's get into Edge edges like the most popular use case.
00:27:31 [W] I guess it's kind of them actually is not really the most popular.
00:27:39 [W] It's like the most popular one that like people kind of associate with k3s. But in fact, I think actually the most popular thing for k3s probably test Dev and test environments.
00:27:50 [W] But when I talk about Edge, what is it that I mean, it's really what I mean is is not like iot devices and he's really really tiny devices like that's too much right now.
00:28:01 [W] now. So we're looking at fairly powerful small device.
00:28:02 [W] So minimum 1 gigabyte memory.
00:28:08 [W] So this is kind of like in your Raspberry Pi realm going up, you know, like some really great devices is like the the oh crap.
00:28:17 [W] What is it that Jetson Nano the in video 1 it's really powerful small device has GPU built-in. Like that's a perfect use case for k3s.
00:28:26 [W] So we're looking at smaller devices but fairly still fairly powerful like we can't go super super small.
00:28:32 [W] You know, I can kind of tease we have another project we're going to start that's like if if it would kind of be like the K1 s like we haven't even like lighter version that's going to Target more like 256 megabytes and really really
00:28:47 [W] But I was going to tease that.
00:28:56 [W] Okay. So this type of use cases were talking about is like retail Branch Factory Planes Trains automobiles wind turbine set-top boxes drive through menus your refrigerator.
00:29:03 [W] Most likely your coffee maker It's Like These Arm computers or even in-toto computers are in so many places and yeah, I mean over the last you know year or so since k3s Phenom just kind of talk to tons and tons of companies.
00:29:17 [W] They're just looking.
00:29:18 [W] at modernizing all these these environments and so it's just I don't know it seems like there's almost I don't know if this is real thing, but it but it but it sounds like there's there's kind of much more computers out there that are not Cloud as much as like my history and past has been
00:29:33 [W] These environments and so it's just I don't know it seems like there's almost I don't know if this is real thing, but it but it but it sounds like there's there's kind of much more computers out there that are not Cloud as much as like my history and past has been focused
00:29:35 [W] SoundCloud there's so much out there. That's not Cloud.
00:29:38 [W] It's really interesting.
00:29:41 [W] But basically like why are people doing this one of the one of the things like the really driving factors is that what people are deploying on the edge is getting more complicated like the applications are some more sophisticated
00:29:53 [W] like open source, you know, they're doing data analytics to using like, you know, different data platforms or tensorflow or insult like they're starting back the software they're starting to have to deploy is getting a lot harder like so
00:30:09 [W] Different data platforms or tensorflow or in-toto like The Shining like the software they're starting to have to deploy is getting a lot harder like so they kind of have to up their skills in how they manage software at the edge of they want to put all this compute out
00:30:16 [W] Have to up their skills in how they manage software at the edge of they want to put all this compute out there. And so kubernative just brings a nice consistency and approach that, you know is already proven in clouded and of Center so it's like how do
00:30:25 [W] How do I get like that efficiency and that Simplicity Simplicity I guess of deploying to the cloud and data center with that kubernative brings.
00:30:35 [W] Like how do I do that? Same thing on the edge?
00:30:37 [W] And so that's really that's really what it is.
00:30:43 [W] It's just making a lot easier to manage these complex software as it's kind of working. You know, it's just kind of grown.
00:30:50 [W] think one of the interesting is like the wind turbine use case like we work with one of the largest wind turbine manufacturers and they practically run like old data center in those things. Well, those things aren't very small. Those turbines are huge.
00:30:56 [W] But it's like the amount of computing power has all those kind of crazy.
00:31:06 [W] Okay. So when we talk about these use cases a lot of time mostly what we're dealing with is like one two or three nodes, so they kind of separating like the one node clusters will be an embedded SQL
00:31:14 [W] Stirs will be using an external data store.
00:31:20 [W] We're looking at doing active passive failover type solution.
00:31:25 [W] And then the three Node 1 is the embedded at CD but that one is like still experimental. A lot of people right now are getting by with really if they want three nodes. They do a single Master with with two or three worker
00:31:35 [W] Until we get like the full the full embedded at CD working like, you know seamlessly, but just in general like these Solutions just have lots and lots and lots of clusters.
00:31:47 [W] And so there's a real fundamental difference between running like one cluster with tons of nodes and a lot of little clusters. It completely changes your perspective on how you deal with it.
00:32:01 [W] we found is a lot of people kind of resonates better to do the a lot of small clusters because it looks a lot more like a configuration management from problem then kind of
00:32:09 [W] I can abstraction Federation type problem. And so like the approach that we've seen is it Maps really? Well, I'll get into this a maths really well to get up.
00:32:19 [W] So I'll talk about in just a second.
00:32:21 [W] So in terms of edge basically don't go overboard don't use like tons of features of kubernative first like oops, let me go through these things up like basically the it's kind of like kubernative
00:32:34 [W] Meyer over the underlying resources so that like it's scalable and pluggable and all this stuff. But when you start getting into Edge, it's like, you know exactly what the resources you have.
00:32:46 [W] You have three servers there this big that this much CPU.
00:32:49 [W] I'm running these applications.
00:32:52 [W] It's fairly static in terms of what the workload is. I mean you want to be dynamic and updating it but it's kind of static and what you put there so the way you plan these deployments is often very static. It's like you don't need like you can just use host path for persistence that makes it
00:33:05 [W] a really nice because it effectively makes kubernative stateless.
00:33:18 [W] If you can make kubernative stateless set of your wife around Wipeout kubernative and just start it again and a redeploys the Manifest and it comes back up and everything's happy. Then that's a really simple thing to operationalize.
00:33:23 [W] So you plan on the deployment slightly different to like exploit the underlying Hardware because you know exactly what it is and also a lot of times your you care because there's gpus and Hardware devices you need to talk to so
00:33:34 [W] Like run this kind of perfectly abstracted pattern or something that kubernative would kind of you normally do like in the cloud.
00:33:50 [W] So that's where you see like doing very explicit node scheduling or or even just Damon sets Damon sets work really well a lot of times because it's just like will run the same thing all three nodes. I only have three nodes and I want the same thing on all of them.
00:33:58 [W] just run a Damon's head or state are Staples head works fine, too.
00:34:00 [W] So in terms of management, we kind of say like just you know, first start with what you have. Like don't go like crazy Greenfield and build all this stuff.
00:34:14 [W] It's like because when you look at like what k3s like how do you manage it?
00:34:20 [W] It's really like I got to get k3s on there, which is a binary k3s is a compact file to configure k3s itself.
00:34:30 [W] And then how am I going to deployment applications which are like manifest and images. So when you combine those it's like really like it could be as simple as rsync to manage these simple.
00:34:31 [W] These systems like just copying files and it just does the right thing so you don't have to go super complicated at first, but the problem is like as soon as your your your the number of nodes are clusters.
00:34:43 [W] You have scales up you're going to want to centralize things.
00:34:50 [W] And so this is what gitops starts to map very well to this like a gitops model of managing groups of clusters.
00:34:54 [W] The only problem with gitops right now is I must get up Solutions do not scale. Well for this edges case because they have a push or pull the push has a problem with just fundamentally not scalable because you can't it's very
00:35:01 [W] From a single point and the deal also with all the networking issues of doing a push model. Secondly, there's the pull model but the problem is a pull model is you don't want to be doing the git clone on the edge. Then you're just transferring all this ridiculous data over and then you have to optimize your get clones.
00:35:19 [W] We have a separate projects not related k3s Fleet that we announced earlier this year and it will go like kind of GH words and of the Year another open source project.
00:35:29 [W] That's kind of addressing some of these issues but just pointing out some of these things like the model of gitops maps really well, but there are some problems with it other little challenges and gaps that you're going to run into is most Kate to Bernays tools.
00:35:43 [W] they don't scale for Edge. So it's like the whole reason why you want to use kubernative ziz because it you get all like,
00:35:51 [W] Kubernative stuff, but they don't like let's say like Prometheus are monitoring those type things.
00:35:56 [W] They don't work really well for Edge deployments. A lot of things won't deal with bad network connections and the fundamental you saw like a hardware and Os management problem.
00:36:04 [W] So so these are things these are kind of things that like we're looking to address within a maybe in the k3s project or or layers above it. Like it is important for us to kind of keep k3s focus and simple but
00:36:20 [W] So so some of these management problems, you know, probably we have other like Fleet, you know, things like that the project set like at Rancher that we're working on all open source to address some of these issues.
00:36:32 [W] Okay, so I'm really bad at time management.
00:36:38 [W] So I went through like pretty much all Edge and I'm pretty much out of time.
00:36:41 [W] I'm going to talk about what app clusters are and then I probably won't talk about pipeline that much so you download the slides or ask my questions were going to open this up for questions as a second.
00:36:50 [W] Let me just throw out at clusters because it's a really cool idea and it's so simple to run to and it's basically the whole idea is like you just have a cluster which is dedicated to one application and it any deploy it on the resources needed for just that one application it could
00:37:07 [W] Three nodes could be one note. It could be a five thousand nodes.
00:37:09 [W] It's kind of funny because k3s while we target very small workloads or clusters.
00:37:13 [W] And in fact will scale to five thousand nodes just fine.
00:37:15 [W] We've tested this it works works very well.
00:37:21 [W] So but the whole idea is you create a cluster just for an application and you don't really treat the control plane is a separate thing.
00:37:30 [W] You just kind of embed it within the resources that are using it for the application and then use something like a man.
00:37:32 [W] Huge database to store the state.
00:37:37 [W] So your deployment you can have these very complicated applications which run on top of kubernative and do fancy kubernative things.
00:37:44 [W] Yes, so it's really simple to automate and it creates a very simple reliable quote reliable cluster.
00:37:59 [W] So I just want to throw that out through this idea icons of time to go and in depth, but please if you have some questions to ask them so I'm not going to go over a pipeline.
00:38:09 [W] Unfortunately.
00:38:11 [W] Yeah, it's bad time management here.
00:38:13 [W] I mean I told you I wasn't going to do any edits or anything.
00:38:14 [W] So kind of screwed that up.
00:38:14 [W] But anyways, um, yeah, so I'm gonna I think I will open it up for
00:38:23 [W] and so I think that's what we're doing now, and that's it.
00:38:24 [W] All right.
00:38:24 [W] Thanks.
00:38:25 [W] It was fun.
00:38:29 [W] Did you do?
00:38:35 [W] Okay, I think I'm alive.
00:38:46 [W] Yeah, so at this point, I'm going to answer some of the questions that come in quite a few questions.
00:38:49 [W] Oh crap.
00:38:49 [W] Sorry.
00:38:54 [W] I'm trying to okay. So there's a lot of questions around kind of the storage options.
00:38:58 [W] What what kind of what we support it's important to call it the
00:39:03 [W] It still does work.
00:39:10 [W] There are some of the questions that come in quite a few questions.
00:39:21 [W] Okay.
00:39:21 [W] Sorry.
00:39:21 [W] I'm trying to okay. So there's a lot of questions around kind of the storage options.
00:39:21 [W] What what kind of what we support it's important to call it. The still does work.
00:39:23 [W] Someone had asked if we recommend running the database options outside of the public cloudbees.
00:39:23 [W] Loud because I had said in the the mean or the presentation that you know, it's really great because you can get it managed. We still do recommend running it outside of the public clouds because
00:39:27 [W] Comfortable with them and so we still see a lot of use cases where people are doing that.
00:39:40 [W] There's one question.
00:39:44 [W] I wanted to address for someone was asking about you know, if I run k3s in like a CI Pipeline and I test your applications against k3s, how much can I trust that?
00:39:55 [W] It's going to be the same as like a you know, they say real I can quote real kubernative cluster.
00:39:56 [W] ER and so the whole idea of k3s is to make it easier to run kubernative zits.
00:40:09 [W] So like the kind of the advantages of kubermatic or k3s has it's, you know, a little smaller memory footprint and it's much easier to run than like the, you know normal way of running kubermatic, but from a kind of
00:40:19 [W] And like that, you know normal way of running kubermatic, but from a kind of like user deploying applications.
00:40:24 [W] It's still just kubermatic is it doesn't behave any differently like we very much want to avoid like, you know, the idea of like does it run on on k3s or or you know, if you're running on k3s, you need to do this.
00:40:35 [W] It's like no k3s is just kubernative.
00:40:38 [W] There's really nothing.
00:40:40 [W] We don't change any functionality that is kind of
00:40:42 [W] of important from from the API perspective or anything like that.
00:40:48 [W] So it's like if your application is just doing normal, you know using all the regular function like apis with kubernetes then if you write it on k3s, it's going to be just the same as running it like on a public cloud like the main difference is like on a like k3s sense. It's not optimized
00:41:02 [W] Good cloud, provider integration. But again, your application doesn't really care about cloud provider integration. It actually cares about service load balancer and you know the ability to create PVCs and get storage but k3s has an implementation of a storage
00:41:17 [W] and and story
00:41:28 [W] 3s is still just kubernative.
00:41:38 [W] Like MySQL is not really an option, which I totally understand.
00:41:49 [W] So there's two things you have two options there. If you want to do like high availability at the edge one is you can kind of wait for us to get the SED support in k3s fully kind of stabilized.
00:42:00 [W] That should be happening.
00:42:02 [W] you know this year in the k3s 119 release we're going to put that as a first class feature and then you know, we hope that will stabilize very quickly.
00:42:11 [W] Because it is still just a 2d it's you know, it's not like a DQ light. One of the things was like we had to wait we had we had to stabilize DQ light itself also, but at CD is very stable.
00:42:23 [W] It's just our integration with it or management of it.
00:42:33 [W] So one option is to do at TD the other is a lot of people right now are just running a single Master node with multiple worker nodes and the single Master node just runs the SQL Lite embedded and that just persist to the local disk.
00:42:39 [W] And then you use kind of traditional means of back.
00:42:45 [W] in k3s fully kind of stabilized that should be happening, you know this year in the k3s 119 release we're going to put that as a first class feature and then you know,
00:42:49 [W] Production right now are actually more oriented towards that a single Master with multiple worker nodes and then they just there's just extra Care on how to manage the state of the masternode if that goes down being able to move over
00:43:03 [W] So there's a lot of different approaches.
00:43:10 [W] Yeah.
00:43:17 [W] So let me see other other questions. Some people have asked like things like how does minikube and k3s compare those really sick kind of a different Realms.
00:43:25 [W] There's another project called k3s D which makes k3s really nice to run on the laptop.
00:43:30 [W] So k3s D and minikube what kind of overlap but like minikube is oriented towards running Kate.
00:43:34 [W] Sorry running kubernative is on your laptop and development environment k3s is really or is focused on production, but it just happens to be sense it so lightweight and easy to run it like works well of development on your laptop to so k3s
00:43:49 [W] Nettie's on your laptop and development environment k3s is really or is focused on production, but it just happens to be a sense. It's so lightweight and easy to run it like works well with development on your laptop to so k3s the goals of k3s
00:43:52 [W] Quite different from minikube. But when you bring in a project like k3s, d it overlaps quite a bit with minikube and so it's just a different option, you know, trying both out.
00:44:04 [W] There's there's kind of pros and cons to all of them.
00:44:05 [W] Okay, a lot of people really like k3s because you can spin up a lot of clusters or quickly fairly lightweight.
00:44:13 [W] Wow, there's really a lot of questions.
00:44:18 [W] Goodness, I don't even know how to see there's a question here. Just k3s support pics.
00:44:27 [W] To the OS booting and stuff like that like I mentioned before like you stupid animal.
00:44:33 [W] There are solutions you still have to kind of find outside of the scope of k3s.
00:44:50 [W] So somebody's asking like, what's the what's the recommended way to deploy k3s on Raspberry Pi obviously, you can just run the regular k3s installation.
00:44:57 [W] It should just work right out of the box like just run the curl script.
00:45:02 [W] There's a in the docs. You just pipe it's get dot k3s dot IO type that.
00:45:07 [W] Download that is to install script and then you can just run that with with bash or and that will just work out of the box on a Raspberry Pi and other approaches is there's ketchup.
00:45:21 [W] That project is really good for deploying very easily deploying k3s Kuma set of machines.
00:45:33 [W] And so that's fairly popular within kind of like that Raspberry Pi crowd of setting up a couple notes uses SSH to deploy. Okay.
00:45:40 [W] Let's see.
00:45:42 [W] Wow.
00:45:45 [W] Wow.
00:45:53 [W] I was a question about rootless mode.
00:46:02 [W] So ruthless mode is this is a great this is a use case of being able to run k3s without root privileges and that's an ongoing thing because that work is not
00:46:13 [W] Um, and it's largely led by sorry.
00:46:21 [W] What's his name?
00:46:22 [W] Akihiro a brilliant engineer.
00:46:26 [W] I believe he works at ndd is doing that it I have no idea when they'll offer code when that will actually actually go ga but we continue to be very interested in that use case.
00:46:39 [W] Wow, I obviously I think I'm out of time at this at this point.
00:46:42 [W] I guess there's a the slack Channel. We also have a booth like a virtual Booth where you can go and ask a lot of questions. We have engineers and stuff so you can get more information about k3s.
00:46:57 [W] So I think that's about it. I think I have to wrap it up now.
