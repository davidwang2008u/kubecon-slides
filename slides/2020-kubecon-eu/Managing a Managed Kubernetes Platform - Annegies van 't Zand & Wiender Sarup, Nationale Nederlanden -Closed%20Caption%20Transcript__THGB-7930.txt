Managing a Managed Kubernetes Platform: THGB-7930 - events@cncf.io - Tuesday, August 18, 2020 7:42 AM - 84 minutes

Participant: wordly [W] English (US)
Participant: wordly [W0] English (US)

Transcription for wordly [W]

00:02:18 [W] Hello everyone.
00:02:21 [W] Welcome to our talk managing a manage kubernative platform.
00:02:28 [W] My name is Venus Hadoop and I'll be giving this talk together with my colleague on his phone sound. So first an introduction, who are we and what is nn?
00:02:37 [W] So both on his and I are part of the container platform team.
00:02:47 [W] We're a team that started in January 2019 consisting of six members.
00:02:55 [W] We're part of the NN cloud and hosting team central it department and we also called the cloudfactory at least we're part of the cloudfactory consisting of three teams.
00:03:07 [W] We provide the cloud infrastructure for customers to run their workloads on
00:03:09 [W] So in short about an n and then group is a financial services company and operating in over 18 countries. Mostly European countries and Japan our head we have
00:03:25 [W] We're part of the cloudfactory consisting of three teams.
00:03:26 [W] We provide the cloud infrastructure for customers to run their workloads on.
00:03:26 [W] So in short about an n and then group is a financial services company and operating in over 18 countries. Mostly European countries and Japan our head we have
00:03:28 [W] Million customers and 15,000 employees. Our head office is located in The Hague the Netherlands and here you can see our products and services.
00:03:41 [W] We have as you can see mostly on insurance Investment Management Retirement services and banking.
00:03:54 [W] So this means we are on their Bank regulation and that means we're very strict on in certain aspects like security and
00:03:56 [W] compliancy. So first our talks about how to manage a container platform, but what is a platform so one
00:04:10 [W] At when you choose an available kubernative manage kubernative service, there's not much to it.
00:04:21 [W] You know, you would choose a cloud provider and yeah, just with a few clicks or with a few commands. You can spin up a kubernative surface and all things are happening in the background and
00:04:35 [W] At each configuration running and you can start to deploy and run your containerd workloads.
00:04:44 [W] But is that your platform?
00:04:56 [W] So when you run carbonate has at least getting kubernative up and running as managers is not that hard the challenge We Believe at least is
00:04:59 [W] something else if you think about what exemptions you need or what components you want to install how I wish you others your network look like do you need to connect to existing infrastructure and
00:05:16 [W] To do security.
00:05:20 [W] So these are all things to think about.
00:05:20 [W] When you run kubernative, especially in an Enterprise such as ours, you have to think of all these things and much more right? If you have an application you want to think about having a load balancing you want to have monitoring
00:05:38 [W] Right. If you have an application you want to think about having a load balancing you want to have monitoring you want to have access to metrics?
00:05:40 [W] Of course, and if you see interesting log messages you want to see how often it happened and how long so things like role-based access control.
00:05:54 [W] Is that part of your platform?
00:05:55 [W] Are you going to apply parsec UT policies? Maybe you would
00:05:59 [W] Want to restrict access to your pots using network policies?
00:06:10 [W] So there's when you run a manage kubernative service.
00:06:12 [W] There's a lot to think about.
00:06:23 [W] This is just the very start of implementing and fitting the solution in your company.
00:06:28 [W] And so that's why we say it's not just about kubernative zits about everything else.
00:06:28 [W] so
00:06:32 [W] About our platform.
00:06:39 [W] We were given the challenge to choose an Implement a platform that fits within our company.
00:06:43 [W] I won't go into much detail but choosing the right platform was not an easy task. However, these Solutions were just very difficult to integrate with our landscape.
00:06:56 [W] So we chose to use the kubernative service of AWS that's called eks that stands for elotl.
00:07:03 [W] About our platform.
00:07:09 [W] We were given the challenge to choose an Implement a platform that fits within our company.
00:07:09 [W] I won't go into much detail but choosing the right platform was not an easy task. However, these Solutions were just very difficult to integrate with our landscape.
00:07:10 [W] So we chose to use the kubernative service of AWS.
00:07:11 [W] Yes, that's called eks that stands for elastic kubernative surface.
00:07:12 [W] So we already had experience with AWS services.
00:07:12 [W] So this was the right choice for us and yeah using eks as a base.
00:07:16 [W] We checked our needs and found the implementations which we want to integrate in the platform and within existing with the NN existing environment.
00:07:27 [W] We created our own wrapper around it and just
00:07:30 [W] So the necessary components and Integrations for our customers.
00:07:34 [W] Besides that just for information. Our customers are basically devops teams throughout our company we have about 20 teams working on our cluster Plateau on our container platform.
00:07:52 [W] Besides that just for information. Our customers are basically devops teams throughout our company we have about 20 teams working on our cluster Plateau on our containerd platform.
00:07:53 [W] We have about 21 production clusters and yet together our customers run about 800 plus workloads in production.
00:08:04 [W] So that's a few numbers and your customers will get their own cluster and we manage all this for them and very important part of our platform.
00:08:17 [W] We wanted to provide our customers and very easy way to unboard our platform whether they are novice users or Advanced users.
00:08:24 [W] Has the solution would have to be a proper fit for the entire company.
00:08:32 [W] And so yeah, there were quite a lot of component balance.
00:08:38 [W] We need to configure and to manage all this we need to have a solid working ci/cd process.
00:08:46 [W] Yeah, so many components. We need to have Sable delivery of our containerd pet for me to make sure that production workloads work steady.
00:08:54 [W] Without any interruptions many components also depend on each other in order to work properly.
00:09:03 [W] And so you can imagine that in such a case one would need to properly test before releasing to customer and that actually brings us to this subject. We will address in this talk.
00:09:13 [W] Which is lifecycle management testing and ci/cd.
00:09:23 [W] To have Sable delivery of our containerd pet for me to make sure that production workloads work steady without any interruptions many components also depend on each other in order to work properly.
00:09:25 [W] And so you can imagine that in such a case one would need to properly test before releasing to customer and that actually brings us to this subject. We will address in this talk.
00:09:26 [W] Which is lifecycle management testing and ci/cd.
00:09:28 [W] So in regards to how you would manage a managed service, these are very broad terms, but hopefully everybody knows that how crucial these are when you deliver and manage
00:09:32 [W] Buddy knows that how crucial these are when you deliver and manage a surface.
00:09:39 [W] So for each subject, we will address the challenges we had and also the solutions we made and so some of these things we will discuss will be recognizable by for some of you and hopefully
00:09:48 [W] Thing you could use in your own environment.
00:09:56 [W] So I'll kick off with lifecycle management.
00:10:00 [W] So lifecycle management is something we all do.
00:10:01 [W] There's something we all encounter, especially in the kubernative world, or at least the kubernative ecosystem.
00:10:15 [W] We always have to do LCM, whether it's deploying a kubernative latest kubernative version minor or major or a bug fix or security vulnerabilities.
00:10:22 [W] so
00:10:25 [W] When we started with our platform as we were developing FP were developing our platform.
00:10:40 [W] We kept integrating more components that were necessary in our platform for our customers.
00:10:42 [W] and your while we were developing we ended up with and finally we ended up with a production ready cluster with all these components and Integrations, but of course, we also had to do LCM, so
00:10:58 [W] You can see you're all the projects we have and insulting our platform.
00:11:08 [W] But so we use option versions of our Docker images and Helm charts.
00:11:16 [W] We try to we try to not manage them by ourselves.
00:11:21 [W] And so you can see that's a lot of components and for each component. We have to check okay where there are new versions available and you know, all these projects are very active. So we really had to
00:11:28 [W] This is something we really encountered where we were lacking in doing LCM because before you know it you're behind a few updates.
00:11:41 [W] And so we in our containerd platform.
00:11:46 [W] We only allow private Registries private doctor Registries, and we proxy remote Helm repositories.
00:11:53 [W] So basically we our all our components have to be secure and compliant of course, and we always have to check the images for vulnerability. So we pulled the images from
00:12:00 [W] Upstream we check these for vulnerabilities and we push them to a private registry.
00:12:06 [W] So this is something we really had to get used to if we found any issues. We had to have them fixed up stream. And yeah, that's something we definitely learned doing because we're part of the community now,
00:12:18 [W] Besides these components and Integrations.
00:12:25 [W] We also of course have to upgrade our communities releases.
00:12:34 [W] And since we use a managed service, we are depending on AWS to provide us with the latest kubernative versions.
00:12:41 [W] And so yeah, that's something we always have to check out look out for together with that.
00:12:48 [W] We also have our managed nodes for worker nodes for eks.
00:12:49 [W] Just FYI AWS does provide their own service for manage no groups, but when we started the wasn't available yet, so we created our own solution.
00:13:04 [W] And so for that we always have to check what the latest versions are what the recommended versions are also four different deployments different manifests manifest and versions, they provide so that's something we really had to get
00:13:15 [W] and not just install the latest mouse or the latest release from GitHub last but not least dueling is also a very important part of our
00:13:35 [W] Dueling is also a very important part of our of our solution.
00:13:42 [W] So for example, we use their form to deploy our infrastructure and switching from there from 11:00 to 12:00.
00:13:51 [W] Yeah, that's a bit annoying and so especially with Sumter from providers and things like switching from home to two three.
00:13:55 [W] and it's also could sometimes be annoying especially when you use off-screen chart versions that maybe we're not up to date yet with Helm tree and those are little things we encountered and
00:14:10 [W] And it's also good sometimes be annoying, especially when you use a string chart versions that maybe we're not up to date yet with Helm tree.
00:14:12 [W] Those are little things we encountered and you know, if we use pay packages and we first jump in buildpacks ages of little things like that are also very important and something to look out for so
00:14:21 [W] Packages and we first open the packages little things like that are also very important and something to look out for so that's those were the challenges.
00:14:25 [W] We really encountered when doing LCM so looking at our solution. So first we didn't have any proper overview of all the docker images and versions.
00:14:38 [W] And same with the charts and versions and the tooling inversions.
00:14:45 [W] We didn't have that and there wasn't anything available.
00:14:48 [W] So a colleague of ours created the kubernative platform lifecycle management tool, which also available which is open source.
00:14:58 [W] So we use this tool with the proper input and this provides us the image first. We have the and all the chart first we have and the same way.
00:15:08 [W] The tooling and basically shows us also shows us the option versions.
00:15:16 [W] So if there are any updates available, we can see that in one overview.
00:15:24 [W] So that's basically the start when we of our yeah LCM process or weekly LCM process We Run The Tool we check for the available updates.
00:15:34 [W] We check for the change locks or the release locks to see if there are any breaking changes.
00:15:38 [W] Of course the to also check for vulnerability so we have to check this as well.
00:15:46 [W] We pulled the images to our private registry.
00:15:47 [W] We deploy the new versions in our deaf cluster to some thorough testing if there are any issues found, we have them fixed up stream. And so this is a process in itself
00:16:02 [W] Everything is fine.
00:16:06 [W] We roll out to production.
00:16:09 [W] so you can see we update so you can we operate these components regularly and release them regularly to our customers and this also means we do is in an automated way and
00:16:22 [W] Some challenges, of course and on the hitch will continue with this with about and talk about our ci/cd implementation.
00:16:31 [W] why so our design for the containerd platform for to create separate communities clusters for different groups of teams or departments the consequence of data us that we have to push changes to multiple clusters and it turns
00:16:53 [W] To do this.
00:16:57 [W] Well, we have to feel the pain first.
00:16:59 [W] I don't think I'm exaggerating when I say that we spent around 30% of last year on rewriting and and building our CD set up and they're still not done yet.
00:17:10 [W] So the May factor of the skill, which at least Batman we need to operate as you can imagine building a single platform.
00:17:19 [W] So quite a process in itself, but we had to do multiple because of this. We also had to look out for infrastructure costs.
00:17:30 [W] You can't just my closest kill your release pipeline closed it can result in huge cuts, but you don't want to save money either at the cost of the reliability.
00:17:41 [W] The impact of what you can do can be huge for the for the regulation of our customers.
00:17:49 [W] So we had to make sure that there's no chance that our big can reach production and reload. And the last one is duration. We didn't want a pipeline to take too long because then it would hardly be continuous deployment.
00:18:00 [W] So our setup the tool we use right now is go CD used to used to use Concourse, which is a beautiful ci/cd tool.
00:18:15 [W] You can do can be huge for the for the workloads of our customers.
00:18:25 [W] So we had to make sure that there's no chance that our book and reached production and reload.
00:18:25 [W] And the last one is duration.
00:18:26 [W] We didn't want a pipeline to take too long because then it would hardly be continuous deployment.
00:18:26 [W] So our setup the tool we use right now is go CD used to Houston. We use Concourse, which is a beautiful ci/cd tool.
00:18:29 [W] But once we started deploying Platforms in parallel, it just became too resource intensive.
00:18:31 [W] So we just decided to switch to go CD for its ability to pipe Works a pipelines and it's kubernative knative implementation running it on commanders are also allowed us to
00:18:34 [W] Skill up and down our agent pool drill easily. So and it resulted in a reduce of the infrastructure cost.
00:18:40 [W] So as you can see here is our released by pain in the upper picture.
00:18:49 [W] We have chosen for a face to release data released with customers and stages instead of all at once this way. We can check the reaction of customers and skill of back and accordingly as adoption rims up.
00:19:02 [W] So there are three main stages we have staging or production and production and just to clarify for us to us their openfaas.
00:19:10 [W] In the blisters, but at an end we maintain a security measure that production environments should always always be immutable.
00:19:23 [W] So we give our customers to glisters a new production environment for their development purposes and a separate production cluster.
00:19:31 [W] that is immutable for production workloads. So well, let me start a release we start the rich by plane from left to right. So we start in the staging of
00:19:42 [W] Our customers to glisters a new production environment for their development purposes and a separate production cluster that is immutable for production workloads.
00:19:56 [W] So let me start a release we start the rich by plane from left to right. So we start in the staging environment.
00:19:57 [W] This environment is only one cluster and as our production cluster only here read the rear end a few applications and perform our end-to-end. This is also the moment.
00:20:01 [W] Are we ramp up our agent pool to prepare for a customer blisters?
00:20:02 [W] If all the test tube sheet we take to get commit of the release in our git repository. This video is just for tracking and other disability purposes, and then we fan out to the customer clusters
00:20:13 [W] And then we found out to the customer clusters.
00:20:19 [W] We release to the customer closer to Bulls of 6 and a picture is free. But in reality, we do pools of 6 and 12 the first pool succeeds the next pool starts into all the Rook non-production clusters
00:20:26 [W] Which are released or then we take again to notify that the releasing new production environment is complete very complicated very continue to the prison environment, which we have great in similar fashion and
00:20:41 [W] Then equal to integration environment, which we have great in similar fashion. And therefore the very end the last tekton Mark the release is complete all these blocks are all that all these blocks that are clusters
00:20:51 [W] All these blocks that are clusters also our pipeline itself.
00:20:56 [W] and that is that in you can see that in the bottom picture.
00:20:56 [W] So what you see here is basically every stage in that pipeline to create a cluster or all part from so from left to right we start with the E KS to master nodes then we deploy our worker nodes.
00:21:14 [W] Bluegreen rolling the great if needed very bootstrap the platform with namespaces role based Access Control cni-genie verse and from there on out.
00:21:29 [W] We just two phases of epic moments based on the finishes on each other.
00:21:31 [W] This is red up really well for us but in a certain scenario it is lacking.
00:21:38 [W] So for example, if we upgrade our communities version we needed a customers needed time to update deprecated API versions and test if there are rivers will run smoothly.
00:21:54 [W] So when we did when we do our data release like that, we would read the pamphlet the pipeline up until and including the new production environment and stop it right between non-production protection.
00:22:07 [W] Then we'll just gift a customer some time to check their workloads to carry new manifest and then we've gotten from in a great signal from all the customers. You would roll out the J2 production that
00:22:21 [W] Our customer base grew the lonely Tok Fork to get okay signal so there's a little summer he realized the fact that you need to be able to differentiate between clusters.
00:22:37 [W] We have to be able to just upgrade the new production clusters and continue to be the production classes without the change in it or if a customer asked for a feature, then we would have to be able to just decorate
00:22:49 [W] And to test it, so the really made this possible is retreating every part of our platform as a separate product from the esk configuration.
00:23:04 [W] Tufin later the backup app you use the product rule says at least we deploy script the configuration configuration and if needed code and we will see version all these products separately and if something changed in the product
00:23:15 [W] So we deploy script the configuration configuration and if needed to go and we will search and all these products separately and if something changed in the product your bum diversion so
00:23:20 [W] Version so to basically a cluster configuration is a package of product variations now and you can overwrite a version of needed in a release pipeline.
00:23:31 [W] So let's say your team one cent of the new feature in of the English controller and we weren't sure about the impact or the consequences.
00:23:44 [W] would add the feature to the product the product great a new version and you'll totally lead pipe.
00:23:47 [W] Fine to just deploy it in that teams not production cluster and then they can test functionality we can monitor it and if it's okay, we can lease it to the rest of the dress down because of this layer deployments
00:24:01 [W] Total he's by playing through just deploy it in that teams not production cluster and then they can test functionality. We can monitor it and if it's okay, we can release it to the rest of the class time.
00:24:03 [W] because of these layer deployments and feature Flags
00:24:04 [W] We are now able to reply with scale but also keeping the customer in mind, but the previous with also fail.
00:24:13 [W] This is why we schedule dividing include a lot of tests and that is what I'm going to talk next about.
00:24:18 [W] So testing is important for us to prevent Banks from lending in a position.
00:24:26 [W] very close. And we also created a custom controller which is the core core component of our self-service interface.
00:24:37 [W] We call it an in controller and because of the negative roller among other things customer can create an eight spaces if property relation and no pools either restricted or shared.
00:24:49 [W] And also these functionalities are extensively tested.
00:24:54 [W] Testing of complaint could tailor platform was new to us as if you're using a lot of Open Source projects.
00:25:04 [W] It was hard to pinpoint where we should start testing and very good just trust Community to have tested for us.
00:25:15 [W] So in the beginning we were just performing small test like we used to deploy Kion and this is the authorization application to authorize
00:25:25 [W] And after a deployment, you just keep deploy a small container to try to get the parameter from from the Pomade stove if us and see if key on this is job, right?
00:25:45 [W] So these aren't really unit tests, but could be perceived as well.
00:25:49 [W] we notice that Services were still breaking sometimes and that's because the most services are consists of multiple components and if these components weren't aligned, well the search would still break.
00:26:01 [W] And as for the negative older, we really struggled with the duration of the test.
00:26:10 [W] So for example, this is a manifest of a new group.
00:26:19 [W] And as you can see you can configure the size of the node group the type to are big and some kind of note me and when it is shared or not and shape just means if it's literally if you
00:26:25 [W] Your pulse to land on this note.
00:26:32 [W] So if you would apply this on the back and the neck at all, I would create a blue and a green outer skin group couple of large figuration their security groups and for that little just shoot probably take like a few
00:26:44 [W] But it does not only Janerio yet to test. You also want to test scaling up down taking a dive changing from restricted to a shared notice.
00:27:00 [W] And if you been to all combined only test cases together it do it could easily take over 30 minutes and we couldn't run it in parallel because at this point you are still using their Scripts.
00:27:11 [W] So we learned that in a containerd platform at the integration between components is more important test and you should interests to mate it and create a solid base for a test. So we reflected all
00:27:26 [W] So we learned that in a container platform at the integration between components is more important test and you sit in a restroom ate it and create a solid base for a test. So we reflected all
00:27:28 [W] That point and create a finger you should I test and if by them is easier to create reusable code in the form of decorators or fixtures or just functions.
00:27:42 [W] And we noticed that the quality of the test room for we had before Rebecca, and this is very easier to include new test.
00:27:55 [W] So it just built a big test suite for platform and also created a separate CSD project containing application that uses most of our features of the platform
00:28:07 [W] Everybody in that the in this application rents in cluster that exists in our staging environment and every release before running up great and performance test to see if our
00:28:23 [W] Supposed to buy this verdict is also to entry point for potential customers at the tutorial. So to conclude it. You should really want to put in the time and do this properly because your best friend can only be considered successful if
00:28:39 [W] Nurse you lose credibility if books keep in your customers back to you being there.
00:28:46 [W] Okay, so these are the subject we wanted to present to you.
00:28:59 [W] We hope you found our challenges and solutions interesting and helpful.
00:29:03 [W] So in short what next for us this year, we started working on offering our containerd platform on Azure using their manage versions managed service AKs as your kubernative service and
00:29:15 [W] Started working on offering our containerd putt from on Azure using their manage versions managed service AKs as your kubernative service and with the support of our platform want to enable customer to easily migrate their
00:29:19 [W] Clattering want to enable customer to easily migrate their workloads from One Cloud Friday to another we want to provide customers on Azure the exact same experience. We created for our customers running their workloads on AWS.
00:29:31 [W] Takes us closer to provide a solid service for all of our ID teams with the more customers. We have the more we will focus on automation on our operations and this will take our containerd platform to the next level
00:29:47 [W] We've come to the last slide some information for to share with you.
00:29:54 [W] We have a boot and then so come visit us if you would like to have more information on our containerd platform and we also available on chat our website and you can always contact us if you have any questions
00:30:08 [W] Name box and we'll answer them.
00:30:27 [W0] Okay, we're life.
00:30:33 [W0] Hi.
00:30:33 [W0] Hi guys.
00:30:39 [W0] So because of technical issues we had to switch to one laptop. So sorry about that will quickly start with answering your questions the first one from news from breast to what extent are you or will you be using Cloud native
00:30:48 [W0] In your questions the first one from news from breast to what extent are you or will you be using Cloud native components from AWS or a juror? Is that a clearly defined border?
00:30:56 [W0] So yeah, we turned out we didn't have a clear idea about that.
00:31:01 [W0] But with the turnout we use a lot of cloud native Services, especially knative BS and when you switch to a sure we actually did the same. So for example if you have used SSM prodyna,
00:31:11 [W0] Parameters from AWS you have we look at the similar of the equivalent are in a chair. That's for example, the key vote Secret.
00:31:25 [W0] So there's not clearly were no clear border.
00:31:30 [W0] But yeah, it's just I guess a matter of the right choice.
00:31:31 [W0] what fits in your solution.
00:31:35 [W0] yeah, we use a lot of knative searches and so far it's worked out next question.
00:31:39 [W0] This on.
00:31:44 [W0] Yeah real couple of questions about our blue green no deployment.
00:31:55 [W0] So what exactly was about is what we do when we perform our blue green, how do you make sure that the applications do not have any downtime?
00:32:00 [W0] So we have like a blue educated group and a greenhouse training group and basically during Harbor grade skipped.
00:32:07 [W0] skipped. It's just a python script and it's skills up.
00:32:10 [W0] Drain to the new nodes.
00:32:24 [W0] So and then when all the ports are moved then we scale down the altar.
00:32:28 [W0] I'll just kidding group. And as long as the our customers had their poddisruptionbudgets.
00:32:38 [W0] This is also something we test in our testing like we could perform a performance test during a create the next question option strategy.
00:32:52 [W0] Yeah, so what is the adoption strategy within the organization?
00:32:53 [W0] How do you scale out this platform to other teams?
00:33:03 [W0] Yeah, so we started to actually with the first the first mover first-movers, right and we're ready to well.
00:33:05 [W0] Yeah. I'm a high enough level to easily adopt it. Yeah and
00:33:08 [W0] So gradually you see other teams interested and also yeah just to help them out in taking that step towards our platform.
00:33:23 [W0] We have sort of consult see Team set up.
00:33:27 [W0] Yeah, so they are expected to help those different teams to get up and running as well.
00:33:35 [W0] Because of course not all other LT means have the knowledge and to quickly start.
00:33:38 [W0] So long way to go to get the whole list of all of the it teams homework on board.
00:33:55 [W0] Are you next question from Andre?
00:33:59 [W0] Are you deploying also monitoring for customers? Do you have the access to it?
00:34:04 [W0] And then are you also managing it?
00:34:12 [W0] So yeah be for monitoring on the metric so security TPU and stuff.
00:34:14 [W0] We provide a Prometheus installation.
00:34:17 [W0] Together with the alert manager and if an official visualization and in a little magic Compass, we made it possible for customers to send their alerts to their own SNS Topic in AWS and event
00:34:31 [W0] So they can act on these themselves and we do the same Falco for the security monitoring.
00:34:42 [W0] Okay, next question Bluegreen plan is already explained it.
00:34:49 [W0] They also yeah, we say workloads.
00:34:55 [W0] What is that deployment?
00:34:55 [W0] Yeah, we already explained so workloads.
00:34:59 [W0] I mentioned this a deployment or deem set.
00:35:04 [W0] Our customers have running in production.
00:35:05 [W0] and scene
00:35:07 [W0] Next page I guess a lot of questions guys. So we won't be able to answer all of them are the docker images Etc managed and security fixed by the death think themselves.
00:35:21 [W0] So yeah, we have forced our private Registries that are the factory and we have another product of jfrog Keda x-ray we enforce that
00:35:36 [W0] Flowmill probability scale but it's their own responsibility to make sure the images are not relevant.
00:35:47 [W0] We don't enforce certain from abilities and not so they have their own repository. So they are responsible for their own.
00:35:58 [W0] images we have our own responsibilities of compliancy stuff, too.
00:36:02 [W0] So some question about managing database servers, we don't have that.
00:36:20 [W0] Yeah, so at the beginning of the for platform basically told well said just run stateless applications and if you want to state or any the
00:36:24 [W0] The cloud services. So in a TBS you would use RDS or dynamic debate.
00:36:33 [W0] for example, so when end we do start hearing something something to host a state yet, but like single vomit right now.
00:36:47 [W0] We're focusing on a chair instead or of also be shipping state.
00:36:52 [W0] Okay, you manage many cluster. How do you manage it?
00:36:56 [W0] Are you using kubernative cluster manager like Rancher?
00:37:01 [W0] Yeah this already explained right expiration.
00:37:11 [W0] Sorry, it's a really small box.
00:37:15 [W0] Okay.
00:37:21 [W0] What about chicken-egg problem running Katie payment on Kate's itself if I understand your question, right?
00:37:37 [W0] We have a on our production cluster. We do not ruin our go Sheedy insulation.
00:37:46 [W0] We're not in a separate cluster outside of the pipeline.
00:37:50 [W0] So it's not like we are upgrading the cluster with two running in the cluster.
00:37:52 [W0] Insulation if just a little amount of services that you can easily scroll up and down.
00:38:01 [W0] So there isn't really a chicken-egg problem.
00:38:04 [W0] So there's a question why are using different version for the nonprofit forces brought that was explained in this in RCC ci/cd part.
00:38:16 [W0] It's yeah, it should be excluded.
00:38:17 [W0] That should be the same.
00:38:23 [W0] So we also only use it for small periods of time just to make not stop our development workflow.
00:38:27 [W0] Okay, and slide 15 the non production and production environment have each two sets of three connected by arrows.
00:38:42 [W0] What is the difference between a cluster on the left and on the right?
00:38:50 [W0] So this is like the difference between a our customers new production environments workloads and their prediction workloads we first.
00:38:57 [W0] To update all the new production environments just to make sure that they're if there's an issue that you'll notice before we are started grading our production environments.
00:39:12 [W0] Okay, I did I understand.
00:39:18 [W0] It's a Samer control plane.
00:39:31 [W0] Yes, when the managed service from Heroes.
00:39:32 [W0] It's the same of it, but just notice perform a all Bluegreen upgrade. So for a temporarily we double the amount of nodes in the cluster and
00:39:46 [W0] So for temporarily we doubled the amount of nodes in the cluster and that all the bolts get moved to the new notes and then we drain and destroy the old Out
00:39:54 [W0] Ring and destroyed adult and screening room noticed.
00:39:59 [W0] So there's a question about testing see interesting one.
00:40:03 [W0] I'm part of the similar team and we're struggling quite a bit to properly test our platform or do we just run the actual application landscape?
00:40:09 [W0] Oh, yeah, so we had the same issue.
00:40:11 [W0] Yes a lot of our future.
00:40:18 [W0] Yeah, so we have like a
00:40:21 [W0] Test application that uses all the features that I told you about.
00:40:35 [W0] So, for example, we just perform a rolling upgrade of the that application and intramural perform a performance test just to just to check if it's still performing right?
00:40:40 [W0] And just a lot of end-to-end tests like creating a security alert and make sure it's it's gets to our alert box.
00:40:50 [W0] for example, so basically every cycle chain which you want to test. Hello whole flow, right? Yeah.
00:41:00 [W0] a lot of Integrations as you mentioned before and that's the difficult part, I guess of managing such platform.
00:41:05 [W0] What's the reason why you are considering a serverless?
00:41:13 [W0] / explained? We had a lot of customers also working on a jurors on both AWS integer. So they're very interested in remaining in the texture ecosystem.
00:41:22 [W0] It's also our expansion.
00:41:26 [W0] New share your test. Shoot framework.
00:41:31 [W0] No, not yet.
00:41:33 [W0] That's very mostly just using.
00:41:36 [W0] vitess framework
00:41:39 [W0] a lot of questions should skip to the next page which vulnerability to you are using as we explained x-ray.
00:41:52 [W0] Yeah of jfrog.
00:41:54 [W0] This is my box many are we closer as separate product how much additional resource in does this take?
00:42:08 [W0] young fresh out of step with product how much additional resource mistake
00:42:18 [W0] Like Financial cost.
00:42:22 [W0] Sure.
00:42:34 [W0] Yeah, we just do it because a big part of the reason that we serves it. This way is every bu of / of of us focus on different strings have a little bit
00:42:39 [W0] A big part of the reason that we serves as his way is every bu of / of of us focus on different strings and have a little bit different rules for our security and stuff.
00:42:43 [W0] and some workloads just had to be able to run in a separate cluster just for a heart Network separation, for example, so we already knew we
00:42:56 [W0] Ruining a separate cluster just for a heart Network separation.
00:42:56 [W0] for example, so we already knew we had to be able to be flexible with servicing our containerd platform because we already knew front. Some of the be used would not accept one
00:43:08 [W0] We already knew from some of the be used would not accept one large platform.
00:43:13 [W0] So we just made it a variable in the way that you can have a platform for wanting multiple teams for whole bu for example, so that's why we chose for a
00:43:26 [W0] Decentralized concept and not not really out. Of course.
00:43:34 [W0] Are some of the components of sources so where can it be found?
00:43:42 [W0] So yeah, I'll component we use our open source.
00:43:44 [W0] I'm not sure how much time we have left.
00:43:49 [W0] Oh, wow.
00:43:51 [W0] Well, they're still there, right?
00:43:53 [W0] All right, so we have still have four minutes. Okay.
00:44:10 [W0] Did you simplify your platform running it and measure well, we started out sorry this platform. We didn't really well plan to also be built the same
00:44:22 [W0] Sure, not at first no, I mean you didn't not simplify it and we're like I think 85% there.
00:44:35 [W0] There's still a few Nick's we have to figure out but no we didn't did attempt to simplify it.
00:44:44 [W0] We just all the features that are only u.s.
00:44:45 [W0] Or also also be present on the edge, which I guess our Focus was on just delivering the same experience, right? Yeah, so it would have to be working.
00:44:53 [W0] Exactly the same and I guess that's where most of the challenge was.
00:44:57 [W0] Yeah, the plan was for customers in the US and n***** to have the same experience.
00:45:06 [W0] We just provide the community API and that's what they interact with.
00:45:14 [W0] with. So from the front there shouldn't be well at least this as less as possible different.
00:45:21 [W0] Oh, what a documentation.
00:45:31 [W0] What does the documentation for developers and related themes look like it's a very important part actually a lot.
00:45:40 [W0] So yeah, we didn't really in the beginning we quickly found out that documentation was so important just providing all necessary information for them to start up the demo
00:45:47 [W0] And those kind of things are explained in our will a very very detailed right step by step and I guess most of them most of our customer actually.
00:46:03 [W0] It was really helpful having that documentation, you know, you get that when they're actually saying that those kind of things and pay documentation brought us that far and so they're very thankful for that.
00:46:17 [W0] How do you structure the platform in terms of git repositories?
00:46:22 [W0] And what is your branching model?
00:46:24 [W0] So we started out with multiple repositories with separate projects that at some point like the platform.
00:46:34 [W0] platform. There are other components are dependent on each other like so it's some point we had like three pull request in three different repositories, and you have to be merged in the same time table. So after that we just move
00:46:50 [W0] A mano repository when live like other directories being sort of separate products.
00:46:55 [W0] And for branching model, we just use the kit. Imagine your most cherished the production code and a future changes greatly in a separate branch and have to pass to be
00:47:11 [W0] You have to request with if there's another brutal.
00:47:17 [W0] But also biggest frustration during the entire project so far and how did you deal with it?
00:47:33 [W0] Especially considering that you were building a green field solution with a regulated financial service provider biggest frustration.
00:47:41 [W0] I don't know what suppose that was for you but when you started reading stand by there was something we had to get used to so it's not only deaf but also the operations part, right? Yeah, that would be if we had like a large.
00:47:55 [W0] Alert pool and we just had to keep growing it for it too.
00:48:00 [W0] Well be effective.
00:48:01 [W0] Yeah a lot of false positives and waking up at night.
00:48:13 [W0] So if me with Devils a big frustration, so for me the part of us knew but is also maybe just for you as well.
00:48:16 [W0] We are part now of the open source Community doing our own commits right to open source projects, if you use a project you think oh it's there but when you use it,
00:48:25 [W0] Some things are not template eyes or those kind of things.
00:48:32 [W0] Yeah, and then you create a PR and then you have to wait for them to merge it and release it those kind of things.
00:48:34 [W0] Yeah.
00:48:37 [W0] We saw that in a few projects. That was frustrating I guess right.
00:48:40 [W0] S into F in shouted.
00:48:46 [W0] what is the select channel to follow only with you guys?
00:48:48 [W0] So I will select channel.
00:48:51 [W0] So it's official cncf Channel.
00:48:52 [W0] Yeah to keep calm operations Channel.
00:49:00 [W0] We will have keep answering questions over there.
00:49:03 [W0] So thank you very much for joining us and we hope to hear from you.
00:49:08 [W0] you.

Transcription for wordly [W0]

00:02:18 [W] Hello everyone.
00:02:21 [W] Welcome to our talk managing a manage kubernative platform.
00:02:28 [W] My name is Venus Hadoop and I'll be giving this talk together with my colleague on his phone sound. So first an introduction, who are we and what is nn?
00:02:37 [W] So both on his and I are part of the container platform team.
00:02:47 [W] We're a team that started in January 2019 consisting of six members.
00:02:55 [W] We're part of the NN cloud and hosting team central it department and we also called the cloudfactory at least we're part of the cloudfactory consisting of three teams.
00:03:07 [W] We provide the cloud infrastructure for customers to run their workloads on
00:03:09 [W] So in short about an n and then group is a financial services company and operating in over 18 countries. Mostly European countries and Japan our head we have
00:03:25 [W] We're part of the cloudfactory consisting of three teams.
00:03:26 [W] We provide the cloud infrastructure for customers to run their workloads on.
00:03:26 [W] So in short about an n and then group is a financial services company and operating in over 18 countries. Mostly European countries and Japan our head we have
00:03:28 [W] Million customers and 15,000 employees. Our head office is located in The Hague the Netherlands and here you can see our products and services.
00:03:41 [W] We have as you can see mostly on insurance Investment Management Retirement services and banking.
00:03:54 [W] So this means we are on their Bank regulation and that means we're very strict on in certain aspects like security and
00:03:56 [W] compliancy. So first our talks about how to manage a container platform, but what is a platform so one
00:04:10 [W] At when you choose an available kubernative manage kubernative service, there's not much to it.
00:04:21 [W] You know, you would choose a cloud provider and yeah, just with a few clicks or with a few commands. You can spin up a kubernative surface and all things are happening in the background and
00:04:35 [W] At each configuration running and you can start to deploy and run your containerd workloads.
00:04:44 [W] But is that your platform?
00:04:56 [W] So when you run carbonate has at least getting kubernative up and running as managers is not that hard the challenge We Believe at least is
00:04:59 [W] something else if you think about what exemptions you need or what components you want to install how I wish you others your network look like do you need to connect to existing infrastructure and
00:05:16 [W] To do security.
00:05:20 [W] So these are all things to think about.
00:05:20 [W] When you run kubernative, especially in an Enterprise such as ours, you have to think of all these things and much more right? If you have an application you want to think about having a load balancing you want to have monitoring
00:05:38 [W] Right. If you have an application you want to think about having a load balancing you want to have monitoring you want to have access to metrics?
00:05:40 [W] Of course, and if you see interesting log messages you want to see how often it happened and how long so things like role-based access control.
00:05:54 [W] Is that part of your platform?
00:05:55 [W] Are you going to apply parsec UT policies? Maybe you would
00:05:59 [W] Want to restrict access to your pots using network policies?
00:06:10 [W] So there's when you run a manage kubernative service.
00:06:12 [W] There's a lot to think about.
00:06:23 [W] This is just the very start of implementing and fitting the solution in your company.
00:06:28 [W] And so that's why we say it's not just about kubernative zits about everything else.
00:06:28 [W] so
00:06:32 [W] About our platform.
00:06:39 [W] We were given the challenge to choose an Implement a platform that fits within our company.
00:06:43 [W] I won't go into much detail but choosing the right platform was not an easy task. However, these Solutions were just very difficult to integrate with our landscape.
00:06:56 [W] So we chose to use the kubernative service of AWS that's called eks that stands for elotl.
00:07:03 [W] About our platform.
00:07:09 [W] We were given the challenge to choose an Implement a platform that fits within our company.
00:07:09 [W] I won't go into much detail but choosing the right platform was not an easy task. However, these Solutions were just very difficult to integrate with our landscape.
00:07:10 [W] So we chose to use the kubernative service of AWS.
00:07:11 [W] Yes, that's called eks that stands for elastic kubernative surface.
00:07:12 [W] So we already had experience with AWS services.
00:07:12 [W] So this was the right choice for us and yeah using eks as a base.
00:07:16 [W] We checked our needs and found the implementations which we want to integrate in the platform and within existing with the NN existing environment.
00:07:27 [W] We created our own wrapper around it and just
00:07:30 [W] So the necessary components and Integrations for our customers.
00:07:34 [W] Besides that just for information. Our customers are basically devops teams throughout our company we have about 20 teams working on our cluster Plateau on our container platform.
00:07:52 [W] Besides that just for information. Our customers are basically devops teams throughout our company we have about 20 teams working on our cluster Plateau on our containerd platform.
00:07:53 [W] We have about 21 production clusters and yet together our customers run about 800 plus workloads in production.
00:08:04 [W] So that's a few numbers and your customers will get their own cluster and we manage all this for them and very important part of our platform.
00:08:17 [W] We wanted to provide our customers and very easy way to unboard our platform whether they are novice users or Advanced users.
00:08:24 [W] Has the solution would have to be a proper fit for the entire company.
00:08:32 [W] And so yeah, there were quite a lot of component balance.
00:08:38 [W] We need to configure and to manage all this we need to have a solid working ci/cd process.
00:08:46 [W] Yeah, so many components. We need to have Sable delivery of our containerd pet for me to make sure that production workloads work steady.
00:08:54 [W] Without any interruptions many components also depend on each other in order to work properly.
00:09:03 [W] And so you can imagine that in such a case one would need to properly test before releasing to customer and that actually brings us to this subject. We will address in this talk.
00:09:13 [W] Which is lifecycle management testing and ci/cd.
00:09:23 [W] To have Sable delivery of our containerd pet for me to make sure that production workloads work steady without any interruptions many components also depend on each other in order to work properly.
00:09:25 [W] And so you can imagine that in such a case one would need to properly test before releasing to customer and that actually brings us to this subject. We will address in this talk.
00:09:26 [W] Which is lifecycle management testing and ci/cd.
00:09:28 [W] So in regards to how you would manage a managed service, these are very broad terms, but hopefully everybody knows that how crucial these are when you deliver and manage
00:09:32 [W] Buddy knows that how crucial these are when you deliver and manage a surface.
00:09:39 [W] So for each subject, we will address the challenges we had and also the solutions we made and so some of these things we will discuss will be recognizable by for some of you and hopefully
00:09:48 [W] Thing you could use in your own environment.
00:09:56 [W] So I'll kick off with lifecycle management.
00:10:00 [W] So lifecycle management is something we all do.
00:10:01 [W] There's something we all encounter, especially in the kubernative world, or at least the kubernative ecosystem.
00:10:15 [W] We always have to do LCM, whether it's deploying a kubernative latest kubernative version minor or major or a bug fix or security vulnerabilities.
00:10:22 [W] so
00:10:25 [W] When we started with our platform as we were developing FP were developing our platform.
00:10:40 [W] We kept integrating more components that were necessary in our platform for our customers.
00:10:42 [W] and your while we were developing we ended up with and finally we ended up with a production ready cluster with all these components and Integrations, but of course, we also had to do LCM, so
00:10:58 [W] You can see you're all the projects we have and insulting our platform.
00:11:08 [W] But so we use option versions of our Docker images and Helm charts.
00:11:16 [W] We try to we try to not manage them by ourselves.
00:11:21 [W] And so you can see that's a lot of components and for each component. We have to check okay where there are new versions available and you know, all these projects are very active. So we really had to
00:11:28 [W] This is something we really encountered where we were lacking in doing LCM because before you know it you're behind a few updates.
00:11:41 [W] And so we in our containerd platform.
00:11:46 [W] We only allow private Registries private doctor Registries, and we proxy remote Helm repositories.
00:11:53 [W] So basically we our all our components have to be secure and compliant of course, and we always have to check the images for vulnerability. So we pulled the images from
00:12:00 [W] Upstream we check these for vulnerabilities and we push them to a private registry.
00:12:06 [W] So this is something we really had to get used to if we found any issues. We had to have them fixed up stream. And yeah, that's something we definitely learned doing because we're part of the community now,
00:12:18 [W] Besides these components and Integrations.
00:12:25 [W] We also of course have to upgrade our communities releases.
00:12:34 [W] And since we use a managed service, we are depending on AWS to provide us with the latest kubernative versions.
00:12:41 [W] And so yeah, that's something we always have to check out look out for together with that.
00:12:48 [W] We also have our managed nodes for worker nodes for eks.
00:12:49 [W] Just FYI AWS does provide their own service for manage no groups, but when we started the wasn't available yet, so we created our own solution.
00:13:04 [W] And so for that we always have to check what the latest versions are what the recommended versions are also four different deployments different manifests manifest and versions, they provide so that's something we really had to get
00:13:15 [W] and not just install the latest mouse or the latest release from GitHub last but not least dueling is also a very important part of our
00:13:35 [W] Dueling is also a very important part of our of our solution.
00:13:42 [W] So for example, we use their form to deploy our infrastructure and switching from there from 11:00 to 12:00.
00:13:51 [W] Yeah, that's a bit annoying and so especially with Sumter from providers and things like switching from home to two three.
00:13:55 [W] and it's also could sometimes be annoying especially when you use off-screen chart versions that maybe we're not up to date yet with Helm tree and those are little things we encountered and
00:14:10 [W] And it's also good sometimes be annoying, especially when you use a string chart versions that maybe we're not up to date yet with Helm tree.
00:14:12 [W] Those are little things we encountered and you know, if we use pay packages and we first jump in buildpacks ages of little things like that are also very important and something to look out for so
00:14:21 [W] Packages and we first open the packages little things like that are also very important and something to look out for so that's those were the challenges.
00:14:25 [W] We really encountered when doing LCM so looking at our solution. So first we didn't have any proper overview of all the docker images and versions.
00:14:38 [W] And same with the charts and versions and the tooling inversions.
00:14:45 [W] We didn't have that and there wasn't anything available.
00:14:48 [W] So a colleague of ours created the kubernative platform lifecycle management tool, which also available which is open source.
00:14:58 [W] So we use this tool with the proper input and this provides us the image first. We have the and all the chart first we have and the same way.
00:15:08 [W] The tooling and basically shows us also shows us the option versions.
00:15:16 [W] So if there are any updates available, we can see that in one overview.
00:15:24 [W] So that's basically the start when we of our yeah LCM process or weekly LCM process We Run The Tool we check for the available updates.
00:15:34 [W] We check for the change locks or the release locks to see if there are any breaking changes.
00:15:38 [W] Of course the to also check for vulnerability so we have to check this as well.
00:15:46 [W] We pulled the images to our private registry.
00:15:47 [W] We deploy the new versions in our deaf cluster to some thorough testing if there are any issues found, we have them fixed up stream. And so this is a process in itself
00:16:02 [W] Everything is fine.
00:16:06 [W] We roll out to production.
00:16:09 [W] so you can see we update so you can we operate these components regularly and release them regularly to our customers and this also means we do is in an automated way and
00:16:22 [W] Some challenges, of course and on the hitch will continue with this with about and talk about our ci/cd implementation.
00:16:31 [W] why so our design for the containerd platform for to create separate communities clusters for different groups of teams or departments the consequence of data us that we have to push changes to multiple clusters and it turns
00:16:53 [W] To do this.
00:16:57 [W] Well, we have to feel the pain first.
00:16:59 [W] I don't think I'm exaggerating when I say that we spent around 30% of last year on rewriting and and building our CD set up and they're still not done yet.
00:17:10 [W] So the May factor of the skill, which at least Batman we need to operate as you can imagine building a single platform.
00:17:19 [W] So quite a process in itself, but we had to do multiple because of this. We also had to look out for infrastructure costs.
00:17:30 [W] You can't just my closest kill your release pipeline closed it can result in huge cuts, but you don't want to save money either at the cost of the reliability.
00:17:41 [W] The impact of what you can do can be huge for the for the regulation of our customers.
00:17:49 [W] So we had to make sure that there's no chance that our big can reach production and reload. And the last one is duration. We didn't want a pipeline to take too long because then it would hardly be continuous deployment.
00:18:00 [W] So our setup the tool we use right now is go CD used to used to use Concourse, which is a beautiful ci/cd tool.
00:18:15 [W] You can do can be huge for the for the workloads of our customers.
00:18:25 [W] So we had to make sure that there's no chance that our book and reached production and reload.
00:18:25 [W] And the last one is duration.
00:18:26 [W] We didn't want a pipeline to take too long because then it would hardly be continuous deployment.
00:18:26 [W] So our setup the tool we use right now is go CD used to Houston. We use Concourse, which is a beautiful ci/cd tool.
00:18:29 [W] But once we started deploying Platforms in parallel, it just became too resource intensive.
00:18:31 [W] So we just decided to switch to go CD for its ability to pipe Works a pipelines and it's kubernative knative implementation running it on commanders are also allowed us to
00:18:34 [W] Skill up and down our agent pool drill easily. So and it resulted in a reduce of the infrastructure cost.
00:18:40 [W] So as you can see here is our released by pain in the upper picture.
00:18:49 [W] We have chosen for a face to release data released with customers and stages instead of all at once this way. We can check the reaction of customers and skill of back and accordingly as adoption rims up.
00:19:02 [W] So there are three main stages we have staging or production and production and just to clarify for us to us their openfaas.
00:19:10 [W] In the blisters, but at an end we maintain a security measure that production environments should always always be immutable.
00:19:23 [W] So we give our customers to glisters a new production environment for their development purposes and a separate production cluster.
00:19:31 [W] that is immutable for production workloads. So well, let me start a release we start the rich by plane from left to right. So we start in the staging of
00:19:42 [W] Our customers to glisters a new production environment for their development purposes and a separate production cluster that is immutable for production workloads.
00:19:56 [W] So let me start a release we start the rich by plane from left to right. So we start in the staging environment.
00:19:57 [W] This environment is only one cluster and as our production cluster only here read the rear end a few applications and perform our end-to-end. This is also the moment.
00:20:01 [W] Are we ramp up our agent pool to prepare for a customer blisters?
00:20:02 [W] If all the test tube sheet we take to get commit of the release in our git repository. This video is just for tracking and other disability purposes, and then we fan out to the customer clusters
00:20:13 [W] And then we found out to the customer clusters.
00:20:19 [W] We release to the customer closer to Bulls of 6 and a picture is free. But in reality, we do pools of 6 and 12 the first pool succeeds the next pool starts into all the Rook non-production clusters
00:20:26 [W] Which are released or then we take again to notify that the releasing new production environment is complete very complicated very continue to the prison environment, which we have great in similar fashion and
00:20:41 [W] Then equal to integration environment, which we have great in similar fashion. And therefore the very end the last tekton Mark the release is complete all these blocks are all that all these blocks that are clusters
00:20:51 [W] All these blocks that are clusters also our pipeline itself.
00:20:56 [W] and that is that in you can see that in the bottom picture.
00:20:56 [W] So what you see here is basically every stage in that pipeline to create a cluster or all part from so from left to right we start with the E KS to master nodes then we deploy our worker nodes.
00:21:14 [W] Bluegreen rolling the great if needed very bootstrap the platform with namespaces role based Access Control cni-genie verse and from there on out.
00:21:29 [W] We just two phases of epic moments based on the finishes on each other.
00:21:31 [W] This is red up really well for us but in a certain scenario it is lacking.
00:21:38 [W] So for example, if we upgrade our communities version we needed a customers needed time to update deprecated API versions and test if there are rivers will run smoothly.
00:21:54 [W] So when we did when we do our data release like that, we would read the pamphlet the pipeline up until and including the new production environment and stop it right between non-production protection.
00:22:07 [W] Then we'll just gift a customer some time to check their workloads to carry new manifest and then we've gotten from in a great signal from all the customers. You would roll out the J2 production that
00:22:21 [W] Our customer base grew the lonely Tok Fork to get okay signal so there's a little summer he realized the fact that you need to be able to differentiate between clusters.
00:22:37 [W] We have to be able to just upgrade the new production clusters and continue to be the production classes without the change in it or if a customer asked for a feature, then we would have to be able to just decorate
00:22:49 [W] And to test it, so the really made this possible is retreating every part of our platform as a separate product from the esk configuration.
00:23:04 [W] Tufin later the backup app you use the product rule says at least we deploy script the configuration configuration and if needed code and we will see version all these products separately and if something changed in the product
00:23:15 [W] So we deploy script the configuration configuration and if needed to go and we will search and all these products separately and if something changed in the product your bum diversion so
00:23:20 [W] Version so to basically a cluster configuration is a package of product variations now and you can overwrite a version of needed in a release pipeline.
00:23:31 [W] So let's say your team one cent of the new feature in of the English controller and we weren't sure about the impact or the consequences.
00:23:44 [W] would add the feature to the product the product great a new version and you'll totally lead pipe.
00:23:47 [W] Fine to just deploy it in that teams not production cluster and then they can test functionality we can monitor it and if it's okay, we can lease it to the rest of the dress down because of this layer deployments
00:24:01 [W] Total he's by playing through just deploy it in that teams not production cluster and then they can test functionality. We can monitor it and if it's okay, we can release it to the rest of the class time.
00:24:03 [W] because of these layer deployments and feature Flags
00:24:04 [W] We are now able to reply with scale but also keeping the customer in mind, but the previous with also fail.
00:24:13 [W] This is why we schedule dividing include a lot of tests and that is what I'm going to talk next about.
00:24:18 [W] So testing is important for us to prevent Banks from lending in a position.
00:24:26 [W] very close. And we also created a custom controller which is the core core component of our self-service interface.
00:24:37 [W] We call it an in controller and because of the negative roller among other things customer can create an eight spaces if property relation and no pools either restricted or shared.
00:24:49 [W] And also these functionalities are extensively tested.
00:24:54 [W] Testing of complaint could tailor platform was new to us as if you're using a lot of Open Source projects.
00:25:04 [W] It was hard to pinpoint where we should start testing and very good just trust Community to have tested for us.
00:25:15 [W] So in the beginning we were just performing small test like we used to deploy Kion and this is the authorization application to authorize
00:25:25 [W] And after a deployment, you just keep deploy a small container to try to get the parameter from from the Pomade stove if us and see if key on this is job, right?
00:25:45 [W] So these aren't really unit tests, but could be perceived as well.
00:25:49 [W] we notice that Services were still breaking sometimes and that's because the most services are consists of multiple components and if these components weren't aligned, well the search would still break.
00:26:01 [W] And as for the negative older, we really struggled with the duration of the test.
00:26:10 [W] So for example, this is a manifest of a new group.
00:26:19 [W] And as you can see you can configure the size of the node group the type to are big and some kind of note me and when it is shared or not and shape just means if it's literally if you
00:26:25 [W] Your pulse to land on this note.
00:26:32 [W] So if you would apply this on the back and the neck at all, I would create a blue and a green outer skin group couple of large figuration their security groups and for that little just shoot probably take like a few
00:26:44 [W] But it does not only Janerio yet to test. You also want to test scaling up down taking a dive changing from restricted to a shared notice.
00:27:00 [W] And if you been to all combined only test cases together it do it could easily take over 30 minutes and we couldn't run it in parallel because at this point you are still using their Scripts.
00:27:11 [W] So we learned that in a containerd platform at the integration between components is more important test and you should interests to mate it and create a solid base for a test. So we reflected all
00:27:26 [W] So we learned that in a container platform at the integration between components is more important test and you sit in a restroom ate it and create a solid base for a test. So we reflected all
00:27:28 [W] That point and create a finger you should I test and if by them is easier to create reusable code in the form of decorators or fixtures or just functions.
00:27:42 [W] And we noticed that the quality of the test room for we had before Rebecca, and this is very easier to include new test.
00:27:55 [W] So it just built a big test suite for platform and also created a separate CSD project containing application that uses most of our features of the platform
00:28:07 [W] Everybody in that the in this application rents in cluster that exists in our staging environment and every release before running up great and performance test to see if our
00:28:23 [W] Supposed to buy this verdict is also to entry point for potential customers at the tutorial. So to conclude it. You should really want to put in the time and do this properly because your best friend can only be considered successful if
00:28:39 [W] Nurse you lose credibility if books keep in your customers back to you being there.
00:28:46 [W] Okay, so these are the subject we wanted to present to you.
00:28:59 [W] We hope you found our challenges and solutions interesting and helpful.
00:29:03 [W] So in short what next for us this year, we started working on offering our containerd platform on Azure using their manage versions managed service AKs as your kubernative service and
00:29:15 [W] Started working on offering our containerd putt from on Azure using their manage versions managed service AKs as your kubernative service and with the support of our platform want to enable customer to easily migrate their
00:29:19 [W] Clattering want to enable customer to easily migrate their workloads from One Cloud Friday to another we want to provide customers on Azure the exact same experience. We created for our customers running their workloads on AWS.
00:29:31 [W] Takes us closer to provide a solid service for all of our ID teams with the more customers. We have the more we will focus on automation on our operations and this will take our containerd platform to the next level
00:29:47 [W] We've come to the last slide some information for to share with you.
00:29:54 [W] We have a boot and then so come visit us if you would like to have more information on our containerd platform and we also available on chat our website and you can always contact us if you have any questions
00:30:08 [W] Name box and we'll answer them.
00:30:27 [W0] Okay, we're life.
00:30:33 [W0] Hi.
00:30:33 [W0] Hi guys.
00:30:39 [W0] So because of technical issues we had to switch to one laptop. So sorry about that will quickly start with answering your questions the first one from news from breast to what extent are you or will you be using Cloud native
00:30:48 [W0] In your questions the first one from news from breast to what extent are you or will you be using Cloud native components from AWS or a juror? Is that a clearly defined border?
00:30:56 [W0] So yeah, we turned out we didn't have a clear idea about that.
00:31:01 [W0] But with the turnout we use a lot of cloud native Services, especially knative BS and when you switch to a sure we actually did the same. So for example if you have used SSM prodyna,
00:31:11 [W0] Parameters from AWS you have we look at the similar of the equivalent are in a chair. That's for example, the key vote Secret.
00:31:25 [W0] So there's not clearly were no clear border.
00:31:30 [W0] But yeah, it's just I guess a matter of the right choice.
00:31:31 [W0] what fits in your solution.
00:31:35 [W0] yeah, we use a lot of knative searches and so far it's worked out next question.
00:31:39 [W0] This on.
00:31:44 [W0] Yeah real couple of questions about our blue green no deployment.
00:31:55 [W0] So what exactly was about is what we do when we perform our blue green, how do you make sure that the applications do not have any downtime?
00:32:00 [W0] So we have like a blue educated group and a greenhouse training group and basically during Harbor grade skipped.
00:32:07 [W0] skipped. It's just a python script and it's skills up.
00:32:10 [W0] Drain to the new nodes.
00:32:24 [W0] So and then when all the ports are moved then we scale down the altar.
00:32:28 [W0] I'll just kidding group. And as long as the our customers had their poddisruptionbudgets.
00:32:38 [W0] This is also something we test in our testing like we could perform a performance test during a create the next question option strategy.
00:32:52 [W0] Yeah, so what is the adoption strategy within the organization?
00:32:53 [W0] How do you scale out this platform to other teams?
00:33:03 [W0] Yeah, so we started to actually with the first the first mover first-movers, right and we're ready to well.
00:33:05 [W0] Yeah. I'm a high enough level to easily adopt it. Yeah and
00:33:08 [W0] So gradually you see other teams interested and also yeah just to help them out in taking that step towards our platform.
00:33:23 [W0] We have sort of consult see Team set up.
00:33:27 [W0] Yeah, so they are expected to help those different teams to get up and running as well.
00:33:35 [W0] Because of course not all other LT means have the knowledge and to quickly start.
00:33:38 [W0] So long way to go to get the whole list of all of the it teams homework on board.
00:33:55 [W0] Are you next question from Andre?
00:33:59 [W0] Are you deploying also monitoring for customers? Do you have the access to it?
00:34:04 [W0] And then are you also managing it?
00:34:12 [W0] So yeah be for monitoring on the metric so security TPU and stuff.
00:34:14 [W0] We provide a Prometheus installation.
00:34:17 [W0] Together with the alert manager and if an official visualization and in a little magic Compass, we made it possible for customers to send their alerts to their own SNS Topic in AWS and event
00:34:31 [W0] So they can act on these themselves and we do the same Falco for the security monitoring.
00:34:42 [W0] Okay, next question Bluegreen plan is already explained it.
00:34:49 [W0] They also yeah, we say workloads.
00:34:55 [W0] What is that deployment?
00:34:55 [W0] Yeah, we already explained so workloads.
00:34:59 [W0] I mentioned this a deployment or deem set.
00:35:04 [W0] Our customers have running in production.
00:35:05 [W0] and scene
00:35:07 [W0] Next page I guess a lot of questions guys. So we won't be able to answer all of them are the docker images Etc managed and security fixed by the death think themselves.
00:35:21 [W0] So yeah, we have forced our private Registries that are the factory and we have another product of jfrog Keda x-ray we enforce that
00:35:36 [W0] Flowmill probability scale but it's their own responsibility to make sure the images are not relevant.
00:35:47 [W0] We don't enforce certain from abilities and not so they have their own repository. So they are responsible for their own.
00:35:58 [W0] images we have our own responsibilities of compliancy stuff, too.
00:36:02 [W0] So some question about managing database servers, we don't have that.
00:36:20 [W0] Yeah, so at the beginning of the for platform basically told well said just run stateless applications and if you want to state or any the
00:36:24 [W0] The cloud services. So in a TBS you would use RDS or dynamic debate.
00:36:33 [W0] for example, so when end we do start hearing something something to host a state yet, but like single vomit right now.
00:36:47 [W0] We're focusing on a chair instead or of also be shipping state.
00:36:52 [W0] Okay, you manage many cluster. How do you manage it?
00:36:56 [W0] Are you using kubernative cluster manager like Rancher?
00:37:01 [W0] Yeah this already explained right expiration.
00:37:11 [W0] Sorry, it's a really small box.
00:37:15 [W0] Okay.
00:37:21 [W0] What about chicken-egg problem running Katie payment on Kate's itself if I understand your question, right?
00:37:37 [W0] We have a on our production cluster. We do not ruin our go Sheedy insulation.
00:37:46 [W0] We're not in a separate cluster outside of the pipeline.
00:37:50 [W0] So it's not like we are upgrading the cluster with two running in the cluster.
00:37:52 [W0] Insulation if just a little amount of services that you can easily scroll up and down.
00:38:01 [W0] So there isn't really a chicken-egg problem.
00:38:04 [W0] So there's a question why are using different version for the nonprofit forces brought that was explained in this in RCC ci/cd part.
00:38:16 [W0] It's yeah, it should be excluded.
00:38:17 [W0] That should be the same.
00:38:23 [W0] So we also only use it for small periods of time just to make not stop our development workflow.
00:38:27 [W0] Okay, and slide 15 the non production and production environment have each two sets of three connected by arrows.
00:38:42 [W0] What is the difference between a cluster on the left and on the right?
00:38:50 [W0] So this is like the difference between a our customers new production environments workloads and their prediction workloads we first.
00:38:57 [W0] To update all the new production environments just to make sure that they're if there's an issue that you'll notice before we are started grading our production environments.
00:39:12 [W0] Okay, I did I understand.
00:39:18 [W0] It's a Samer control plane.
00:39:31 [W0] Yes, when the managed service from Heroes.
00:39:32 [W0] It's the same of it, but just notice perform a all Bluegreen upgrade. So for a temporarily we double the amount of nodes in the cluster and
00:39:46 [W0] So for temporarily we doubled the amount of nodes in the cluster and that all the bolts get moved to the new notes and then we drain and destroy the old Out
00:39:54 [W0] Ring and destroyed adult and screening room noticed.
00:39:59 [W0] So there's a question about testing see interesting one.
00:40:03 [W0] I'm part of the similar team and we're struggling quite a bit to properly test our platform or do we just run the actual application landscape?
00:40:09 [W0] Oh, yeah, so we had the same issue.
00:40:11 [W0] Yes a lot of our future.
00:40:18 [W0] Yeah, so we have like a
00:40:21 [W0] Test application that uses all the features that I told you about.
00:40:35 [W0] So, for example, we just perform a rolling upgrade of the that application and intramural perform a performance test just to just to check if it's still performing right?
00:40:40 [W0] And just a lot of end-to-end tests like creating a security alert and make sure it's it's gets to our alert box.
00:40:50 [W0] for example, so basically every cycle chain which you want to test. Hello whole flow, right? Yeah.
00:41:00 [W0] a lot of Integrations as you mentioned before and that's the difficult part, I guess of managing such platform.
00:41:05 [W0] What's the reason why you are considering a serverless?
00:41:13 [W0] / explained? We had a lot of customers also working on a jurors on both AWS integer. So they're very interested in remaining in the texture ecosystem.
00:41:22 [W0] It's also our expansion.
00:41:26 [W0] New share your test. Shoot framework.
00:41:31 [W0] No, not yet.
00:41:33 [W0] That's very mostly just using.
00:41:36 [W0] vitess framework
00:41:39 [W0] a lot of questions should skip to the next page which vulnerability to you are using as we explained x-ray.
00:41:52 [W0] Yeah of jfrog.
00:41:54 [W0] This is my box many are we closer as separate product how much additional resource in does this take?
00:42:08 [W0] young fresh out of step with product how much additional resource mistake
00:42:18 [W0] Like Financial cost.
00:42:22 [W0] Sure.
00:42:34 [W0] Yeah, we just do it because a big part of the reason that we serves it. This way is every bu of / of of us focus on different strings have a little bit
00:42:39 [W0] A big part of the reason that we serves as his way is every bu of / of of us focus on different strings and have a little bit different rules for our security and stuff.
00:42:43 [W0] and some workloads just had to be able to run in a separate cluster just for a heart Network separation, for example, so we already knew we
00:42:56 [W0] Ruining a separate cluster just for a heart Network separation.
00:42:56 [W0] for example, so we already knew we had to be able to be flexible with servicing our containerd platform because we already knew front. Some of the be used would not accept one
00:43:08 [W0] We already knew from some of the be used would not accept one large platform.
00:43:13 [W0] So we just made it a variable in the way that you can have a platform for wanting multiple teams for whole bu for example, so that's why we chose for a
00:43:26 [W0] Decentralized concept and not not really out. Of course.
00:43:34 [W0] Are some of the components of sources so where can it be found?
00:43:42 [W0] So yeah, I'll component we use our open source.
00:43:44 [W0] I'm not sure how much time we have left.
00:43:49 [W0] Oh, wow.
00:43:51 [W0] Well, they're still there, right?
00:43:53 [W0] All right, so we have still have four minutes. Okay.
00:44:10 [W0] Did you simplify your platform running it and measure well, we started out sorry this platform. We didn't really well plan to also be built the same
00:44:22 [W0] Sure, not at first no, I mean you didn't not simplify it and we're like I think 85% there.
00:44:35 [W0] There's still a few Nick's we have to figure out but no we didn't did attempt to simplify it.
00:44:44 [W0] We just all the features that are only u.s.
00:44:45 [W0] Or also also be present on the edge, which I guess our Focus was on just delivering the same experience, right? Yeah, so it would have to be working.
00:44:53 [W0] Exactly the same and I guess that's where most of the challenge was.
00:44:57 [W0] Yeah, the plan was for customers in the US and n***** to have the same experience.
00:45:06 [W0] We just provide the community API and that's what they interact with.
00:45:14 [W0] with. So from the front there shouldn't be well at least this as less as possible different.
00:45:21 [W0] Oh, what a documentation.
00:45:31 [W0] What does the documentation for developers and related themes look like it's a very important part actually a lot.
00:45:40 [W0] So yeah, we didn't really in the beginning we quickly found out that documentation was so important just providing all necessary information for them to start up the demo
00:45:47 [W0] And those kind of things are explained in our will a very very detailed right step by step and I guess most of them most of our customer actually.
00:46:03 [W0] It was really helpful having that documentation, you know, you get that when they're actually saying that those kind of things and pay documentation brought us that far and so they're very thankful for that.
00:46:17 [W0] How do you structure the platform in terms of git repositories?
00:46:22 [W0] And what is your branching model?
00:46:24 [W0] So we started out with multiple repositories with separate projects that at some point like the platform.
00:46:34 [W0] platform. There are other components are dependent on each other like so it's some point we had like three pull request in three different repositories, and you have to be merged in the same time table. So after that we just move
00:46:50 [W0] A mano repository when live like other directories being sort of separate products.
00:46:55 [W0] And for branching model, we just use the kit. Imagine your most cherished the production code and a future changes greatly in a separate branch and have to pass to be
00:47:11 [W0] You have to request with if there's another brutal.
00:47:17 [W0] But also biggest frustration during the entire project so far and how did you deal with it?
00:47:33 [W0] Especially considering that you were building a green field solution with a regulated financial service provider biggest frustration.
00:47:41 [W0] I don't know what suppose that was for you but when you started reading stand by there was something we had to get used to so it's not only deaf but also the operations part, right? Yeah, that would be if we had like a large.
00:47:55 [W0] Alert pool and we just had to keep growing it for it too.
00:48:00 [W0] Well be effective.
00:48:01 [W0] Yeah a lot of false positives and waking up at night.
00:48:13 [W0] So if me with Devils a big frustration, so for me the part of us knew but is also maybe just for you as well.
00:48:16 [W0] We are part now of the open source Community doing our own commits right to open source projects, if you use a project you think oh it's there but when you use it,
00:48:25 [W0] Some things are not template eyes or those kind of things.
00:48:32 [W0] Yeah, and then you create a PR and then you have to wait for them to merge it and release it those kind of things.
00:48:34 [W0] Yeah.
00:48:37 [W0] We saw that in a few projects. That was frustrating I guess right.
00:48:40 [W0] S into F in shouted.
00:48:46 [W0] what is the select channel to follow only with you guys?
00:48:48 [W0] So I will select channel.
00:48:51 [W0] So it's official cncf Channel.
00:48:52 [W0] Yeah to keep calm operations Channel.
00:49:00 [W0] We will have keep answering questions over there.
00:49:03 [W0] So thank you very much for joining us and we hope to hear from you.
00:49:08 [W0] you.
