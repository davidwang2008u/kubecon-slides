Capacity-aware Dynamic Volume Provisioning For LVM Local Storage: PXCD-8291 - events@cncf.io - Thursday, August 20, 2020 6:49 AM - 64 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:03:04 [W] Hello everyone.
00:10:58 [W] Hi everyone.
00:11:04 [W] I'm Cosmo estimates. Dad and I woke up sigh both today.
00:11:04 [W] I'm going to talk about CSI driver for kubenetes a capacity of your Dynamic volume provisioning for lvm local storage
00:11:17 [W] Today, I'm going to talk about CSI driver for kubenetes a capacity of your Dynamic volume provisioning for every M.
00:11:18 [W] Local storage.
00:11:20 [W] and my co-presenter is subtle Takeuchi. Also an engineer at cyborgs Japanese crowd service provider of girl prayer.
00:11:28 [W] we are now reconstructing our infrastructure into a kubernative spaced cluster on the improves Miss data center, including today's content about
00:11:44 [W] stories
00:11:46 [W] here is the agenda first.
00:11:54 [W] I'm going to talk about existing ways to use local storage in kubernative then talk about the motivation and challenges of dynamic provisioning
00:12:08 [W] Introduce our Noble CSA program named a top all lbn and give a demonstration.
00:12:18 [W] So, why would we use local storage?
00:12:25 [W] In general persistent storage in kubernative provides on remote storage system such as safe. It also includes storage Services provided by crowd service
00:12:41 [W] such as Amazon EBS
00:12:45 [W] However, the benefits of using local storage still exist which eye-opener for months and reasonable cost.
00:12:58 [W] Of course using local storage in kubenetes has some disadvantages such as topology limitation and redundancy problems, but
00:13:12 [W] for iot bound applications
00:13:16 [W] So if you have a Obama and Rock Road such as my SQL their sticks, let's look at this all also have high performance vehicle storage.
00:13:32 [W] Maybe our presentation might be helpful content.
00:13:34 [W] First I'll show existing ways to use local storage in kubernative the most popular and simple way is host pass maybe which you which you may already know.
00:13:52 [W] A host pass the kubevirt among the hosts file system passed to passing the Pod.
00:14:06 [W] However host past has was not designed to be used for state of all applications.
00:14:13 [W] They did not retain essential attributes such as capacity bound status. And so
00:14:20 [W] of course, it also does not and does not support dynamic provisioning.
00:14:28 [W] automobiles such as capacity bound status and so
00:14:43 [W] of course, it also does not and does not support Dynamic provisioning.
00:14:44 [W] It's mainly used for applications that have control privileges for the whole stories and or collect information about the host. Anyway hospice should not be
00:14:45 [W] Not be used for many things application state or data.
00:14:48 [W] A practical method was presented kubernative 1.14 and that is local persistent volume.
00:15:05 [W] This feature can have topology or earpods scheduling with persistent bomb create once persistent volumes created manually in other words users must
00:15:15 [W] Pass the Senate barriers beforehand, of course, we can utilize some automation tools.
00:15:25 [W] However, that is outside of the persistent volume right cycle managed by kubernative.
00:15:35 [W] Therefore it cannot be dynamic provisioning.
00:15:35 [W] Without Dynamic provisioning supported by kubernative crossed at me his right agree to meet the challenge like this one developer says Hey, I want to run
00:15:53 [W] So, please give me persistent volume, but I cannot say how it will consume disk space.
00:16:02 [W] So 100 gigabytes for now, please another developer says please give me give me a persistent volume for my SQL but service
00:16:16 [W] Addicted but lovely 500 gigabyte.
00:16:21 [W] Another one says in the service has gone over. So I release the Ballroom in kubenetes and the pot life cycle is very rapid.
00:16:37 [W] Last cycle of persistent volume is also quick.
00:16:46 [W] Therefore we can easily imagine the the operation and management or persistent volumes must be collapsed in terms of scalability.
00:16:58 [W] So we need automated Management. In other words. We need Dynamic flow.
00:17:08 [W] prisoner for local storage
00:17:11 [W] Dynamic provisioning is defined in the kubenetes document and that is dynamic provisioning feature eliminates the need for cross the administrators to
00:17:26 [W] Is it it it automatically automatically provision storage when it is requested by users. It provides a charity scalability
00:17:43 [W] For the operation and management of storage.
00:17:47 [W] Essence show Futures mechanisms for dynamic volume allocation and resizing because we cannot determine physical volume sizes for services before
00:18:05 [W] To realize Dynamic allocation.
00:18:16 [W] We have to determine where required persistent volumes can be located and considering the future expansion of boring.
00:18:24 [W] I know that has more free disk space is preferable to all others. Both of them require capacity of are boring scheduling. So capacity of illness is cute.
00:18:37 [W] you Dynamic provision
00:18:39 [W] to achieve capacity of our warmest scheduling. We need to follow two steps the first course the first cautious of gathering capacity Matrix from knows.
00:18:57 [W] To achieve capacity of Airborne scheduling. We need to follow two steps.
00:18:59 [W] The first course the first cautious of gathering capacity Matrix from nose, then the Cellular Field days and scores the nose using capacity Matrix and the required volume
00:19:06 [W] Then the Cellular Field days and scores the nose using capacity Matrix and the required volume size.
00:19:08 [W] The process is depicted on this right first volume provisioner gives us capacity Matrix when spot controller recreates pots are doing the controller should
00:19:25 [W] controllers said past the requested by mm sighs to the surgery room to determine where to locate the pot the cellular filters and scores all nodes based on the capacity metallics
00:19:38 [W] the requested by room size
00:19:41 [W] After that, first change the volume controller will request a boehm from the provisional.
00:19:50 [W] However, the current kubernative does not support capacity of awareness also the cape which proposed how to expose storage capacity to kubernative
00:20:09 [W] Does not support capacity awareness also the cape which proposed how to expose the weight capacity to kubenetes.
00:20:11 [W] It was protested and merge, but policy are doing with storage capacity is ongoing so ahead
00:20:23 [W] Musti is ongoing so ahead of it.
00:20:24 [W] We've implemented a capacity of Airborne provisional for local storage name Will. Topple are VM.
00:20:31 [W] Simplest it we made it it as a CSA program topple. Every M of course has the capacity of your Dynamic provisioning feature and it
00:20:47 [W] It's love rock volume as persistent volume which improves the performance of applications that you can use block devices directory.
00:20:59 [W] Online resizing is also supported.
00:21:05 [W] When me show you the details of topple are VM.
00:21:11 [W] Here is a diagram of the for every m in this figure the bull square boxes on top. Oh NVM components and the round cut boxes indicate the API resources
00:21:26 [W] And it'd be a means kubeedge serger and kubeedge API server respectively external probably gonna is the sidecar container that what is partially
00:21:42 [W] Call the CSI drivers APA to create and buying power system boys.
00:21:51 [W] Let's check out the dynamic provisioning Seekers by top.
00:21:59 [W] Oh NVM first the tougher MVM node learning each server, which server and it and updates its own servers storage capacity to the corresponding
00:22:13 [W] resources
00:22:15 [W] When a pond with PVC is created the curb says Allah will receive a sizzling request then pass it to the top.
00:22:31 [W] Oh NVM schedule and the top.
00:22:34 [W] Oh NVM schedule fifties and swore scores.
00:22:37 [W] Ono's based on the intention of capacity Matrix.
00:22:42 [W] Once the location of the pot is determined the external provisional called the top.
00:22:58 [W] Oh NVM controllers APA with the topology key that is not named.
00:23:01 [W] The top. Oh NVM controller create a custom resources usuals limit top logical volume with the node name and the requested boehm size.
00:23:16 [W] Each top. Oh NVM nodes each point. We note what is this custom resource? And if is for its own node, the top of every node will create
00:23:34 [W] boom
00:23:35 [W] And update the status the custom whistles.
00:23:40 [W] The top.
00:23:47 [W] Oh NVM controller, which is watching the status of custom resource when detecting this update the top.
00:23:58 [W] Oh NVM controller, which turns the volume information as the return value of the API call.
00:24:03 [W] Therefore the external provisional can create persistent volume with the volume information.
00:24:13 [W] Okay, I will give you additional explanation for the capacity of your bombers a drink as I mentioned briefly each topical area note just as capacity of
00:24:31 [W] Small storage this metric is written to the node annotation the this way with specific and Tatian key topple every inside bol.com capacity.
00:24:48 [W] Top. Oh NVM has admission mutating web.
00:25:01 [W] It's for modifying pots back according to it requesting volume size like this.
00:25:06 [W] It ensures that the top. Oh NVM schedule can get the requested bones sighs.
00:25:13 [W] We're the kuma seizure.
00:25:14 [W] The club cetera is implemented as an extension of kubeedge schedule, which means the kubeedge cellular calls the web hook of top.
00:25:29 [W] Oh NVM surgery with a pot of manna Fest according to the previous mentioned information and the Top Eleven cellular can judge which node must be filtered.
00:25:43 [W] We can calculate scores of North to determine where to locate the pot.
00:25:52 [W] The scoring expression is here.
00:25:58 [W] That is the logarithm to base 2 is very simple.
00:26:02 [W] I'm also going to touch and the ramifications or topple lbm. Although you can get some redundancies using other techniques such as Wade one, but it does not provide.
00:26:20 [W] Level redundancies because volume just located on the local disk.
00:26:36 [W] So the boring stuff I'd buy topple lvm and should be years by applications.
00:26:39 [W] can be redundant themselves for example, dbms databases and distributed storage systems such as my secret safe.
00:26:52 [W] Okay, next we will give a demonstration of top or every please subtle.
00:27:01 [W] Okay, I have some demos of top.
00:27:16 [W] lbm are introduced following three features that causes store mentioned in this presentation.
00:27:21 [W] Here is a software and Hardware configuration in this demo.
00:27:26 [W] There are two worker nodes kind of worker and Kyle Walker to kind of worker has one volume group named my bujji. Wang that Hearts 18 giga byte three space and kind
00:27:42 [W] Also have 80 gigabytes free space bottom group my Bridget to both might be G1 and my budget to manage the by top. Oh NVM
00:27:54 [W] I'll use 3 terminals in this presentation.
00:28:05 [W] So first one is Operation terminal to issue could be control command.
00:28:10 [W] For example kublr control get node shows three notes.
00:28:16 [W] The first one is control plane and the second wall and sidewalk is worker nodes kind of worker and kind of work are too.
00:28:23 [W] And the second terminal is connected to kind worker node so we can get the information on my bridge one from here.
00:28:34 [W] My body wants free space is under 18 Giga bites.
00:28:39 [W] On the last terminal is connected to kind worker 2 and we can get the my bujji tools information.
00:28:50 [W] It's free space is under 18 gigabytes.
00:28:54 [W] So since both my veggie wash and my budget to manage to buy top of zebrium we can get the free space on my veggie wash and my veggie to from the jeez.
00:29:10 [W] Olds know the results of the control gate node kind welcome.
00:29:19 [W] I don't know. Oh, yeah, MO.
00:29:21 [W] okay, please see the this annotation topple lbm does cyborg bol.com capacity this annotation means free space of
00:29:37 [W] You want so it's about 18 Giga bytes. Okay.
00:29:42 [W] The next one is gonna be kind wakatu kind of worker to also has this annotation and the value is same as my bridge ones its corresponding to the
00:29:58 [W] Was free space the it's also under 18 Giga bites.
00:30:03 [W] Okay.
00:30:06 [W] So first the demo is about Dynamic volume provisioning.
00:30:17 [W] So let's schedule a port named nginx one. This port is uses one gigabyte bottom.
00:30:22 [W] Yes, but one okay, my persistent Bloom claim topple BBC One request 1 Giga bytes from top of lbm and nginx one
00:30:38 [W] Is couple people schwa and is mounted in powder blue W HTML. Okay, please note that there is no percent volume resource.
00:30:54 [W] There are only busting boredom creme and pottery salts.
00:30:58 [W] And of course could be control get zebrium.
00:31:16 [W] Okay, so they expect every expected result here is that persistent boreum is created dynamically, okay.
00:31:28 [W] So let's confirm the control get caught.
00:31:35 [W] okay nginx one is running and we control get people she okay Topo here. We see one is created and bound to be we see Barbara
00:31:49 [W] The next one is running and we control get people she okay Topo here. We see one is created and bound to be we see Barbara
00:31:52 [W] Already have a created dynamically by Topo lbm.
00:31:54 [W] Okay busted worry, so we found that persistent volume is created dynamically. So we found Dynamic volume provisioning
00:32:11 [W] walk the fight
00:32:13 [W] And as a side note, we can get the this problem is correspond to the logical volume in my pretty one.
00:32:29 [W] So first Bridget display shows the free space is decreased to change the chromatin gigabytes to 70 gigabytes.
00:32:39 [W] And we display show.
00:32:53 [W] Okay. This poem is dragic. Our volume is corresponding to the post and volume and posted bottom. Crane new porcelain body. Okay, so calls the kuma
00:32:57 [W] It know the kind of worker its capacity is changed. It was about 18 Giga bytes. Now.
00:33:13 [W] It's it's about 17 gigabytes.
00:33:16 [W] So the next next demo is about capacity our scheduling also present preparation.
00:33:33 [W] Let's exhaust kind worker to support him groups now.
00:33:36 [W] Can you work out tutorial group Bible G2 has 18 Giga bytes free space to exhaust this Podium. Let's schedule our pot and nginx to to kind of worker to
00:33:48 [W] 17 gigabytes for you
00:33:51 [W] let's go to
00:33:56 [W] Okay, top of B, which is 2 it has 17 gigabytes and consumed by nginx to port and this nginx to Port is bound to kind of worker to okay.
00:34:11 [W] Why?
00:34:15 [W] 420k commitment wrong with you get bored.
00:34:24 [W] It's on they're creating for his way to Hawaii.
00:34:25 [W] So the top of PBG to and corresponding volume is under creating.
00:34:39 [W] Okay nginx to is now learning to become total get people are probably okay 70 gigabytes.
00:34:50 [W] So get node kind f*** too.
00:35:02 [W] Okay, it's the might be tools capacity is now and the 1 Giga bytes.
00:35:14 [W] Of course, we can find it from kind worker to okay, my G my bridge eTools free space is on the one gigabyte, okay.
00:35:24 [W] So now kind of Walker to the capacity is under warranty yugabyte.
00:35:33 [W] Why pot gee sport of the G-Spot views are one gigabyte for you.
00:35:58 [W] Please note that the kind of worker tools. My bujji to is has only has only under one gigabyte of free space.
00:36:07 [W] So it doesn't it doesn't have enough space to create.
00:36:12 [W] date one gigabyte boring
00:36:14 [W] Sorry.
00:36:22 [W] Many ports, okay.
00:36:34 [W] Double BBG 3 is request one gigabyte and consumed by GX 3 and it's same as four five six
00:36:41 [W] Okay, it's upright.
00:36:45 [W] we're going to roll up the LIE many ports.
00:36:47 [W] Okay.
00:36:49 [W] So the expected result here is over put schedule to kind worker.
00:36:57 [W] Okay.
00:37:00 [W] it's because nginx to know my zebrium. IBG to doesn't have enough space. Okay.
00:37:06 [W] So we control get bored.
00:37:10 [W] Okay, it's already running.
00:37:17 [W] And nginx 327 or all these pots learning and in learning in kind worker.
00:37:31 [W] It means that this port not evenly spread in the spread over kind worker and kind of worker to it because
00:37:43 [W] Two doesn't have enough space.
00:37:46 [W] Okay, so then to poetry am select kind of worker as node to be scheduled, okay?
00:38:01 [W] So we confirm all pots schedule to kind of worker without toppling over M.
00:38:15 [W] So some ports will be scheduled to schedule to kind of work out too, but it failed to start because the
00:38:27 [W] Confirm or pot because you're too kind of worker without top.
00:38:29 [W] Oh NVM, some some ports will be scheduled to schedule to kind of work out too, but it failed to start
00:38:30 [W] Our boreum is cannot be created.
00:38:34 [W] Okay, so we confirmed that corporate capacity is scheduling in-toto lbm worked fine.
00:38:43 [W] So the next and last demo is about online volume resizing.
00:38:50 [W] So it's very simple just just expand nginx ones volume to 2 gigabytes nginx one's body.
00:39:04 [W] Umm is top Opa which one to Poppy which one is kublr control the control gate 50b. She topple PVC one.
00:39:14 [W] yes, it has one gigabytes and corresponding wire system is mounted in nginx 1T f
00:39:30 [W] Okay.
00:39:34 [W] it's about www HTML HTML its size is about one yugabyte.
00:39:39 [W] Okay, so to expand BBC it's very simple ready to just edit if we see double gives you one.
00:39:52 [W] The current requested bottom sighs is 1 Gigabyte.
00:40:07 [W] So what should I do is just change this value to 2.
00:40:14 [W] So, okay. So expanding job is kicked.
00:40:17 [W] So Google control get BBC double BBC One
00:40:23 [W] Yes not it's not changed yet.
00:40:28 [W] It's and they're expanding so more precisely precisely the boring logical volume corresponding to topple PBC wall is now under
00:40:41 [W] Expanding and after that Topo lbm expands the query system inside this logical boy.
00:40:55 [W] So is it down? Okay.
00:40:59 [W] It's changed it to 2 gigabytes.
00:41:00 [W] It's expanded.
00:41:03 [W] So other side note it's event is get can be get from kublr control with this chronosphere.
00:41:10 [W] By BBC top of each one.
00:41:24 [W] Okay, the when I changed I edited the BBC resource. This event is kicked external expanding and
00:41:29 [W] This means resizing poem.
00:41:34 [W] And resize file system started to resize file system and by stimuli side successful, it's done.
00:41:45 [W] So, let's see the this part things whilst them inside inside nginx one to you, but www HTML
00:42:01 [W] It's expanded to two weeks ago bites, okay.
00:42:05 [W] So expected result is 2 power P. Which one is resolving sized. Okay.
00:42:18 [W] Okay. The second one is the corresponding file system is resized also a checked so we can grant or I'm ballsy. I'm resizing feature or top. Oh NVM worked fine.
00:42:30 [W] So the demo is done.
00:42:33 [W] So here is takeaways of the presentation topple lbm is a local storage Dynamic provisioner based on Lem and it enables capacity our airport to
00:42:49 [W] Wang is to own local station storage.
00:42:53 [W] And we saw both continue to develop topple lbm and the top elotl B and M is not a toy program about Target to Blair Williams.
00:43:08 [W] Target is to use production use
00:43:10 [W] So here is the community and links or topple lbl please join us.
00:43:19 [W] Thank you very much.
00:43:20 [W] That's all.
00:43:21 [W] How do I be run?
00:43:28 [W] I'm cause which though but today and thank you for listening for our presentation.
00:43:43 [W] My co-presenters Otto is unfortunately opposite because sickness so I'll handle QA / by myself.
00:43:46 [W] Okay. I'll pick a question.
00:43:53 [W] Okay.
00:43:56 [W] Deuce through what will happen if the notes that there's a pot with schedules and the note and people we are located
00:44:15 [W] VM and does not delete the PB and there is a node is the rigid nor the resources deleted from APS double.
00:44:30 [W] So you need to delete the node resource or the PB directory. And then the cabinet is where we create the pot.
00:44:40 [W] It means top of every a week with a new PB for the pot, right?
00:44:45 [W] Okay, next question. I have only few minutes so
00:44:58 [W] Okay, Andy's.
00:45:07 [W] When out what will happen when it's born cannot be extended carry over to insert ribbon.
00:45:24 [W] It is show in custom whistles.
00:45:27 [W] In my presentation name a logical volume in in the state that state s and shows the error top of everything cannot expand the volume.
00:45:41 [W] Okay.
00:45:44 [W] I try to pick up next next question.
00:45:57 [W] Okay.
00:46:07 [W] Where is the current rate of sorry and I have no more time. So I love up my presentation.
00:46:25 [W] Please. Don't forget we can discuss in school because of the Frog channel on storage and of course in the top of the top waving suck if you want to
00:46:38 [W] Joins top. Oh NVM shock and please check through with me in the GitHub repository top.
00:46:49 [W] I have m / top of every so okay.
00:46:53 [W] That's all and let's continue the discussion on the swac storage to ack.
00:47:01 [W] Okay.
