Introduction to Strimzi: Apache Kafka on Kubernetes: YPAO-4973 - events@cncf.io - Wednesday, August 19, 2020 6:59 AM - 51 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:15 [W] So thank you very much for joining us.
00:00:20 [W] We are going to talk about strimzi a project about running a Kafka on kubernative.
00:00:27 [W] I am a Palapa tierno and I am here with Yahoo Schultz.
00:00:29 [W] We are both maintainers of the strimzi and we are going to talk about it in the next few minutes.
00:00:38 [W] Let's start from Kafka.
00:00:40 [W] So Kafka is an open source project originally created by LinkedIn and at the beginning Kafka was
00:00:44 [W] and as a publish/subscribe messaging system because at the end Kafka is a messaging system, but over the years the use case is around Kafka are changed.
00:00:59 [W] There are more use cases about using Kafka for doing some analytics on data in real time.
00:01:07 [W] So today Kafka is even defined as a data streaming platform, but at the end Kafka is a distributed fault tolerance.
00:01:13 [W] Hi I have available commit.
00:01:15 [W] Log, but Kafka is not just about the Brokers.
00:01:19 [W] So the components which are in charge to exchange the messages between the client so the consumer and the producer but it's more a broader ecosystem with more components on the right-hand side. You can see for example,
00:01:34 [W] Next which is a framework for moving data between different system using Kafka like for example, moving data from one database to another you can also see mirror maker meet your maker is used for
00:01:49 [W] Data between two different Kafka clusters running maybe on two different data centers in the cloud.
00:01:58 [W] for example coming to the clients.
00:02:04 [W] So talking about consumer and producer and the apis for the clients.
00:02:07 [W] There are a kind of low-level apis.
00:02:11 [W] So consumer and producer API that you can use for developing your application for sending and receiving messages, but there is even a more complex API, which is the strimzi P I4 bridgecrew.
00:02:20 [W] Writing more complex application for doing some analytics in real time on the data flowing through your calf Castle Kafka is able to ingest this data in real time and you can use this strimzi API for doing some complex.
00:02:35 [W] Like filtering mapping and so on.
00:02:41 [W] There are also some third-party tools.
00:02:50 [W] So other tools in the Kafka ecosystem, which are not part of the Kafka Upstream project, but can be used for interacting with the Kafka but why this point running Kafka on kubernative? So on one side we
00:02:56 [W] We'd Kafka but why this point running Kafka on kubernative?
00:02:57 [W] So on one side we have Kafka which is a system distributed by nature and even the applications and workloads using Kafka are also distributed a scalable by
00:03:09 [W] Send the workloads using Kafka are also distributed a scalable by Nature on the other side.
00:03:11 [W] We have kubernative kubernative provides a great abstraction layer for running your software everywhere.
00:03:22 [W] So you can run kubernative some bare metal or you can run kubernative. Zon any cloud provider like Jesus or AWS IBM and Google and you can move your software on any of these platforms or
00:03:32 [W] Has your AWS IBM and Google and you can move your software on any of these platforms or on bare metal or on a cloud provider if you have kubernative under it, so you have just using kubernative for
00:03:40 [W] Provider if you have kubernative under it, so you have just using kubernative for running your application and you can move your application everywhere.
00:03:47 [W] So kubernative is enables the cloud native development, but having on one side Kafka and on the other side kubernative some people who has no knowledge about kubernative why they should learn more about
00:03:59 [W] Who has no religion about kubernative why they should learn more about Kafka not using the knowledge that they already have about kubernative for running Kafka on kubernative.
00:04:09 [W] This is where strimzi comes so strimzi is an open source project.
00:04:14 [W] It's a cncf sent Book Project since last year more or less and it's mostly focused on running Kafka on kubernative as I already mentioned.
00:04:23 [W] and so it provides some container images for Kafka for zookeeper because Kafka needs a do keeper and Sam in order to work today, but even images for all the other components that are
00:04:38 [W] Scott of the strimzi ecosystem as we will see in a little bit strimzi provide some operator. So it's based on the operator pattern in order to deploy handling your cuff clusters and even
00:04:53 [W] Around the coffee cup, but we will see more with the demo that Yahoo is going to show us so strimzi provides really kubernative knative experience for us in order to end all cuff count kubernative.
00:05:09 [W] Is it really kubernative knative experience for us in order to end all Kafka on kubernative?
00:05:10 [W] Why because it's not only about a Kafka clusters, but even about the users and the topics and even all the other Kafka components in the Kafka ecosystem, but why I say that
00:05:24 [W] But why I say that strimzi provides a kubernative knative experience for Kafka because in kubernative we have different objects, right like for example pods.
00:05:38 [W] Ford said deployment Secrets config map and so on. They are the different kubernative knative resource that the user can use today, but in kubernative there is also a way for extending the kubernative CPI.
00:05:54 [W] So strimzi provides some custom resource definitions in order to to make real decent kubernative negative experience for Kafka. So it means that we strimzi.
00:06:07 [W] We have a new Kafka resource.
00:06:08 [W] So you can create your kubernative resource of kind Kafka where you can describe your cluster and all the configuration, but it's not just about Catholic has already mentioned even for all the other components in the strimzi ecosystem.
00:06:23 [W] Like for example, you have a resources for Kafka users and Kafka topic for engineering users and topics in the cluster.
00:06:37 [W] But you also have Kafka connect and Kafka connector resources for deploying a Kafka cornet.
00:06:38 [W] Deployment so all the worker nodes related to Kafka connect, but even for interacting with Kafka connect for running the connectors, which are the components needed for removing the data between the system using
00:06:53 [W] Kafka then there is a gap bridgecrew resource for deploying a bridge HTTP bridge in order to allow HTTP client to interact with your cupcake luster.
00:07:08 [W] So using the HTTP protocol then we have a couple of resources for mirroring so cough computer maker and cuff computer maker to because they provide the way to deploy the two different version of mirror maker that today are
00:07:22 [W] Right in the Kafka Upstream project so for doing mirroring across Kafka clusters and last but not least. We have a Kafka rebalance resource, which is used for doing a rebalancing on the cluster. So moving the
00:07:36 [W] Partitions across the the the cluster to the brokers in order to have a more balanced the cluster not having he be loaded Brokers compared to some other Brokers that are not
00:07:51 [W] So hosting partitions so they have no traffic from the other clients.
00:07:59 [W] So it's a way for rebalancing the cluster using cruise control, which is supported by strimzi say that I would like to hand over to your Kuma not there to show you everything.
00:08:09 [W] I just say in order to see how all this kind of stuff works using strimzi.
00:08:12 [W] Thanks, Paula.
00:08:19 [W] Let me share my screen.
00:08:20 [W] And I'm here already connected to my burner T's cluster. And in this demo, I will show you that deploying covets strimzi is fairly easy if you ever worked with the operators before
00:08:36 [W] Or you know that the first thing which we need to do is deploy the operator so to deploy strimzi operator. I will use a script from our website.
00:08:51 [W] So HTTP as strimzi dot IO / install latest and my name space is my project.
00:09:04 [W] equals here
00:09:07 [W] Enter the total install the operator for me the installation really consists of all the usual files, which you will find in installing applications on kubernative.
00:09:22 [W] It's the custom resource definitions for the custom resources mentioned already by Paolo. It's all the different Arabic files to give the operator the access rights and then things like a service account and then last but not least.
00:09:35 [W] It's the deployment.
00:09:37 [W] Which actually contains the operator so if I do now Cube CTL get pots I can see the operator is already running.
00:09:50 [W] There are also other ways how you can install the operator.
00:09:53 [W] So on our website or on the GitHub page, you can download llamo files directly to install it from there.
00:10:01 [W] We have also Helm chart.
00:10:02 [W] And then strimzi is also on the operator Hub. But I also you can also install it easily from there. So you can really choose whatever fits you best.
00:10:17 [W] Now, if you know the operators, you know that the next thing which I will do will be to create some custom resource for those who don't know that much about operators yet. The custom resource really extends the kubernative API
00:10:29 [W] To add some own resources in our case.
00:10:36 [W] I will be using here Kafka resource and then the resource is created.
00:10:44 [W] Then the operator will see it and it will make sure that it deploys the Kafka cluster accordingly and it doesn't just do the deployment and installation, but it will also make sure it is managed while it is running
00:10:53 [W] I think it keeps running and it can take care of things like certificate renewals upgrades new versions and so on the custom resource really serves basically as a blueprint for the Kafka cluster.
00:11:09 [W] This one is one of the more simple one it's free just specifies the version of Kafka which we should use number of replicas.
00:11:21 [W] It configures the Kafka listeners perverted clients will be connecting some configuration. It configures the storage and then because Kafka depends on the Zookeeper as a kind of dependency to bootstrap
00:12:25 [W] Is to apply the resource.
00:12:27 [W] And the operator will basically immediately see it and it will start deploying the odds. So what we can see here is that it's already deploying The Zookeeper cluster so we can see zookeeper pots 0 1
00:12:43 [W] And to and the operator will wait until the Zookeeper cluster is ready until it is bootstrapped and prepared to work. And only when that happens it will actually move to the
00:12:58 [W] deployment so you can see that the Zookeeper pots are not getting ready and now it will provision the Kafka storage using the storage class and persistent volume claims and
00:13:13 [W] You know to Kafka pots starting as well.
00:13:23 [W] And again, it will wait until the TUF car crossed. ER is ready and available and then it will deploy The Entity operator as
00:13:31 [W] Paula mentioned we have also custom resources for users and topics and that's what the entity operator is responsible for.
00:13:47 [W] And as you can see the whole process is quite fast.
00:13:57 [W] really depends a lot on how fast your internet connection is and how quickly the container images will be pulled and so on. So now we can see that
00:14:01 [W] Kafka is there The Entity operator is now deployed and when that is ready, it will deploy it Kafka exporter.
00:14:14 [W] And in this demo, I'm really showing just deployment of the Kafka cluster but more or less in exactly the same way. You can also deploy the cuff connect or the mirror maker or for example the http
00:14:24 [W] Breach so density operator is now deployed now just the Kafka exporter.
00:14:35 [W] And once the cupcakes Porter is ready, then basically the whole cluster will be deployed and available and we can check that by doing Cube CTL get Kafka
00:14:53 [W] Which shows us that we have this my cluster of Kafka resource with free cuff connotes and free zookeeper nodes and we can also do get it in llamo and we can see that these are for example addresses
00:15:09 [W] The Kafka clients can connect this one is using load balancers from the outside. For example from my laptop.
00:15:19 [W] This one is from applications running inside the cluster and then we can also see that the state of the cluster is ready.
00:15:26 [W] So now we have the cluster running and we should deploy some application, right?
00:15:34 [W] So let's start by preparing some user for that application and the topic and that's where we will use the entity.
00:15:40 [W] Operator so for the user we have the Kafka user resource in my case.
00:15:46 [W] The user is named my user and inside this resource.
00:16:01 [W] The relation I can also specify the authorization rules.
00:16:05 [W] I can say that is user should be allowed to use TLS authentication and I can also because I'm using
00:16:09 [W] So for example, in my case, I give you the right to send messages to Kafka topic which is called my topic and I allow it to consume the messages from this topic as well and
00:16:18 [W] I just apply the resource that we created and because we selected that we want to use TLS client certificates for our convocation.
00:16:36 [W] Then I can click and there should be a secret called my user which is the same as the username which was created by the entity operator and which contains the authentication details for
00:16:48 [W] Connecting to for out indicating to the cluster and when I check the details of what's inside the secret we can see that it has basically the user key and user certificate which I will use for Authentication.
00:17:03 [W] And if I choose some different mechanism for example success crankshaft for using username and password, then the secret will contain the password for authentication instead of the certificates.
00:17:20 [W] And so this is when you want to manage the users locally, but it's not the only option which we have you can for example use for the authentication all out of using oauth tokens and manage the user centered in your
00:17:35 [W] All server and you can use also for authorization or for example, we have also an option to use open policy agent for authorization.
00:17:46 [W] So that was the user next we need to create a topic for that.
00:17:53 [W] We have a resource called Kafka topic and I'm great at creating unique name. So I call it my topic it will have 12 partitions and three replicas and I can also add the config section where I
00:18:06 [W] Specify all the different details for this topic. And again, I just apply resource to get the pocket created and the great thing about
00:18:21 [W] This is that I do not really need to remember all the commands from Kafka all the tools all the options all the parameters and execute them somewhere, but I really just have this custom resource in
00:18:36 [W] More which I can use and then with the topic and the user ID.
00:18:42 [W] We have to deploy the application. Right and I have here really just some simple hello world producer and consumer which run as a deployment, but the nice thing is that because the
00:18:55 [W] Entity operator created the secret with the credentials for the user.
00:19:09 [W] I really just need to mount the secret as a volume or use it as environment variable and I can use the certificates from it for the out indication.
00:19:15 [W] So I do not need to copy them anywhere. I can really just use the kubernative API for this when I apply it.
00:19:20 [W] We can check that the pots are starting and we can check in the lock of the consumer that it is actually receiving some messages as you can see.
00:19:39 [W] It's really just a sample application.
00:19:44 [W] So it's really just sending every second some Hello World message. But yet it shows that it works and the great thing about having the Kafka user in Kafka topic resources.
00:19:56 [W] is that when you develop your application, you can basically take all these resources the kubernative deployment the Kafka user and the Kafka topic you can for example store it in the GitHub together with your application and then for example you some gitops tooling to
00:20:09 [W] to get that automatically deployed and it can travel with the code together with your application through the test environments production and so on and you
00:20:24 [W] Really need to have some complicated installation guide book, which would explain how to create the topics or the users in Kafka.
00:20:31 [W] And I also wanted to show that while strimzi makes it easy to deploy and manage the Kafka cluster.
00:20:42 [W] It's not really just something for playing locally.
00:20:44 [W] We really support the features that you need to run production clusters. And we have of course users using strimzi in production. So for example, what I get automatically out of the box are things such as Prometheus monitoring so I can see here
00:20:57 [W] Microphone on this board that I have three Brokers.
00:21:03 [W] I have 186 partitions.
00:21:05 [W] I can see all the different metrics right now. Of course with the hello world application the throughput in the cluster is very small, but you get this all built-in including the kubernative
00:21:18 [W] The Griffon addition boards and some sample alerts and things like that. So yeah, that's it for this demo and back to Paulo.
00:21:31 [W] So thank you very much yaakov. It was a great demo showing.
00:21:41 [W] What is the kind of kubernative knative experience for handling a Kafka cluster, right?
00:21:47 [W] So jakub showed us some of the features that strimzi provides but strimzi as a lot of features so you can see here showing up different features like
00:21:59 [W] Scaling up and scaling down easily. You can just change the number of replicas on your Kafka resource.
00:22:09 [W] You can even use a finite and coloration in order to define the nodes where you would like to deploy your Kafka Brokers instead of other pods. You can even enable the encryption so having TLS as showed by jakub
00:22:19 [W] Clients, but even internally between the Brokers you have a CL sending for handling the rights for writing and reading from the topics for the users as already mentioned integration with Chris control Kafka
00:22:34 [W] The HTTP breach mirroring secrets are used for storing the credentials and certificates.
00:22:45 [W] You also have metrics from all the components.
00:22:51 [W] So from the operator itself from Kafka from zookeeper Kafka contact and so on and we provide some graph on a dashboard that Yahoo! Showed about showing all these metrics through Prometheus, of course, so
00:23:00 [W] these are a bunch of features or part of the features that strimzi of course provides today, but other than the built-in features we can also say that strimzi really integrates pretty well with some other cncf projects
00:23:16 [W] Like of course kubernative also with the helm because we provide Helm charts for deploying strimzi.
00:23:29 [W] There is of course the integration with Prometheus exposing the Matrix and showing them in Ravenna fluently. For example is support for Kafka that you can deploy on kubernative C using strimzi records. There is an integration with jaeger
00:23:38 [W] Tracing for for doing some freezing so tracing traps. So getting some trading information about the messages exchanged between clients through Kafka topics and even integration with the OPA.
00:23:54 [W] So the open policy agent for the authorization so that you can specify and described using Opa.
00:24:04 [W] what are the topics that a consumer can read the producer can write and so on and there is also integration with key data, which is pretty new in cncf today and it's a project for event-driven
00:24:18 [W] In complication, so can you can Auto scale your Kafka based application using a Kafka scalar provided by Keda and you can of course deploy your Kafka cluster alongside Kedah using strimzi.
00:24:33 [W] So there is a great integration with all this kind of project in the cncf family at this point.
00:24:46 [W] What's the way you kind of call to action for engaging with the community with the Upstream community in strimzi. First of all, you can
00:24:47 [W] just go on strimzi website and download strimzi.
00:24:53 [W] Try it locally on some cloud provider. So your kubernative installation.
00:25:04 [W] You may be can found some back running strimzi entrance themes it so it will be great submitting the bug so you can hope and GitHub issue in our GitHub repo explain about the bug and
00:25:14 [W] So on your kubernative installation, you may be can found some back running strimzi entrance themes it so it will be great submitting the bug so you can hope and negative issue in our GitHub repo
00:25:15 [W] It will be great that you could even open a pull request on the Kita proposal submitting your code, but you can even submit your code if you have some is new ideas around strimzi.
00:25:29 [W] So you want to propose some features to add to strimzi self.
00:25:32 [W] You can also help with the the documentation so not developing stuff, but writing documentation improving the documentation that we have today if you find some typos
00:25:44 [W] If you would like to make clear some part of the documentation that you didn't get well while going through the documentation itself and you can even help translating the documentation in your language. So for making strimzi
00:26:00 [W] Bowl across the world in different languages, you can even join our chat room.
00:26:09 [W] We have a room in the cncf slack workspace. You can of course follow us on Twitter.
00:26:19 [W] We have a strimzi Twitter account where we tweet about a new release new blog post new features in strimzi, but you can also help us spreading the word so talking
00:26:28 [W] And maybe the project where you are using strimzi or some ideas that you have around strimzi at conferences and meetups or even writing articles or blog posts.
00:26:44 [W] And if you don't have a place for blogging you can of course blog with us so you can contact us and you can write your article on the official strimzi website in our
00:26:56 [W] Say that what's the way for reaching the Upstream community?
00:27:05 [W] Of course, there is the official website. So strimzi dot IO there is a strimzi organization under get up.
00:27:11 [W] It's an organization where all the components in strimzi ecosystem leave.
00:27:15 [W] So like for example the operator, of course the the HTTP breach the oauth library, but even some client examples for for interacting with the Kafka cluster deployed by strimzi.
00:27:26 [W] The Twitter account that I mention and even the strimzi room in the cncf slack workspace.
00:27:37 [W] We also have a mailing list in order to interact with us.
00:27:38 [W] Just sending an email.
00:27:42 [W] So I guess that that's all on our side.
00:27:44 [W] I really hope that you enjoyed this session and that you will go and try strimzi and we will be really happy to know from you from having some feedback for improving this project and maybe
00:27:56 [W] Sing with us in the future. So thank you very much.
00:27:59 [W] Thanks for joining our session.
00:28:09 [W] I hope this was useful for you.
00:28:12 [W] There are a lot of questions.
00:28:15 [W] There you can join and we can continue the discussion there and you can of course also asked in the in the select channels as well and we are also running strimzi survey.
00:28:41 [W] So if you are interesting to help us know more about your requirements and missing features and so on and please go to our website there you find a link and you can fill it in.
00:28:54 [W] So let's have a look at some of the questions which we got.
00:29:05 [W] First of all there's our two questions, which are a bit similar one is better. There are plans to replace zookeeper.
00:29:14 [W] And another one is whether there is any Initiative for unifying common dependencies like zookeeper, which are used in a different projects. So
00:29:24 [W] The Kafka perspective is a bit different.
00:29:29 [W] So if you follow the Apache Golf Community zookeeper is being slowly removed from the Kafka project and should be not needed in the future and since strimzi focus on upper cheek of card and we will basically follow that up and
00:29:43 [W] As it is removed from Kafka. We will then use only Kafka not need zookeeper anymore.
00:29:55 [W] So that way we will just upgrade and get food not deployed zookeeper anymore.
00:30:04 [W] And I think the current time expectations are maybe around end of this year or beginning of next year when this might happen in the Apache Kafka project.
00:30:06 [W] Then another question was did you try to run it with is Theo so I personally didn't run strimzi VT still but we have users using strimzi together with is
00:30:22 [W] Zero right now doesn't kind of tightly integrate into is Theo and run as a part of his deal.
00:30:33 [W] So the users who are using this boat together. They always configure we still too kind of exclude strimzi from the from kind of the sto sidecars and not use them
00:30:42 [W] To do all the traffic and instead kind of road traffic to strimzi and the Kafka Brokers as to an external application so you can run it together, but it's not for the running strimzi as part of
00:30:58 [W] another question was whether there is any road map for all the different projects and features of strimzi if you go to our GitHub organization,
00:31:13 [W] There's a GitHub project which is used as a road map where you can have a look and yeah, if you think we are missing something then we can definitely edit right now in the strimzi.
00:31:28 [W] There's a lot of work going on around you I which would allow to manage strimzi and Kafka itself like the Kafka topics consumer groups.
00:31:42 [W] So that's for example, one of the big things coming.
00:31:43 [W] Being in in the future. Then. Another question was the strimzi also include components such as ASR rest proxy Kafka manager, so we include
00:31:58 [W] Components but not all of these we have our own race proxy, which is integrated into strimzi.
00:32:13 [W] We have support for cruise control for balancing the cluster and that's all built in and as I said, we are working
00:32:21 [W] On on the UI and some kind of rest API for also managing the things a bit more so not all of these are really built in but some of these are and the rest
00:32:36 [W] The usually connected really as yet another calf operator. So to be honest, you do not always need operator for anything. Some of these things are just easier to deploy as the regular deployment that for example includes
00:32:51 [W] schema registries
00:32:52 [W] then another question was how would one perform performance tuning on strimzi?
00:33:03 [W] For example number of disks, which can affect the performance or if you can specify on which types should the Brokers running so you can definitely do it.
00:33:16 [W] Strimzi support all kinds of different environments starting from the kind of basic minikube environment, which the users can run locally up to the big public clouds.
00:33:32 [W] Are not always enabled by default, but you can for example use Affinity in the configuration to Define on which nodes should the Brokers be scheduled.
00:33:47 [W] We also support the j-bot storage.
00:33:54 [W] So if you want you can specify that you want the Kafka clusters to use multiple disks, and we will then just create these discs and mouth.
00:34:02 [W] Mount multiple of them into single pot and that way you can kind of use more storage or get better performance from the individual Brokers and you can also
00:34:17 [W] Use most of the different Kafka configuration options to tune the performance.
00:34:31 [W] So the operator itself manage some of them related to things like TLS and listener configuration, but all of the differents buffer sizes and number of threats and so on you can easily configure it
00:34:38 [W] And that was the last question, which I managed to answer.
00:34:50 [W] There will be a threat on the slack where you can continue asking the questions.
00:34:59 [W] And as I said in around 25 minutes, we have meet the maintainer session. So feel free to join there as well and you can continue answering the questions there.
00:35:04 [W] Thanks for coming for our talk and QA.
