gRPC Easy: PRYK-5199 - events@cncf.io - Wednesday, August 19, 2020 11:38 AM - 1141 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:02:03 [W] Hi, I'm Richard Belleville, and I'm a software engineer at Google on the grpc team.
00:02:12 [W] I am at Nelson on those things get up and Twitter for example, and today I'm going to talk about a project. I've been working on called grpc easy. First a little bit about myself.
00:02:22 [W] I have been working for Google for about a year and a half now primarily on the python bindings before that. I was working at a smallish networking company called add Tran. I'm glad that I spent time there.
00:02:30 [W] First because it gave me kind of perspective.
00:02:35 [W] The thing about small companies is that everyone tends to be less specialized if we generalize in order to cover all of that ground needs to be covered.
00:02:47 [W] So in my time there I got to help build and maintain a custom messaging framework as well as build our own container orchestration framework before kubernative became the de facto standard and then migrate accumulated kubernative. Once we saw the writing on the wall.
00:02:54 [W] Since Google is such a big company.
00:02:57 [W] Most people are hyper focused which can sometimes lead to myopia. So I'm glad I had my experience in my previous company as a
00:03:00 [W] Member of the Target demographic for grpc because I think that's enabled me to empathize with our users a little bit better than I otherwise would have. Okay so enough about me.
00:03:09 [W] let's talk about grpc. Although this talk is called grpc easy.
00:03:14 [W] This is not an introductory talk on grpc.
00:03:20 [W] Ruined tends to be less specialized.
00:03:30 [W] you have to be generalizing were to cover all of that ground needs to be covered. So in my time there I got to help build and maintain a custom messaging framework as well as build our own container orchestration framework before kubernative became the de facto standard and then migrate to keep United kubernative once we saw the writing on
00:03:31 [W] Probably pause me and go watch that talk or one of the other various intros talks now.
00:03:36 [W] For the benefit of those of you who are watching live.
00:03:45 [W] Let's do a very brief recap of the structure of an application using grpc grpc is an RPC framework RPC standing for remote procedure call when you boil the fat. This means that we're a library and a set of development tools that enable you to Define and
00:03:56 [W] Grpc is an RPC framework RPC standing for remote procedure call when you boil the fat.
00:03:57 [W] This means that we're a library and a set of development tools that enable you to Define and call a function so that it runs on a different machine from the caller though.
00:04:04 [W] It could run on the same machine if you set things up that way technically speaking grpc is a protocol not a library.
00:04:10 [W] There are many implementations of that protocol.
00:04:13 [W] There are there are the original go C++ and Java implementations donated by Google that cncf.
00:04:15 [W] And there are other community Source implementations like the one built into Envoy, but when I talk about grpc in this presentation, you can safely assume that I'm talking about the original implementations built by Google since they're the oldest most robust and most popular.
00:04:29 [W] So by default grpc is a point-to-point client-server model where the client and server can be in different languages very much like HTTP Json rest. The difference is in the payload in the different concurrency model you can use so
00:04:46 [W] Ancient of the collar and the Kali need to know the API in the ABI the application binary interface by default but not as a requirement grpc uses protocol buffers for that. So you can see an example of what a protocol buffer service definition looks like here.
00:05:01 [W] You define a function insane see so that's what grpc is.
00:05:09 [W] What about its users and how they feel about it?
00:05:13 [W] Well grpc is found very wide usage in the data centers of big high-traffic companies.
00:05:20 [W] You can see some of them listed on our homepage grpc dot IO you got Netflix Cisco Juniper square and a bunch more. So what do we hear from these users?
00:05:22 [W] Well, we here at the well-supported you have a preferred language odds are we've got binding the tooling for it you want on Windows?
00:05:31 [W] We got you.
00:05:31 [W] You need to run an arm.
00:05:32 [W] No problem.
00:05:35 [W] We hear that. It's performing at the transport level. We introduced very little overhead. A lot of complex logic has been put in place to ensure maximum performance for multi-threaded applications and protocol buffers being a binary serialization format cut down substantially on the amount of time you would otherwise be
00:05:47 [W] Lies in Json you got the same DJs on project on Hacker News a while back.
00:05:57 [W] That was a project that applied some lessons from a pretty buff white paper to the task of serializing and deserializing Json but because Json isn't knative Li a binary format.
00:06:01 [W] It's still not as fast we hear that it's robust one's got a bug report for a server that crashed after a year of serving we fixed the bug but learned that we were down to once a year sorts of bugs in the stack and they say that it's safe the interface definition language provided by prodyna Buffs
00:06:15 [W] Yourself in the foot by sending an accidentally malformed request to the server.
00:06:21 [W] It's like using a statically typed language after being forced to use an untyped language forever.
00:06:26 [W] But is it easy to use?
00:06:30 [W] I don't think I've ever gotten that sort of feedback before very often the task of the migrating these organizations to grpc lands on the shoulders of a platform team like and IPC Team part of the reason for that. Is that migrating from an existing messaging system
00:06:42 [W] Very often the task of migrating these organizations to grpc lands on the shoulders of a platform team like and IPC Team part of the reason for that. Is that migrating from an existing messaging system can be tricky. The part of it is likely that using grpc itself isn't always that
00:06:46 [W] The part of that is likely that using grpc itself isn't always that easy. And we sometimes get positive confirmation on that from smaller organizations and individuals struggling to roll out grpc.
00:06:53 [W] The grpc team regular we scour stackoverflow and answer as many questions as we can this here is just a sampling of python related issues that we've seen now, it's unavoidable.
00:07:10 [W] Whatever your project is that some users are going to have questions about it that if you want to be inclusive and popular your goal should be to minimize the level of surprise and of cognitive burden for everyone as much as possible.
00:07:17 [W] When I first started on the grpc team, I was somewhat uncomfortable with the API and workflow at worked with other tools that were used to use in the past and my gold standard was the python request Library.
00:07:27 [W] I'm going to wager the majority of people watching this talk of used requests. Even if python is that their daily driver why well one python is easy writing integration tests. Do it in Python writing a supporting scripts doing python working to Startup and need to move fast.
00:07:46 [W] Hey, it worked for Reddit do it in Python to the request library is easy.
00:07:52 [W] You can sneeze and accidentally send some Json to a different continent personally.
00:07:58 [W] I think this is one of the major reasons why HTTP, Json rest has become so very very popular.
00:08:02 [W] User-friendly libraries.
00:08:14 [W] Abel I was going to kick out of the first comment to this just this ultimately was the goal of the grpc Python Library lower the barrier to entry so that anyone no matter what size organization there are part of can say screw it this one off server is going to be a grpc server.
00:08:31 [W] We can write it in the client in an hour.
00:08:38 [W] So one day I decided to want about my issues with the library to piece of paper.
00:08:45 [W] This was eventually transformed transformed into a design doc. But at the time I just called it a complaint back there were a lot of little things but there were really
00:08:47 [W] two main friction points that I saw
00:08:49 [W] The first had to do with protocol buffers.
00:08:58 [W] I went to lurk around GitHub people pulling in our library so I can see exactly how they use it.
00:09:00 [W] My first observation was that the vast majority of people are not Advanced use of the API.
00:09:08 [W] The second thing I noticed is that people have absolutely no idea what to do with protocol buffer definition files.
00:09:18 [W] So unlike rest your PC as a buildpacks step, even if you're using an interpreted language like python or node, you featured a Proto file which contains your service definition, you know your functions,
00:09:19 [W] Sure into the protocol compiler and it spits out code in your language of choice that you can blend your client and server code now internal Google.
00:09:30 [W] This is all abstract it away from the user.
00:09:33 [W] There was a paper published in ECM back in 2016 that describes in detail with Google Source control build and test systems look like called believe why Google stores billions of lines of code and a single repository.
00:09:45 [W] Doesn't scatter its code base across dozens or hundreds of tiny git repos connected together by package managers like is fashionable in the open source Community stays instead.
00:09:57 [W] Google's code base is live at head.
00:10:00 [W] Every source file is in a single code Base called Google 3 and an internal build system called Blaze tracks every source file and every intermediate Target so that the build system is completely hermetic you can add a printf statement is deep in your dependency tree as you want recompile and just immediately see
00:10:13 [W] The build system is General enough that they created a rule set that allows you to say.
00:10:20 [W] I have a DOT prodyna file and I want a library in C++ or Java and then you can just add a dependency on that library is simply as if you were any simple as if you're pulling in a library in your target language, I believe the use case of protocol buffer code gen
00:10:32 [W] So we a driving factor for the crazy generality of place which by the way has relatively recently been open sourced this battle.
00:10:45 [W] So developers in Google don't have to worry about what they do with your generated code as far as they're concerned.
00:10:47 [W] The fact that the code is generated and isn't just a third party Library they're pulling in is an implementation detail, but that's not the case for open source users at me open language agnostic build systems are exceedingly rare. So while they're Integrations with Maven and setup
00:11:01 [W] Other language specific build systems you still have to figure out how to integrate with those specialized rules. And then you have to be the one to worry about how you pull down the protocol buffer files from a central source and what to do with the generated code. So what do most people do the simplest thing?
00:11:16 [W] They copy the dot profile so they have one copy their client repo and then one copy of their server.
00:11:28 [W] Okay. Now these two have to stay in sick every time you or anyone else makes an update to the service definition or to a message definition. They have to remember to update both
00:11:35 [W] One that's called naissance if you're looking for the exact software coupling term.
00:11:36 [W] I guess if you've copied your dot profile across multiple Repose now you struggle with the protocol compiled command line interface there at least three flags that you're gonna have to deal with one of the Tells it where to put the generated code for serializing and deserializing messages one that tells us where to put generated
00:11:51 [W] First and one that tells it what director your protocol buffers living if you're doing a helloworld service, this is all in the tutorial on our website.
00:12:07 [W] But once you start pulling in multiple dot profiles or you have expectations about what language specific module the code should be important well as in for a fun time, so people may be figure that stuff out.
00:12:13 [W] If not, the probably hand modify the generated code.
00:12:15 [W] seen that on GitHub of here a few times. Now when you check in hand modified generated code the next person that makes an update to the dot Proto file is in for a nasty surprise.
00:12:27 [W] Rise not only do they have to figure out how to use the product protocol compiler.
00:12:30 [W] They've got to figure out the hack the previous person added on top of the generated code recipe for disaster.
00:12:37 [W] So in practice the people who are successful with protocol buffers tend to store all of their organization organizations dot Proto files and a single repo and then pull that repo into their client and server Repose using get sub modules then they integrate
00:12:46 [W] Use the product protocol compiler.
00:12:47 [W] They've got to figure out the hack the previous person added on top of the generated code recipe for disaster.
00:12:48 [W] So in practice the people who are successful with protocol buffers tend to store all of their organization organizations dot prodyna files and a single repo and then pull that repo into their client and server Repose using get sub modules then they integrate
00:12:49 [W] Until they're using so that developers don't ever have to deal with generated code directly. So that's the first point juggling protists.
00:12:58 [W] The second big pain point is channel management now channels are sort of a grpc specific Concepts generally speaking grpc is built on top of each to P2, which is in turn built on top of TCP one of the improvements in performance of
00:13:08 [W] Is built on top of HTTP 2 which is in turn built on top of TCP. One of the improvements in performance of grpc comes from the fact that you don't spin up and tear down a TCP connection every single time. You make a request a channel represents
00:13:16 [W] Up and tear down a TCP connection every single time. You make a request a channel represents one or more TCP connections across which our client balances its requests based on load balancing configuration.
00:13:25 [W] I actually heard a good joke about this sort of thing. Once an HTTP Library walks into a bar and orders a beer.
00:13:31 [W] It takes the beer and walked out of the bar one second later.
00:13:36 [W] It walks back into the bar and ordered another beer takes it and walked out of the bar and so on and so forth often HTTP library is unnecessarily.
00:13:41 [W] Finops in teardown TCP connections some http1 libraries have got the message on this and maintain their connections between requests but it's not Universal. So grpc is current approach is to get the application off of just how us when they're done ordering beers at
00:13:55 [W] Cheston's some http1 libraries have gotten the message on this and maintain their connections between requests but it's not Universal. So grpc is current approach is to get the application off of just how us when they're done ordering beers at which point the closer channel the TCP
00:13:57 [W] Channel the TCP connection to shut down and the memory used to manage the channel is return the system but in practice we don't think people closing their channels ever.
00:14:10 [W] In fact, we often see servers that need to send Downstream requests spin up a new channel for each request they receive and they don't ever close those channels memory leak nasty surprise for them down the road and we see this sort of problem not just with open source users,
00:14:21 [W] Go we introduced a contact manager based API to combat it that just didn't seem to be enough.
00:14:32 [W] Even if you do use the contact manager version. It adds an extra level of indent in it isn't very pretty to look at.
00:14:34 [W] So with those problems in mind.
00:14:36 [W] mind. I try to create a before and after picture for grpc python just like requested.
00:14:38 [W] So here's that before and after picture on the left, you see the before we import the grpc library and then import our to generated files then in the main function.
00:14:54 [W] We first construct a stop whatever wrote the symbol greeter stub into r dot profile, but we have to use it. Nonetheless.
00:15:03 [W] Honestly, I usually have to look in the generated code to remember what that name should be. Then we construct a pretty buff request payload make an RPC against the Local Host using this tub and request a message and finally we print out there.
00:15:12 [W] That's not a great delivery on the idea of a function called but on another machine so you see we're using a contact manager here to manage the lifetime of our Channel.
00:15:26 [W] I know for my GitHub lurking that usage of this form isn't very common people general just create their Channel and don't close it fire-and-forget.
00:15:33 [W] And of course we have to generate our code using good old prodyna C for python.
00:15:38 [W] We provide the PIP installable grpc iot tools package that bundles prodyna C and grpc python plug-in now the right you can see our attempt to getting closer.
00:15:42 [W] From a DOT profile at runtime instead of remembering that there is an underscore pb2 or underscore pb2 grpc suffix.
00:16:04 [W] You just import the dot profile that you've written and chose the name of and is checked into Source control the object you get back.
00:16:09 [W] It's a python module object that you can name it whatever you like in general.
00:16:11 [W] I like to call them Proto's and services.
00:16:17 [W] So we create a request message and then in a single line, we send our message and receive the response function. You invoke is greater that say hello, which is exactly what we wrote.
00:16:22 [W] Not profile no need to remember arbitrary suffixes or to look them up from the generated code. You may accidentally checked in.
00:16:28 [W] Okay, so let's look at things a little bit more depth first.
00:16:46 [W] There's the runtime dot profile parsing with these new functions do is integrate with a python import live model import labor module to instantiate modules directly from a DOT profile and your python task.
00:16:50 [W] task. This depends on the presence of the grpc iot tools package that you've traditionally used to build time that bundles this extension that does the actual parsing and coach at for prodyna box.
00:16:57 [W] What's really nice about this? Is that it bear? It lowers the barrier to entry for prototyping change some fields around in your not profile.
00:17:06 [W] No need to recompile.
00:17:08 [W] Just restart your client or server.
00:17:13 [W] Runtime parsing while developing and pre generate the code when you're ready to put it into production alternatively if you're Distributing your application as a wheel. You can now just include your dot profile in the wheel instead of generating python code from it and including that.
00:17:36 [W] The other big change that we've made is channel pooling now instead of manually creating a Channel of in creating a stub from that channel.
00:17:53 [W] You can do something that really does just look like calling a function. Of course. This is backed by the same sort of channel that you would have used before. It's just lazily instantiate it and keptn a process Global cache after configural period of time without any use channels will be
00:17:59 [W] To be made is channel pooling now instead of manually creating a channel then creating a stub from that channel.
00:18:01 [W] You can do something that really does just look like calling a function. Of course. This is backed by the same sort of channel that you would have used before.
00:18:01 [W] It's just lazily instantiate it and keptn a process Google cache after if you figure we'll period of time without any use channels will be evicted from the cache without any intervention from the author of the application.
00:18:06 [W] will work for all four areas. Not just you touring as this picture here and all those are Eddie's work exactly.
00:18:09 [W] Please use it as you'd expect the the new API will exist alongside the current apis where you manually manage your channels and your free to continue to use those whenever you do feel that you need to manually manage those channels.
00:18:24 [W] That any intervention from the author of the application.
00:18:25 [W] This will work for all four.
00:18:25 [W] are these not just you touring as this pictured here and all those are these work exactly as you'd expect the the new API will exist alongside the current apis where you manually manage your channels and your free to continue to use those whatever you do feel that you
00:18:28 [W] Now let's run through a slightly more complicated example to see what these new apis really look like in action pretty much every time I give a talk on grpc.
00:18:35 [W] I build out the same example key value store because it's about the simplest non-trivial thing.
00:18:39 [W] You can build using grpc.
00:18:43 [W] If you want to see a full in depth build out of this example.
00:18:44 [W] You can just look my knative on YouTube.
00:18:47 [W] There's want to go and another in Python.
00:18:51 [W] I'm going to be building up on the python example, and I'm only going to be showing off a client here since the improvements. We just talked about in the past couple of slides are
00:18:55 [W] Are really only on the client side. If you like, you can actually pull down the Go version of the server from three of these talk and test it out against the client code from today's talk likewise the client code we available on my GitHub.
00:19:10 [W] So the key Value Store were building is really just a network accessible version of this data structure in Python.
00:19:19 [W] You can sort of value under a particular key, you can get a value under a particular key and you can check whether a particular key exists within the store.
00:19:24 [W] store. It's nothing very fancy.
00:19:27 [W] Okay. So this is what our protocol buffer definition it looks like we've got a record consisting of two strings the key and the value we've got three different kinds of requests to follow best practices for Prototype based apis, and then we've got our three methods get record
00:19:41 [W] And update record. So what does the client code for this look like?
00:19:46 [W] Well sure it is you'd expect the original version of this client that use the existing apis was several hundred lines, but out over multiple files.
00:20:02 [W] This new client is about a hundred fifty lines in total. And most of it is actually our parse.
00:20:08 [W] Most of the implementations are single line to invoke the RPC and then a single line to print the results.
00:20:12 [W] You can see one new argument here, which is insecurity equals true.
00:20:16 [W] This was actually a point of debate when designing these apis who wanted to make things as easy as possible, but in 2020 yugabyte
00:20:19 [W] Don't want to make anything in Secure by default.
00:20:24 [W] So the default is actually TLS encryption.
00:20:30 [W] And if you want to do a plank Jack's connection for unit testing, for example, then you have to opt in with this explicit keyword argument.
00:20:36 [W] So that's basically the set of new apis. But while we're on the topic of making grpc easy, there's already a lot of great stuff in the grpc ecosystem that I just don't feel is as well known as it should be so let's
00:20:46 [W] Could it really from GitHub? It is a command line tool for grpc servers.
00:20:54 [W] It's basically curl for grpc servers.
00:20:56 [W] I think that says about 80% of it the really cool thing about this is that if you don't necessary is that you don't necessarily need to write the sort of client that we just spent the last few slides looking at for simple use cases.
00:21:08 [W] You can just write a shell script that uses grpc curl to be curled was written by Joshua Humphreys who's a developer at full story.
00:21:15 [W] He gave a presentation on the tool at gopher con 2018. So take a look.
00:21:17 [W] Look at that if you want more details on it.
00:21:23 [W] So here's an example usage of GOP curl to interact with the key value store.
00:21:24 [W] We just talked about there's a playing tag plaintext flag here because again in Secure by default bad, there's the payload which is defined in Json here.
00:21:33 [W] There's the server Target and there's the fully qualified method that we want to invoke boom outcomes of record, but there's a catch we supplied Json how did grpc curl know how to serialize that to the binary form. It doesn't have access to the protocol buffer.
00:21:47 [W] Jen's we didn't tell it where they were all the secret actually lies on the server server.
00:21:53 [W] I ran this against exported reflection server.
00:21:54 [W] What does that mean?
00:21:59 [W] There's a grpc service definition that allows a server to tell interested clients exactly what methods it has and what the in messages and out messages look like so when we ran grpc curl here what happened was the grpc curl process first
00:22:09 [W] Question server at the Target be specified use the information that learned to serialize our Json into a protocol serialized format.
00:22:22 [W] The catch is that you have to choose to export a reflection server on your target.
00:22:29 [W] It's really easy in all languages just a couple of lines of code, but it's an opt-in process in there are certain instances in which you may not want to for security reasons for example, but the function is actually even cooler than this but it really gives you more than anything else is discoverability
00:22:37 [W] And there are certain instances in which you may not want to for security reasons.
00:22:37 [W] for example, but the function is actually even cooler than this but it really gives you more than anything else is discoverability without looking at documentation.
00:22:39 [W] You can ask grpc.
00:22:41 [W] Well to tell you the exact schema that any given server of spects the verbs that you want to use for this our list and describe they allow you to explore an API.
00:22:52 [W] Of course, you also could have just supplied grpc Crow with the path of the prodyna on your file system and that it wouldn't have needed to query the reflection server.
00:22:56 [W] So that is as far as tips and tricks for making grpc easy goes, but I'd like you to know that we're absolutely receptive to contributions and suggestions to do with usability.
00:23:11 [W] So if you have an idea or even just complaint, please provide us with more feedback, one of the hardest things about maintaining an open source project. Is that more often than not when something is broken or difficult to use we never hear from that user. They just drop the library.
00:23:22 [W] So we definitely do value the feedback we hear from our existing or potential users the two places that you would want to
00:23:27 [W] Feedback are one of the several GitHub repos that has been fermentation or the grpc - heiio Google Group, which is where we sort of conduct official business like API extension proposals or just answer questions and the apis that you saw here today
00:23:42 [W] The next release of grpc if you want to try them out before then you just pull from our nightly builds.
00:23:48 [W] So with that I think we can move on to questions.
00:23:50 [W] Hello, everybody. Glad to see you all live now think we're gonna go ahead and get started with questions.
00:24:05 [W] So please forgive me if I mispronounced any of your name's I'm sorry about that.
00:24:12 [W] First one. I see is from Deepak any provision to generate uml model from proto-earth.
00:24:17 [W] It's possible that such a tool exists within the community ecosystem.
00:24:21 [W] haven't seen one if you did want to build one. I don't think it would actually be
00:24:26 [W] It's very difficult.
00:24:29 [W] The protocol compiler has a system of plugins that can just be binary is on the file system.
00:24:37 [W] There's an environment variable that allows you to tell the protocol compiler where to look for those and it's very simple format where it takes a serialized protocol buffer message on standard n and it outputs codon standard out
00:24:48 [W] For example take in an arbitrary protocol buffer and output a uml file in any format that you'd like.
00:25:04 [W] So Chandra asks, when would you use grpc rather than when you went would you not use grpc?
00:25:12 [W] So let's start with reasons why you might not want to use grpc in any particular circumstance. So let's say that, you know,
00:25:19 [W] Or in a setup where you don't necessarily have full support for HTTP HTTP to on your data path, right? There might be some ll7 proxies that aren't going to support it fully there might be some.
00:25:34 [W] Events that aren't going to support everything you might be running in a browser.
00:25:39 [W] that doesn't support trailers, which is most of them at the moment.
00:25:46 [W] I will say for a caveat there is grpc web which allows you to get most but not all of the functionality of grpc and requires a proxy in the metal.
00:25:54 [W] So those are circumstances where you might choose not to use grpc.
00:25:59 [W] I did give you a bunch of Pros the beginning of this talk of grpc like type safety. For example, the the other big
00:26:05 [W] Area where you're going to want to use grpc is where you need streaming or your have very you have a lot of sensitivity to latency, right?
00:26:20 [W] So in an event driven model, you don't want the clients to be polling because polls always have a cool-down between each pole. What you want is for the server that sources the events to push them to the client.
00:26:29 [W] That's when grpc streaming is going to be incredibly valuable to you on the next one Deepak asks does prodyna
00:26:35 [W] Of support inheritance and composition this really good question.
00:26:40 [W] So composition very basic feature of prodyna Buffs. You can arbitrarily Nest message types inside of each other and that's going to allow you to do composition as for inheritance.
00:26:53 [W] Which means that an application that uses any particular message is able to add their own Fields defined by their file with within those extensions.
00:27:19 [W] So that's that's something akin to inheritance Chandra asks when there's a simple client server architecture.
00:27:25 [W] Would you still recommend grpc versus normal rest?
00:27:34 [W] Absolutely. The other thing that I will say there is people sort of build this false dichotomy between grpc and
00:27:35 [W] Rest rest technically is a set of semantics for how you build your apis and you can build a restful grpc service.
00:27:49 [W] It just means that you need your art our PCS to be resource oriented.
00:27:57 [W] I think maybe what you're asking here is about HTTP Json rest, which is sort of people will light it to rest these days but in general I would say yeah, you can use grpc and I need
00:28:05 [W] Where you use rest plus other areas Christian asks, what about using golang for grpc / Proto?
00:28:20 [W] Is there also a way to directly make use of the dot profiles? If yes, how is code completion handle than an ID. He's if know, what do you recommend here check in generated code?
00:28:27 [W] He's to be resource oriented.
00:28:35 [W] I think maybe what you're asking here is about HTTP Json rest, which is sort of people I'd it to rest these days but in general I would say yeah, you can use grpc and any place where you use
00:28:36 [W] Same way the reason that it works in Python and node and could potentially work in PHP. And Ruby is because when you say food bar, you know you access a bar member of a
00:28:50 [W] Those languages. You're literally doing a Dictionary lookup right.
00:28:56 [W] You're looking up that symbol bar at runtime.
00:29:01 [W] That's not what's happening in the compiled languages in the compiled languages.
00:29:08 [W] They see a compile time that I'm looking for this member bar and that it translates it to sort of an offset or some other mechanical look up from the the serialized protocol buffer message.
00:29:16 [W] So you need those protocol buffer a header files or dot go files at componentconfig.
00:29:20 [W] Pile time you could in principle do something similar, but the way that you would access the Proto's individual members of a protocol protocol buffer message would be very different and not quite as idiomatic.
00:29:35 [W] So that's the first part of the question you couldn't principal do it.
00:29:36 [W] I wouldn't recommend it.
00:29:41 [W] The other question was if know, what do you recommend here check in generated code?
00:29:46 [W] I would still say try your very best not to check in generated code.
00:29:47 [W] a couple things you can do here. The first one is going to be I meant
00:29:54 [W] That internally to Google a build system called leis is used that's been open sourced as a system called basil.
00:30:05 [W] I actually think that the go tool chain was inspired by a lot of the features in blaze.
00:30:07 [W] You could just use Dazzle.
00:30:11 [W] I think best practice is to include your generated files in your get ignore file if you're using git.
00:30:27 [W] Bart Bart Smits asks is using the profiles from runtime also available in Java.
00:30:37 [W] No not to my knowledge.
00:30:39 [W] But with the same caveat as in the previous answer that you could in principle use reflection apis to read from a DOT profile at runtime.
00:30:52 [W] But again, since it compile time, you don't have access to the the symbols that you would need to access things.
00:30:56 [W] It wouldn't look like idiomatic Java in order to access an individual member bar of a message fluentd.
00:30:59 [W] Nami tasks, although it is making it a lot easier for the client but still the client needs to understand that it's working with the grpc server.
00:31:11 [W] Is there a way that we can a completely abstract this?
00:31:12 [W] Not sure I fully understand the question.
00:31:19 [W] Okay. So yes, if we're talking about differences between a client and between an actual local function call and one against a grpc
00:31:31 [W] Addition to the arguments.
00:31:38 [W] There's also the target server the location of the target server and there are things like transport level security.
00:31:47 [W] So one thing that I already called out the transport level security you could make that you could include SSL credentials and by default it will use SSL credentials if you don't Supply anything there
00:31:57 [W] Is the surfer Target right?
00:32:02 [W] So how can you abstract that away there? It's not exactly a completely abstract it away. But there is a lot of work going into the set of X DS protocols which mean that you can abstract away the
00:32:16 [W] Their server that you're going to and you can use a control plane like sto or traffic director on gcp that allow you to abstract out to an abstract service name, but doesn't correspond to a particular server's IP.
00:32:31 [W] Host name and those can change. Dynamically that would help to abstract that away a little bit.
00:32:41 [W] I don't know if that fully answers your question though.
00:32:45 [W] Alex asks any plans to add more officially supported languages in the future.
00:32:50 [W] So I'm wondering if this is about grpc in general or if this is about the features that I discussed here today.
00:32:57 [W] I'm assuming that this is about General language support. No, I do not know of plans for additional.
00:33:02 [W] Languages but they're popping up in the community all the time. For example coplin support recently came around I know of multiple rust implementations that have been coming around if you keep your eyes peeled you will
00:33:17 [W] Languages coming around and if you have any language that you care about in particular, it's not too difficult to wrap the grpc core which is which is it used to be a plane.
00:33:32 [W] C89 set of apis that you can wrap a higher level API around now it's C++, but there it is a relatively stable set of API so you could in principle build a new language around that relatively easily.
00:33:47 [W] And those are all the questions I see right now. So I am going to head over to the slack and I'll be available there for at least the next 15 minutes.
00:34:03 [W] Thank you everybody for attending today.
00:34:07 [W] and I think that'll be it for the talk.
00:34:07 [W] Thank you.
