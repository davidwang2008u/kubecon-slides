From Alert Notification to Comparison of Good and Bad Requests in One Click: TYQW-2980 - events@cncf.io - Tuesday, August 18, 2020 8:22 AM - 77 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:02:38 [W] Hello everybody.
00:07:36 [W] Good morning.
00:07:37 [W] Good afternoon.
00:07:37 [W] Good evening. Depending on where you're located.
00:07:41 [W] My name is Chris today.
00:07:43 [W] We're going to talk about how we can make use of the current state of the art Integrations between metrics and traces to speed up and improve root cause of issues particularly.
00:07:57 [W] We're targeting the use case of comparison of good and bad request to root color shoes quick background about myself.
00:08:03 [W] I'm a technical leader chronosphere webassembly.
00:08:04 [W] Rebuilding hosted metrics and monitoring platform for large scale High to produce cases.
00:08:13 [W] I primarily focus on the applications and metrics and traces to solve different observability problems previously before chronosphere.
00:08:21 [W] Everybody good morning. Good afternoon.
00:08:32 [W] Good evening, depending on where you're located.
00:08:33 [W] My name is Chris. Today. We're going to talk about how we can make use of the current state of the art Integrations between metrics and traces to speed up and improve root cause of issues particularly.
00:08:34 [W] We're targeting the use case of comparison of good and bad request to root cause issues a quick background about myself.
00:08:35 [W] I'm a technical leader chronosphere where we're building.
00:08:36 [W] Hosted metrics and monitoring platform for large scale High to produce cases.
00:08:38 [W] I primarily focus on the applications on metrics and traces to solve different observability problems previously before chronosphere.
00:08:41 [W] I was in The Observer. He might ruber working on the alerting platform there the agenda for the talk today is kind of split up into three sections will first go over kind of like the experience
00:08:45 [W] today in route causing issues with an initial entry about different observability signals with follow that up on basically on a journey talking about deep linking metrics and traces and how that can
00:08:47 [W] And how that can actually get us to tomorrow, which is kind of jumping from an alert to request comparison.
00:08:53 [W] to start off with let's talk about some observable these signals of Interest the three primary signals are interested in for today or kind of like metrics logs and traces so jumping through each of these metrics
00:09:09 [W] Been around for a long time.
00:09:14 [W] They're one of the most commonly used tools for observability.
00:09:16 [W] the restructured their fast and efficient aggregate both the Korean collection time.
00:09:25 [W] They're efficient from a storage perspective as they store aggregate information, which makes them a really good tool to kind of identify high-level issues.
00:09:35 [W] But this you stopped short of being able to debug issues in detail, so they're not very detailed on a permanent basis.
00:09:41 [W] And you cannot see like request response information and detail that's where logs and traces come in.
00:09:55 [W] Now the widely used and have been around for a long time fast Log search has made it useful for basically search and group cause they are structured sometimes with sometimes. They're not
00:10:41 [W] Standing and debugging microservices or different chord pattern. We're going to model it the restructured historic context information about the whole like API calls being made the
00:10:55 [W] Will like API calls being made the instrumentation is normally implemented in libraries like RT C libraries or wherever there's a transfer of execution context.
00:11:05 [W] So this means the initial setup with instrumentation requires a lot of planning and work. But once an application is in is instrumented using tracing users, and we need to ensure to pass around
00:11:17 [W] Unfortunately Trace has become very verbose as they contain the full request response information describing every Network cop leading to storage class leading to high storage costs.
00:11:34 [W] So like we need some form of sampling to limit. The costs of tracing sampling is a tough problem as you need to pick like what you want to store for the tracing information to be useful.
00:11:47 [W] Are many ways people lose trembling like head based sampling and I kill bass like adapter sampling but many of these end up like losing critical like events, especially for the ones which actually occur infrequently.
00:12:02 [W] Yeah, so moving on I want to talk about like an on-call issue and Engineers gets woken up at the middle of the night.
00:12:14 [W] He gets an alert saying a particular end point is seeing higher latency these so how does the engineer actually like walk through like debugging this issue?
00:12:28 [W] So the alert basically has some context information on it, whether it's an email or page that context information.
00:12:34 [W] Has pointers to perform on a graphs or some other visualization system?
00:12:44 [W] the first action may actually be to go visit the Griffon a dashboard and try to see what's going wrong dashboard can have multiple graphs defending graph in this case is basically the request latency histogram graph
00:12:54 [W] I think that some requests are taking much longer than others.
00:13:01 [W] This is what we actually need to investigate there could be many reasons for this.
00:13:10 [W] It could be any of the dependencies being slow or just an issue and application itself tracing could be useful here to resolve the issue.
00:13:20 [W] So the user probably wants to use traces or logs to debug further now traces are logs need to be searched.
00:13:24 [W] Based off some tags, but the graphs themselves need to be easily readable sitting get to the actual like tags on the metrics.
00:13:39 [W] You may need to go to a different view where now you get some tags on the metrics which here kind of a thing with the endpoint the instance the job or some other information now kind of armed with this tag information we can
00:13:50 [W] Debug further now traces are logs need to be searched based off some tags, but the graphs themselves need to be easily readable sitting get to the actual like tags on the metrics. You
00:13:51 [W] Desert races for for the root cause for the current scenario, let's talk about using traces this slide shows a Jaeger searchview.
00:14:17 [W] This particular case.
00:14:19 [W] Jaeger is a widely used cncf project for distributed tracing. So once we have the tags, we can basically search for the appropriate races using using Jaeger.
00:14:24 [W] We probably also want to use the latency numbers from the metric to actually search for a target range for Target race, like within the latency range that we are interested in so firstly user probably wants to find the trace with the
00:14:31 [W] That we are interested in so firstly user probably wants to find the trace with the high early can see the trace kind of details and number of steps.
00:14:37 [W] It's doing there's an API call to dispatch a customer which has to look up the customer and that look up has to go to reduce or my SQL in this little case.
00:14:48 [W] It seems like MySQL actually has taken quite a bit seeing this. You probably want to see like what the lower latency Trace
00:14:58 [W] Actually did so you basically kind of make another search to look up to look lower latency Trace when you look at this, you see that the MySQL call doesn't exist. So it was probably my SQL having the problem
00:15:11 [W] see a tree is different view which you are supports like comparing both of these traces, especially useful and larger traces and it's kind of clear that the culprit here is actually my SQL and yeah
00:15:27 [W] you can kind of use that information to go further and root cause things further to trace differences are really powerful tools to help you cause issues, but actually making use of Trace differencing is not very easy
00:15:42 [W] Able to search for traces with kind of specific characteristics which in most cases is not a trivial task moreover, like sometimes like traces for like rare circumstances may not even be present.
00:16:00 [W] Question is like can we actually jump directly from this email that we got directly to a truce difference in you?
00:16:10 [W] In the current like with the current technology and Jaeger search.
00:16:20 [W] This is kind of difficult because metrics to not have like Trace associated with them but some work on deep linking metrics and traces that my colleague Rob's Killington presented a q Khan San Diego. Last number actually makes this
00:16:30 [W] We first kind of go over a summary of that work here before we talk about how we can leverage that work to basically make getting that race differences much easier.
00:16:47 [W] So moving on like talking about kind of deep linking metrics and traces with this kind of with this.
00:16:59 [W] this. It's actually possible to associate like metric symmetric data point with a representative Trace, so
00:17:02 [W] Normally as a recap like the way we did it earlier.
00:17:08 [W] Like how do we actually use metrics and traces together?
00:17:13 [W] The scattered integration is to use kind of tags to map between metrics and traces these tags need to be similar like or same like so that when you get to lurk around something you can actually
00:17:23 [W] For appropriate traces and other challenges that even if you try to search for the traces the traces may not be present due to sampling.
00:17:36 [W] Yeah, but with you some of the latest versus Technologies, it's actually possible to jump to traces directly from metrics lot of this work is currently like working progress
00:17:48 [W] It's possible to store the trace and span IDs alongside the metric data points giving away for us to go directly from a metric to a trace.
00:18:01 [W] We will walk through kind of the different steps needed to make this possible.
00:18:09 [W] The first thing we want to talk about is kind of openmetrics and exemplars.
00:18:15 [W] So openmetrics is a standard for transmitting metrics that scale one of the things it specifies is an
00:18:19 [W] Ended Prometheus Exposition format which is essentially the Prometheus like regular Prometheus exclusion format.
00:18:34 [W] But in the comment section of the exhibition format, you can like add different foreign keys and context information on a data point for the purpose of kind of this exercise.
00:18:42 [W] We're going to make the tree psyd the foreign key. So it allows us to have linked to trace has given this Exposition format.
00:18:51 [W] We need a way to actually emit Matrix which race IDs and that's where kind of opentelemetry comes into play.
00:18:59 [W] So opentelemetry is a new standard that provides a single set of apis to emit metrics and tracing information.
00:19:13 [W] Could be the trace ID and opentelemetry supports openmetrics extended Prometheus format.
00:19:27 [W] Some of the below things were going to talk about in the specially in the Prometheus nm3 face or slow work in progress and we have were having continuing discussions with stakeholders.
00:19:42 [W] So we've been working on like adding Prometheus support to script metrics with exemplars and making them available to remote right customers M3 now has the ability
00:19:52 [W] work the script metrics with exemplars and making them available to promote right customers M3 now has the ability to actually store exemplars alongside metric data points
00:19:57 [W] Or exemplars alongside metric data points. The exemplars are essentially a tree side. He's are durable and stored for the lifetime of datadog point the one
00:20:08 [W] That it does end up using a lot of extra memory depending on the length of this foreign key the trace idea. It could be a few tens of bytes per data point.
00:20:21 [W] So we need to kind of limit the emission and storage of exemplars to just the specific metrics where the information is most useful in this scenario, like especially when we kind of combined this with tracing
00:20:33 [W] Is one of the cases where interested in the query engine of him three supports occurring exemplars along with data points, and it also ensures representative Exemplar to be present even after applying
00:20:49 [W] Auctions like some and Max and others.
00:21:02 [W] So one of the challenges with using traces for debugging these like Corner case like Corner cases is actually sampling traditional to stamping techniques like can be sampling or different adaptive sampling techniques or in
00:21:10 [W] Traditional to stamping techniques that can be sampling or different adaptive sampling techniques or in many cases insufficient because these one-off traces don't get to sampled.
00:21:18 [W] So we need to use some form of kale based sampling to pick traces that are emitted as exemplars with metrics zooming.
00:21:27 [W] We have a trace holding tear which can cash all the traces for a short duration with them tikv gatien layer then kind of indicating to it like which additional traces
00:21:34 [W] to persist. So Chris is basically like the regular head based sampling still applies, but We additionally go and like store persist another like additional set of traces which
00:21:49 [W] To persist. So Chris is basically like the regular head based sampling still applies, but We additionally go and like store persist another like additional set of traces, which the
00:21:51 [W] associated with
00:21:51 [W] so what does this complete ingestion pipeline? Looks like look like you have an application instrumented using opentelemetry.
00:22:03 [W] It's using openmetrics extended Prometheus format. And with those Matrix The Matrix gets scraped by Prometheus go through them three aggregation here to like long-term storage for the metric data
00:22:15 [W] Trace is going to be a real collector. But instead of going a hundred percent sound food and go to the air collector, but instead of going directly into storage.
00:22:26 [W] They sit in a holding cash and the holding cash basically gets information from the M3 aggregation here to actually store this traces that are associated Matrix any regular sampling like had based sampling
00:22:42 [W] also can still happen and those traces can also like end up in that tree storage finally like different consumers like you eyes Griffon are Jaeger and alert engine can basically speak to
00:22:57 [W] Strength to actually like create like nicer user experiences.
00:23:09 [W] So you can basically end up with a graph on a graph for example where like every because every metric data point is associated with the trace you can make do it make extensions or plugins where you can click on a data
00:23:18 [W] Jump to a corresponding Trace. Now initially. We should kind of how Chris differences can be valuable tools for debugging the difficulty is actually in searching for these traces now deep
00:23:33 [W] Openmetrics and traces actually makes the job of actually searching for these traces really trivial.
00:23:46 [W] So we plan to leverage that to build Integrations that allow us to jump from a graph an alert directly toward question person.
00:23:50 [W] I'm going to jump off to demo and we're basically going to talk about like what on call experience can actually look like for the purpose of the demo.
00:24:02 [W] We're going to use Jaeger example application called Hot Rod which simulates different
00:24:04 [W] types of traces request responses so they can create like a few interesting twists so jumping
00:24:14 [W] hot rod
00:24:17 [W] so we can kind of see hard drug running here.
00:24:31 [W] We basically put some data into it and hot rods like sending requests. We had some alert emails come in previously.
00:24:39 [W] These emails are like regular team is but additionally they have some additional context with like a dashboard which is common but they also actually point to a trace difference. So if you actually click to the tree is different, so we basically get back to
00:24:53 [W] The initial example we had but we basically able to get here and like one one step we talk about how that's possible.
00:24:59 [W] Chris and you can actually see here that my SQL being present is actual problem.
00:25:12 [W] We've also made some changes kind of threw like a griffon a graph has a number of different graphs here. Like we can actually look at something like 5 XX.
00:25:25 [W] where now I want to see like why this are actually happened and you're able to jump directly to another tree stiff and it kind of shows you the trace difference information.
00:25:35 [W] Let's look at another one.
00:25:36 [W] Yeah, so this stress difference is actually showing you that both of these loodse these traces kind of took the same path, but the fading trees like the mr. It is Cash ends up
00:25:53 [W] Like feeling in my SQL and returns but the successful case actually succeeded MySQL and made kind of further forward progress.
00:26:06 [W] So these are kind of coming some of the Integrations that we can actually set up.
00:26:11 [W] So I'm going to move back and kind of like jump back to the demo now jump back to the presentation mode.
00:26:14 [W] So, yeah, so how like how is it actually possible to actually like being too like to build these Integrations?
00:26:26 [W] So we leveraged opentelemetry and openmetrics so that we can kind of omit the trace IDs as exemplars. We leverage Prometheus and threes like support to scrape exemplars
00:26:40 [W] Ours alongside the metric data points, but the critical part is we finally kind of like worked on building contextual links into the systems which are actually consuming the metrics consuming the metrics and the trace information.
00:26:56 [W] External links into the systems which are actually consuming the metrics consuming the metrics and the trace information.
00:26:59 [W] So these are essentially our alert engines your persona and other visualization tools.
00:27:11 [W] This is really possible because it's not really difficult to build these contextual links as the underlying data is actually readily available in three Curry returns exemplars alongside Matrix either ensures a single representative.
00:27:17 [W] Of Exemplar, like if present like across aggregation functions can using this information.
00:27:25 [W] It's possible to build contextual links into different query consumes as can be seen here like when the value comes back there's a timestamp data point and there is a spanning tree surgery.
00:27:38 [W] So if you have something like this this kind of shows another sample workflow, we could build into graphing Solutions where you kind of click on a like one metric.
00:27:49 [W] And you mark that as your control trace and which in general kind of can be your 2 x axis can be your control interest. And then if you have like 4 XX XX and other like her information here when you click on like the
00:28:03 [W] And like defeat against the controller is so that's one idea of like how you could boo contextual links for a graphing engine.
00:28:18 [W] You could in general just have the graphing engines say that there is this is a controlled metric for alerting Integrations.
00:28:28 [W] You could provide the ability to configure metric that can act as a good source of good exemplars source of like control exemplars another thing which is actually
00:28:35 [W] A possible is to basically like for standard will name metrics like RPC Matrix. We can build plugins that can automatically detect and provide comparisons kind of based on knowledge of the types of metrics
00:28:48 [W] Is to basically my first standard well name metrics like RPC Matrix, we can build plugins that can automatically detect and provide comparisons kind of based on knowledge of the types of metrics
00:28:50 [W] That is kind of what we did with for our demo where we augmented Yeager's RPC metrics to actually have the trace ID information on it.
00:29:01 [W] So given a failure or 5 XX metrics.
00:29:04 [W] We know kind of what the success metric looks like. And yeah, so yeah for summary we kind like we basically kind of showed you that creates differences
00:29:16 [W] Poultry bug issues if you're able to find the right traces and kind of using deep linking support between metric data points and traces we can build a number of Integrations that can speed up root cause finally we kind of showed a sample of how this can
00:29:32 [W] Jen or relation to like Rihanna. So where can you actually get this?
00:29:40 [W] Like where are we on like on this journey, the current and doing demo is actually is present at this link or a few changes which you've already made towards this but there are many other kind of work in progress changes.
00:29:54 [W] We've also like had help from the open source, like other from like ravana like Bjorn from profound. I hope that's a tank exemplars.
00:30:03 [W] Support and Prometheus client and actually change the kind of storageos employers in memory and then forwarding the modern award rate is still kind of a work in progress some other resources that are of interest is like if you've not
00:30:18 [W] Link or futurewei changes, which you've already made towards this but there are many other kind of work in progress changes.
00:30:20 [W] We've also like had help from the open source, like other from like ravana like Bjorn from profound. I hope that's had a big Exemplar support and Prometheus client and actually change the kind of storageos employers in memory and
00:30:21 [W] Please do go check out and Rob's talk on deep linking metrics and traces that he gave at coupon San Diego.
00:30:31 [W] It kind of talks like in more detail about like how this deep linking is actually possible and kind of what are the what are the technical challenges with that and there are few other sources here on openmetrics opentelemetry,
00:30:42 [W] Start with that and there are few other resources here openmetrics opentelemetry Prometheus M3 and performer.
00:30:44 [W] And finally, thank you so much.
00:30:50 [W] Thanks a lot everybody.
00:30:51 [W] Thanks for your time.
00:30:57 [W] Do come stop by a virtual boot to sign up for demos to check this demo out and other interesting features.
00:31:03 [W] We're actually building.
00:31:05 [W] Yep.
00:31:05 [W] Thank you.
00:31:08 [W] Hi.
00:31:16 [W] Ya Tink.
00:31:16 [W] I'm on my way now.
00:31:18 [W] Yeah, so there seemed to be a couple of questions.
00:31:23 [W] I will go over them now.
00:31:28 [W] So the first one from Dmitry, how are you detecting good and bad traces for comparison.
00:31:35 [W] Do you do it automatically?
00:31:41 [W] Yeah, so this is actually the biggest challenge in for this particular demo.
00:31:42 [W] Yes.
00:31:45 [W] We can you can you ended up doing it automatically because you kind of know the source of the good and the bad metrics the metrics actually were emitted.
00:31:54 [W] From the Jaeger from the your client.
00:32:04 [W] So the Jaeger Clan time, it's like success and error metrics or kind of ease that different latency metrics.
00:32:08 [W] And bad traces for comparison.
00:32:12 [W] Do you do it automatically?
00:32:13 [W] Yeah. So this is actually the biggest challenge in for this particular demo.
00:32:13 [W] Yes.
00:32:13 [W] We can youcan you ended up doing it automatically because you kind of know the source of the good and the bad metrics the metrics actually were emitted from the Jaeger from the your
00:32:14 [W] Aces see within a threshold on the latency or success versus errors to do it generically in general may be difficult.
00:32:27 [W] So there are a couple of different ways.
00:32:29 [W] This could be handled one is as a part of an alert execution system. You kind of say that I'm actually monitoring a particular metric but the good metric but this is actually like
00:32:42 [W] Like the example good metric. So if you're looking at kind of are accounts, every error metric should have a corresponding success metric so you can say that my success metric is kind of my control metric.
00:32:57 [W] You Source the traces from that particular metric and you build Integrations based off of that.
00:33:07 [W] So there is user input required to actually to actually figure out those good and bad. Do I figure out this button batteries?
00:33:17 [W] The second question is from Bart. It is basically asking like what is m 3?
00:33:38 [W] Yeah, so I think it was initially mentioned your M3 is an open source kind of like time series data base which supports Prometheus remote right? It's highly
00:33:47 [W] From Bart it is basically asking like what is m 3?
00:33:49 [W] Yeah, so I think it was initially mentioned. Your M3 is an open source kind of like time series data base which supports Prometheus remote right? It's highly
00:33:49 [W] What horizontally and vertically and I can store time series data like different resolutions for and the same metric at different resolutions for very long
00:34:03 [W] Wait, like dr.
00:34:12 [W] Temporary storage and we have a query engine which supports kind of doubtful Prometheus query language.
00:34:14 [W] Okay, there is one more question here building contextual.
00:34:27 [W] One more question here building contextual links into systems consuming tracing metric information.
00:34:41 [W] Yeah similar to the previous answer like some of this has to be done kind of manually or kind of when you configure alerts or dashboards
00:34:52 [W] It's possible to do this because the traces themselves are like directly associated with metrics.
00:35:03 [W] So as long as you can say that these are my kind of control metrics to Source like the good versus bad. You should be able to do that.
00:35:13 [W] Vincent is it correct that Exemplar supported Matrix is now possible to achieve both with Prometheus client libraries and opentelemetry client libraries.
00:35:35 [W] Good question.
00:35:37 [W] I'm not a hundred percent sure about the opentelemetry client libraries yet on the Prometheus client libraries at least 4 KO Lang. It's available as an experimental feature.
00:35:51 [W] and on the experimental flag and you can start emitting metrics with exemplars Prometheus itself supports scraping those exemplars, but the storage path of like
00:36:06 [W] Making it into kind of like back and storage that is still a work in progress.
00:36:13 [W] Yeah, Christopher as a which Technologies were used for the tracing cash.
00:36:28 [W] So yeah this point of time they also look at the previous talk tracing cash is to still not it's still not there.
00:36:40 [W] It's still kind of that is something that we have to implement the demo kind of does like hundred percent.
00:36:47 [W] Sampling of the traces and yeah, you can yeah, it's still a work in progress.
00:36:57 [W] How is tracing different from a p.m.
00:37:09 [W] Solutions?
00:37:10 [W] Is it more for custom metrics?
00:37:12 [W] Who penis?
00:37:15 [W] Yeah, so not a hundred percent what you call I'm not a hundred percent sure about how exactly the APM Solutions you mentioned work. But tracing
00:37:32 [W] whenever kind of a request comes in at the highest level there are some context which gets attached to the request and that context flows like to the whole system as different like API calls are made in case of
00:37:49 [W] In case of microservices and whenever it kind of it makes a hop from one service to another it like adds on to like this content like basically M. Its information saying oh this was a particular color
00:38:05 [W] Is where they basically starts emitting spans, which basically has collar and Kali information and information about how long something took and then you can kind of because this context passes through like various
00:38:21 [W] Something took and then you can kind of because this context passes through like various microservices. You can stitch together these pans to get a complete view of like how this Trace looks or how this request
00:38:30 [W] Get a complete view of like how this Trace looks or how this request response called.
00:38:35 [W] Yeah how this request response called actually like like propagated through the system.
00:38:41 [W] that answers your question.
00:38:43 [W] Demetrius it could be a big challenge if you compare two traces if your infrastructure consists of 1K micro purses do you have any suggestions for such cases?
00:39:01 [W] Yes it is.
00:39:05 [W] It can be a really big challenge really good question the Jaeger like I think they're like certainly like the current bigger like Trace differencing view is
00:39:17 [W] It is just a start.
00:39:23 [W] I think one of the challenges just because even searching for traces and making use of that view is difficult, especially in like large microservices.
00:39:35 [W] That is true.
00:39:41 [W] But I think the moment you kind of have the ability to jump to these Trace differences more easily certainly like I can see it. I can see changes being
00:39:47 [W] You kind of coalesce them together and kind of improving that view.
00:40:11 [W] I'm assuming that was kind of your question.
00:40:13 [W] there. Like how do you compare traces with which which contain like many many hops if I'm hurting
00:40:20 [W] hey coasst have you played around with Victoria metrics yet much better performance and in 3 for us.
00:40:44 [W] No, I've not really worked with Victoria metrics. So I cannot.
00:40:51 [W] Yeah, I will I can certainly look into that.
00:40:54 [W] that. Yeah, I'm not sure if they actually support saving exemplars.
00:40:57 [W] Anisha swerd M3 be comparable to tunnels in terms of focus.
00:41:08 [W] Yes, M3 is like similar similar to Thanos in that.
00:41:12 [W] Yeah.
00:41:15 [W] It's a Prometheus remote right back end and kind of store metrics longer term.
00:41:22 [W] Three. Is it achievable without M3?
00:41:36 [W] Yes, as of this point to my knowledge like M3 is the only like kind of long-term store which can store these exemplars alongside the
00:41:49 [W] like alongside individual data points and certainly like actual Prometheus itself, like how exemplars are going to be stored and be available is
00:42:05 [W] Progress so I have time to 18 take one more question here.
00:42:13 [W] Chances doesn't elastic ecosystem provide this type of linking.
00:42:25 [W] I'm not very sure probably does.
00:42:30 [W] It's certainly something that I would like to go. I can take a look at
00:42:32 [W] And yeah, I think we've run out of time.
00:42:42 [W] So I will be in the observability room after this and happy to take your questions there.
00:42:44 [W] Thanks a lot everybody for taking a look at this and many questions.
