Controllers at Chaos: QNFB-3936 - events@cncf.io - Thursday, August 20, 2020 6:58 AM - 54 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:01:18 [W] Hello, welcome to coupon today myself K7 with me Governor from sap will be taking you to some of the interesting things about our controllers and Garner and how we leverage the existing kubernative
00:01:38 [W] To operate kubernative cluster such skin.
00:01:43 [W] Let's start from basics.
00:01:43 [W] So how will you run a container? Basically you have you'll get the libraries you change the root and set the namespaces and run the camp think of a cases where you want to have a few number of containers to run like a search some
00:01:59 [W] He's a root and set the namespaces and run the camp think of a cases where you want to have a few number of containers to run like a search some around 10 to 20 containers.
00:02:06 [W] Then you will go with some thing like darker or some other containerd platforms.
00:02:08 [W] Now, let's go with a big bang. Now when you have to operate thousands of such containers, what will be the good solution the Quicken will be kubenetes.
00:02:18 [W] So kubernative helps you to orchestrate this
00:02:21 [W] thousands of containers across across the kubernative so clothes and then helps you to manage those containers Kuma rates are nothing but a bunch of controllers like controller manager Cloud controller Q Pi server head CT now.
00:02:36 [W] Head CT. Now, let's take some big organizations where they want to operate thousands of clusters.
00:02:46 [W] What is the solution we have in place to operate these many kubernative clusters rather than just operating clusters. We need across cloudbees like AWS DCP has your and even on private clothes.
00:02:55 [W] We just not stop but creating clusters, but be one some more other than just operating this. We need a quick solution quick way of managing the Clusters operating the Clusters which are single click and so on the other thing to be noticed
00:03:11 [W] There are lot many Cloud providers available in the market like AWS DCP vsphere as your only clue each of them have their own design structures in providing them producing the Network's volumes virtual machines Etc. But
00:03:27 [W] Kubernative developer.
00:03:32 [W] We need an alcohol McGinnis clusters so that this helps the developers to be more cloudevents snyk next comes for The Operators.
00:03:46 [W] There should be some backup and restore in place for the kubernative Clusters itself so that this will help them in hand during Disaster Recovery times and people working on kubernative SAR more familiar with going of declarative way of creating a kubernative so
00:03:54 [W] We chose your containers and how many replicas you want to run and just to deploy it on kubenetes similar approach.
00:04:04 [W] Why don't we can have for our kubenetes say a kubernative spec would be like giving a what is the kubernative version which you want to run?
00:04:14 [W] What is the worker node type 1 watch cloud provider. You want to run?
00:04:17 [W] What is the OS image you want to run and those tapes?
00:04:18 [W] This will be a good one, right?
00:04:19 [W] next thing comes more important is about extensibility your solution which needs to be more extensible the to adopt new features when needed and it should be extensible to adopt new crowd providers whenever in place in the future,
00:04:36 [W] We'll see.
00:04:41 [W] what are the common cluster set up how we have in current situations will take us some small example of bunch of worker nodes, which we have some leader notes in which we host Over Control pin components here.
00:04:52 [W] You can see we have Hachi for little notes to may have a question for our control plane components.
00:05:00 [W] Let's take some example of different kubernative clusters of varying sizes here. You could see there are a lot of few worker nodes in one kubernative cluster and there are lot of kubernative.
00:05:06 [W] Worker nodes in some other kubernative cluster here. The load is uneven when you think of fewer worker machines big small small clusters.
00:05:17 [W] The leaders are underutilized leader notes when you going for bigger clusters, the leaders would be over-utilized and this will limit Us in scaling capabilities.
00:05:30 [W] So we Hunter who will see how our approach will help us in position loosening this cases. Let's take a end-user cluster. Here we go.
00:05:36 [W] collectors should cluster
00:05:38 [W] Here you can see the normal kubernative workloads and our leader node, which has the control pin companies will have one more seed cluster that this is nothing but some other kubernative cluster. We just take the control pin components of the suit cluster inducer cluster
00:05:55 [W] Does workloads put in this seed cluster their way we host control pin components of multiple kubernative cluster and we're just operate them.
00:06:10 [W] Now who is going to take care of this suton CD clusters is our guy Gardener Gunner is nothing but kubernative workloads, which run in another kubernative clusters here. You could see Gunner comprises of some more
00:06:21 [W] Similar to kubeedge kubenetes like Ghana Ghana controller manager Garden scheduler and Garner - for this moocs will take into a simple approach what we want to deliver we want here. You can see
00:06:37 [W] Kubernative nothing apart from that here.
00:06:46 [W] We delegate I delegate only the worker nodes to the end users and the governor will take care of managing the worker nodes. And as well as the control plane components, let's speak about it is more simple architecture light.
00:06:56 [W] Let's add some colors in it here you could see this is the complete Governor architecture which comprised of all control pain components of Garner and your the Contraband components of particular particular suit clusters.
00:07:07 [W] And how they communicate with each other.
00:07:11 [W] Let's speak about k8s.
00:07:13 [W] Everyone was familiar with k8s and they learn kubenetes for that Garner also follows the same design principle.
00:07:24 [W] We don't want to reinvent the win. We just learn once concept.
00:07:24 [W] that is kubernative and apply uniformly over to you governor of
00:07:29 [W] Yeah, so let's have a recap of how kubernative works so that we can draw parallel from there for the design of gardeners solution.
00:07:45 [W] So we know that we have a cube a pi server running in the kubenetes cluster and you also have kublr running in each of the nodes now when a user wants to create a pod it the user can provide a Body mlperf Source mlperf scheduler can schedule
00:07:55 [W] Enrolled and then kublr can take care of running the pot in the in the node Sim on the similar lines.
00:08:03 [W] We have guarnere Pi server, which which manages the custom resources and we have garden lights which are running in each of the seed cluster see clusters. Now when a user provides a shoot resource Hamill shoot custom resource,
00:08:16 [W] so which are running in each of the seed cluster see clusters now when a user provides a shoot a resource Hamill shoot custom resource Yemen, which is nothing but a Cuban it is create a cluster request from the user The Gardener scheduler can
00:08:22 [W] take you when it is create a cluster request from the user The Gardener scheduler can pick up the pickup this request and can schedule the control clean of the Chute cluster in a seed cluster and garden let then
00:08:31 [W] Get all for deploying the control plane components in the seedless job.
00:08:37 [W] So Gardener controller manager itself is enough to manage lots and lots of kubernative sister. But for a true scalability, we would want to distribute the logic of deploying the control plane components in the seed cluster
00:08:54 [W] Learnings from kubelet Q8 is a primary node agent which turns on every node and is responsible for keeping a pod running and healthy similarly Garden.
00:09:05 [W] It is also a garden agent which runs on each of the seed cluster and can manage the shoot clusters in which are running or which are responsible which are running in the seed cluster.
00:09:19 [W] It takes over the job from Gardner controller manager for reconciling the shoot controller. Reso shoot cluster resources. It works in
00:09:24 [W] the similar way the cube it works.
00:09:34 [W] I ain't it depends on the lease objects for the seed heart beats. It paves the way to grow and operate as many shoot clusters across our gardener lenses cape.
00:09:43 [W] It is not necessary to run this garden light in inside a seed cluster as long as it can talk to the seeds API server, which is which is running in the gardener cluster.
00:09:48 [W] also opens up the doors for running a shoot lasers Under Fire wall since the control plane is managed.
00:09:54 [W] Tate separately by Gardner
00:09:56 [W] Now since we also want to provide extensibility, which means that we should be very easy for a gardener provider to add support for multiple Cloud providers.
00:10:14 [W] We were there are something called extension controllers.
00:10:18 [W] Which is running in the gardener cluster it also opens up the doors for running a chute classes under Fire wall since the control plane is managed outside separately by Gardner.
00:10:26 [W] Now since we also want to provide the extensibility, which means that we should be very easy for the gardener provider to add support for multiple Cloud providers.
00:10:27 [W] We were there something called extension controllers.
00:10:28 [W] These are Cloud specific controllers, which know how to talk to the cloud providers and manage the DNS V PCS or other infrastructure needs now the
00:10:30 [W] attention controllers template can be provided as a custom resource to The Gardener and then Gardner can take care of deploying these extension controllers in the seat cluster so that when a request comes for a see shoot cluster for a specific
00:10:43 [W] Other infrastructure needs now. The extension controllers template can be provided as a custom resource to The Gardener and then Gardner can take care of deploying these extension controllers in the seed cluster so that
00:10:44 [W] Control cloud provider in that case. These controllers can deploy the required infrastructure in the in in the cloud providers.
00:10:52 [W] Now Cuban, it is does not have a way or it does not support a way to create the provision or D provision machines in the infrastructure.
00:11:09 [W] So we rely on the componentconfig Xin Controla manager, which works on the same principles as of Kube control the manager. So it provides a declarative way of managing the VMS of creating the vm's
00:11:23 [W] In the same way that we have deployment controller. We have machine deployment control as part of Machine controller manager machine deployment custom resource takes the number of replicas that of the machines that needs to be provisioned and it also takes a machine template which which
00:11:39 [W] Details about the machine the size the OS image that the machine should have this machine deployment controller then creates a machine set controller machine setup checked this machine such object is picked up by the machine set controller and it creates
00:11:55 [W] But of machines that are created are specified in the replicas field and then the Machine controller create picks at these machine objects, and then talks to the cloud providers to actually provision the machines which
00:12:10 [W] kubernative pluses as node objects
00:12:15 [W] To keep the control plane up and healthy all the time and to have minimal downtime.
00:12:26 [W] We also depend on a componentconfig pendency foster.
00:12:31 [W] So what can happen is when a Cheerio the EPS server is down, the the other controllers in the control plane can go into exponential fresh look back off and if if and when a pi server comes back up it can take a long time for
00:12:43 [W] For those controller ports to start running again.
00:12:48 [W] So what what dependency Watchdog does is that it keeps a watch on that CD endpoint. So for the availability of hcd and it also keeps a watch on the control plane pods that are going into fresh look back off and
00:13:02 [W] See is that a chibi is down, which can potentially result in controller ports controller manager pods to be down.
00:13:13 [W] It shoots off. Our it deletes those pots so that new bodies immediately created which is not an exponential back-off anymore and it can start as soon as as soon as the TD and a pi server are back up.
00:13:26 [W] We also rely on cluster autoscaler, which we have formed cluster autoscaler and adapted it to work with machine deployment objects with this weekend autoscale overshoot clusters, basically the user clusters and the seed cluster which is managing.
00:13:43 [W] Shoot lessons themselves, but a potential problem there could be that if I HEV partition you'll Don on node that is getting scale down.
00:13:56 [W] It can lead to Long down tines.
00:14:01 [W] So to prevent to such cases we deploy h-series in a separate dedicated worker pool so that the worker pull that hose the other control main components of the Chute lesser can still be scaled
00:14:11 [W] Noah when the road decreases
00:14:14 [W] some of the components like you be Pi server can scale both horizontally and vertically but since VPN - PA don't work well together when it comes down to the CPU and memory Matrix alone.
00:14:34 [W] We rely on a controller that is hppa controller.
00:14:43 [W] It provides a way to provide the user with a way to provide the ways how HP Envy PA recommendations.
00:14:48 [W] Can be used together using a weight based scaling so user can provide weights that needs to be given to HP and VP recommendations. It also does some extra things. It also provides some extra flexibility and functionality.
00:15:04 [W] So for example, a user can provide the thresholds which can be used to so which provides a way for SVP controller to apply the recommendations only when certain data or the changes is reached.
00:15:20 [W] In the recommendations by HP of EPA it also we can also provide scaling policies.
00:15:28 [W] which can which which user can for example mention a time slot during which only a certain kind of scaling should take place.
00:15:35 [W] And Disaster Recovery scenario, so in case of shoot Lester has issues.
00:15:51 [W] So if the users and users cluster has issues in those kind of cases the kubenetes itself, since all of the control thing components are running in pods and is managed by Cuban. It is the control link Parts can be brought back
00:16:02 [W] I said sir. If the machines of is the packing Machines of the of the users, let's share our down then Machine controller manager can take care of bringing up new machines and clearing up the failed machines
00:16:17 [W] To leave alone activity backup/restore to provide backup of the Clusters the state itself.
00:16:32 [W] So in case of HED failure we can use itd's backup which is stored in the cloud to restore the state of of the plaster and Gardner itself can reconcile the state of the
00:16:40 [W] In preserve the essence of the shoot cluster itself.
00:16:44 [W] So in case the C cluster which hosts the control planes of many many shoot clusters itself is down.
00:16:57 [W] So in those kind of cases, we rely on the x-series backup and restore functionality.
00:17:04 [W] So for example, let's say we have to see clusters and one of the seed cluster has the host the control plane of the Chute cluster.
00:17:17 [W] Now this control plane the state of the cluster itself is backed up.
00:17:19 [W] blobstore and in case a seat goes down the country Gardener can then schedule the control plane of of the Chute lesser in a separate in a separate seed and when it
00:17:33 [W] For example, let's say we have to see clusters and one of the seed cluster has the host the control plane of the Chute Lester. Now this control plane the state of the cluster itself
00:17:35 [W] Art's did it can restore from the blobstore the state of the cliché in can start managing the shoot cluster from there.
00:17:42 [W] So time for a small demo over to you case one.
00:17:48 [W] Yeah, go go. So here you can see how as simple as that to cater kubernetes cluster with our Gunner beautiful dashboard just to mention.
00:18:00 [W] What is the cluster name and is a given the worker nodes.
00:18:06 [W] What is the machine type and we're on the cloud provider.
00:18:09 [W] You just sell it and gonna dashboard gives you the cluster in few minutes.
00:18:15 [W] Let's be removed like of declarative way of approaching kubernative cluster, right? Let's see in a quick demo.
00:18:16 [W] Yeah here you can see us at speak of custom resource here. You can see the add-on kubernative dashboard Ingress controller and the cloud provider is mentioned s AWS Corner provide a feature of adding hibernation s so that you can see
00:18:34 [W] This can save the cause for creating clusters.
00:18:41 [W] Next comes for the Network's here.
00:18:44 [W] You can mention the network types and the controller worker groups.
00:18:46 [W] What is the mission type you need?
00:18:47 [W] What is the mission of glass? You want to create a number of organ notes?
00:18:51 [W] That's it. We just uploaded the shooter much in the above pan. You can see the gunman cluster where we created shoot custom resource and Below pan. You could will have a watch on the control pin components which will be provisioned in one of the cgroup.
00:19:05 [W] A cluster we just did have a march on the name space.
00:19:09 [W] In the perp and you could see a progress bar for having the how much does a cluster has been created here.
00:19:16 [W] You can see them terraform part which is in the back and creating the infrastructure resources like VPC networks for the particular kubernative blister now hcd is up and running. We'll wait for other control pain components.
00:19:29 [W] Here you could see 12 control manager and CSI driver in cash flow back up because the qbb server is still not a tranny.
00:19:49 [W] So howhow like governments and the dependency Watchdog will keep on watching this crash loopback of parts. And once the cube a server is up and running. It just kills the cloud control manager on those things should now we could see the replica set replace it with the new color control and manager without.
00:19:57 [W] 2004 ranges from Tsukasa to back off
00:20:01 [W] Now we'll leave for few more minutes.
00:20:10 [W] We just made a speed up so that we can have a quick view of with the cluster is created.
00:20:13 [W] You can see a progress It's At 87 percentage and almost all the control plane components like episode.
00:20:22 [W] were Cube controller manager our mission control manager survey D and now the cluster is ready to use.
00:20:24 [W] So coming back to our main end of the story how
00:20:31 [W] Yeah, coming back to the end of the presentation Tikki takeaways. So with the governor we are able to deliver fully manager homogeneous clusters.
00:20:45 [W] Even River anticipating.
00:20:50 [W] We operate thousands of kubernative clusters across multiple Cloud providers like Ali Baba AWS
00:20:51 [W] Microsoft Azure and even on specific government Cloud as well. We run workloads like Hannah which is an in-memory database.
00:21:06 [W] So if you want to reach out to us more about one to learn about corner and involved with us, just reach out to us in any of the links below. Thank you.
00:21:10 [W] Thank you.
00:21:13 [W] So time for questions and answers.
00:21:15 [W] Yeah.
00:21:19 [W] Reading out the questions pictures from the audiences.
00:21:43 [W] First question is Garner Apache 2.0 from top to bottom are there any components that are not published so all the components which are showcased now are in the GitHub or completely open source. Nothing has been under the hood.
00:22:01 [W] Next question how to manage gun clusters garnered managers. I think God has an answer. Did it grow?
00:22:13 [W] Okay.
00:22:24 [W] So others is it possible to change the VPN to another type like wire got so here we Garner itself has a package of a profiting beep beep in inside it.
00:22:40 [W] It's possible to change as per your own need.
00:22:42 [W] Okay, many of you wants to go to setting the slates.
00:22:54 [W] Yeah, definitely. We will sell this lights with you.
00:22:55 [W] Okay.
00:22:58 [W] So others is it possible to change the VPN to another type like wire got so here we Garner itself has a package of a providing a weapon inside it.
00:23:00 [W] It's possible to change a Spurrier won't need.
00:23:00 [W] Okay, many of you want to report to sharing the slides.
00:23:01 [W] Yeah, definitely. We will share the slides with you.
00:23:01 [W] Next how do you support a on-prem clusters?
00:23:03 [W] So Gardener probation, whatever it extensibility to profile to offer across different Cloud providers and we can even if you have your own cloud providers or anything with Justin extensibility to creative word own
00:23:15 [W] On from clusters so Gardener provides on whatever it extensibility to profile to offer across different Cloud providers and we can even if you have your own cloud providers or anything with Justin extensibility to
00:23:17 [W] We can you can beat even condone on proven clusters.
00:23:21 [W] Okay, does Garner work with other Heroes like flatcar Talos?
00:23:48 [W] So there is an option so it is Garner is completely accessible as a gun is Guru told you can bring your own OS in three.
00:23:53 [W] That's right. Now we have our own specific OS like Garner Linux and it can be on any other way systems for the ochre notes can be added to governor.
00:24:01 [W] Go to your line.
00:24:05 [W] Yeah II had a network issue.
00:24:07 [W] I'm back.
00:24:12 [W] I'll also try to go to some of the questions.
00:24:15 [W] So when is how does Gardener API so we have conqui confused plans to be compliant with lust plus API class API today supports extensible control plane
00:24:27 [W] Is right now kubeedge DM and the plan is to extend the control plane provider ci/cd with Gardner provider.
00:24:37 [W] So guess it's if we have a concrete plan to get on with it.
00:24:43 [W] So another question is what is the largest shoe that we are running?
00:24:52 [W] So the larger shoot is not really a limited by Gardner itself.
00:25:03 [W] But since we try from what we have tested, we have tested with 250 cluster and shoot notes, but it is not really about the number of nodes.
00:25:09 [W] But what kind of load we are putting on the EPS are wearing to how much extent we are. We are ready to load the API server, so
00:25:15 [W] You have extra parameter own requirements and we have been able to load the API server to around thousand or 1500 requests per second where we were running 110 node ports per node and each of
00:25:29 [W] Also had secrets and config Maps attached to them so they had their own load on the pi server because of those kind of configurations.
00:25:38 [W] So another question is how does
00:25:45 [W] how do I gotta manage kubernative cluster version upgrades?
00:25:51 [W] Yeah, how does Garden manager kubernative cluster version upgrades so you can see from the thing whatever whichever the Upstream things coming from kubernative releases Garner make sure it's also as part of Governor we
00:26:05 [W] Kubernative Solutions and keeper Upstream to the governor so big you can get the Upstream kubernative Solutions on Garner.
00:26:15 [W] Okay.
00:26:24 [W] Another question is do the shoot cluster need to be homogeneous, or they can be from multiple managed Cloud providers.
00:26:25 [W] So as of now the shoot clusters can only be configured in a bunch single.
00:26:31 [W] shoot cluster can only be configured in one cloud provider but one Gardener cluster can manage shoot clusters across Globe providers. So you can at the same time create multiple kubernative stresses, which can be managed as a single guard Gardener cluster, which can span across
00:26:45 [W] Not even bare metal.
00:26:51 [W] So the support is there for bare metal as long as the infrastructure provider provides a clear API for creating machines load balancers volumes attaching volumes and things like that. As long as these
00:27:03 [W] Darnell can manage the cabinet specimen source.
00:27:08 [W] Yeah, one more question is digitalocean supported.
00:27:23 [W] Yeah, there are some pull request. I believe which are on the pot. We can it just like a how you onboard new cloud provider.
00:27:32 [W] We just have to create an extension for the particular providers and it's definitely possible to onboard work with a digital ocean as well.
00:27:33 [W] Okay, A lot of people are asking for slides also, so just to let everyone know the flights will be available after around 40 48 Hours on the website.
00:27:46 [W] So another question is can we use HP Envy petabyte-scale so and from our experience HP Envy PA when there's just left on their own and are left on their own to work with the same set of matrices like CPU and memory there
00:28:01 [W] First slides also so just to let everyone know the slides will be available after around 40 48 Hours on the website. So another question is can we use HP and vpa together?
00:28:03 [W] So in from our experience HP and vpa when there's just left on their own and are left on their own to work with the same set of matrices like CPU and memory there might be some clashes and some stability, but what we have
00:28:04 [W] and some stability, but what we have tried with HP Pi controller is to kind of get control of actually do the scaling ourselves and let HP and vpa only work
00:28:17 [W] Conditions based on the usages. So once the recommendations from HP Envy PA are in hppa controllers takes place recommendation, and the idea is to scale according to a spec with that is provided by the user to the
00:28:33 [W] And so this is how we have been trying to run both HP and BPA together and till now it we are very happy with the way we were able to make it work and it's and the results have been promising.
00:28:49 [W] So we use this for our Cube API server scaling since this is one of the components that can scale both horizontally and vertically
00:28:56 [W] And one more question, which is Will Garner can manage the Clusters across different data centers.
00:29:07 [W] Yeah, I think you meaning different data centers.
00:29:10 [W] It's like a pruning to the Region's. Yeah, so we better clusters across the different multiple or over 50 plus regions across the different Cloud providers.
00:29:22 [W] just like a garden LED lights on the particular seed cluster and it's manages those two clusters Link in that particular seed cluster, so it's possible.
00:29:30 [W] already in that
00:29:31 [W] another question is can it work with openshift or only specific distribution of k8s, so we are working on collaborating with IBM and edit so that support for open ship flavored
00:29:46 [W] It will be provided on IBM machines.
00:29:50 [W] Another question is does Gardener work with other OS like flatcar Telos.
00:30:05 [W] So right now since the architecture is extensible the support for OSS can be plugged in as an extension and we support bunch of
00:30:15 [W] Could it be used for bare metal?
00:30:25 [W] kubernative / - yes as already answered. It can be used as long as we already support bare-metal Zach the mean the meccan stack which for example which provides bare metal infrastructure.
00:30:38 [W] One more question if I want to want to shoot cluster to be upgraded to your new Cube version on the run without downtime does Garner automate the upgrade process can Garner do it in a canary fashion so that the version upgrade is rolled back.
00:30:57 [W] Self trouble.
00:31:03 [W] Yeah, what happened means the might have seen in Governor governor's speech like that is a component Mission controller manager, which takes care of draining the nodes and brave sitting the workloads on the another bring up the new
00:31:15 [W] With a particular kubernative version, so it works seamlessly as a canary pension in Garner.
00:31:25 [W] It just are in the dashboard. You just have to just uh, press on a button press to upgrade your kubernative cluster and you can even mention the maintenance window time. Where is a cluster upgrade has to be happened?
00:31:35 [W] I have the question is how to manage Gardener cluster itself or the gardener managers the Cardinal cluster itself. So the first cluster The Gardener cluster need to be created somehow it is not managed by Gardner itself.
00:31:53 [W] It can be any cluster that is created using it could be GK or UK is but after that one's Gardener for this cluster is created the creation of C plus s and shoot lasers can be all or the three pluses and shoot classes can all be managed by gotta
00:32:09 [W] I think we have answered almost all the questions I guess the row.
00:32:28 [W] Yeah, I don't see if I in case like I have Miss I'm missing some of the questions if we may have missed some of the questions, please feel free to reach out on the slack Channel.
00:32:42 [W] on the plane
00:32:47 [W] So, thanks again for everyone for tuning in. Thanks case 1
00:32:53 [W] Thank you, everyone.
00:32:57 [W] Happy learning.
00:32:59 [W] Bye.
