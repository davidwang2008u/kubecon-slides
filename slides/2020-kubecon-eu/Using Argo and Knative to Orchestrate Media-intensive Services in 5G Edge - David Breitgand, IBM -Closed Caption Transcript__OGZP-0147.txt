Using Argo and Knative to Orchestrate Media-intensive Services in 5G Edge: OGZP-0147 - events@cncf.io - Tuesday, August 18, 2020 7:44 AM - 83 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:44 [W] Hi, my name is David. This work has been done in collaboration with my colleagues having Pavel all three of us work for IBM research and we are based in Haifa Israel.
00:01:00 [W] Today, I'm going to share with you some experience from our journey into orchestrating meeting intensive services in five.
00:01:18 [W] Uh, I will start by giving you some background and motivation and then I'll talk how we used Argo and Canadians in our project then I'll show you a short demo and provide some concluding remarks.
00:01:27 [W] These work was part of a New Horizon 2020 project called 5G media as you can see the been many partners in this Consortium the started in June 2017.
00:01:44 [W] It was almost a three year project and been developing a programmable Edge to cloud service virtualization platform for me the Intensive application in 5G networks, IBM's focus in this project.
00:01:57 [W] Integrating serverless technology into the platform helping the use case Partners to leverage it for applications and harmonize it with the standard management orchestration approaches such as Ed.
00:02:13 [W] mono used by Telco. See also, we've been an integration partner responsible for tying bits and pieces together so that they would play out nicely. So naturally this included lots of orchestration work both in.
00:02:28 [W] Surah and interviews cases
00:02:31 [W] So let's define our problem first.
00:02:37 [W] We want to facilitate third-party applications deployment at the 5G Edge. We want to do it cost efficiently with instantaneous elasticity and have fast time to Market.
00:02:51 [W] It's difficult to achieve his traditional vm's.
00:02:58 [W] We don't know in advance where and when to deploy them. We can cannot just deploy them everywhere in the edge waiting for events that may never come the Amazon notoriously difficult to
00:03:11 [W] Gals might be a problem scaling in might be even a greater problem pays you go is not really what happens with the m and the remaining problems related to infrastructure.
00:03:27 [W] So serverless many media intensive obligations are session-based and even driven.
00:03:39 [W] So what serverless can potentially give us is an ability to spawn cncf containerd Network functions just in time when needed and for the exact time duration the I
00:03:52 [W] Hungry even so what serverless can potentially give us is an ability to spawn cncf container at work functions just in time when needed and for the exact time duration the
00:03:54 [W] Horrible, and it will take away the infrastructure issues.
00:03:57 [W] So these are the use cases that we've been looking at in this project telling immersive media will take a closer. Look just a second remote media production. You going to see a short demo of it
00:04:15 [W] High-definition CDM.
00:04:26 [W] That's an extremely interesting use case where without glasses the amps and containers, but obviously, I don't have enough time to cover it.
00:04:28 [W] So we are not going to discuss it today just to emphasize IBM was on the infrastructure side of things. The applications have been developed by other partners.
00:04:38 [W] All right.
00:04:46 [W] So tell immersive media.
00:04:51 [W] It's use case Family actually rather than a specific use case in 5G media.
00:04:57 [W] We use a telomere Civ game as an example of such an application.
00:05:01 [W] But this was just demo to play with very briefly.
00:05:02 [W] There are two players here are two players.
00:05:05 [W] Each player is in a specific geographical location, but they are close enough and use the same 5G media slice each player is surrounded by four cameras producing a time-varying macstadium.
00:05:21 [W] The players are embedded into a virtual world in which they can freely move in any direction the players interact via CNF, then your network function called Virtual Broker the broker
00:05:36 [W] The broker starts at the beginning of a gaming session and leaves throughout the session Spectators can join from anywhere at any time. Then they might have very different terminal capabilities. Of course, they can also live at any time those
00:05:53 [W] Who have a RV our equipment elotl high-end equipment and that close enough to the players and enjoy good 5G local coverage might consume time varying measures directly from the broker
00:06:08 [W] Rich might consume time varying measures directly from the broker other Spectators see transcoded two-dimensional video where the service automatically maintains
00:06:18 [W] spok makgeolli maintains a mixture of transcoders with one transcoder pair transcoding profile to optimize the total quality of experience for all Spectators and to do it at the lowest price for
00:06:31 [W] Spectators also can move freely in the 3D virtual world, but they are and seemed to the players and to each other if a spectator joins from a remote location, and she's the first one there
00:06:48 [W] Of them.
00:06:49 [W] It has spectator joins from a remote location and she's the first one there. We spawn another broker at the edge and connect it to the main one so that every frame produced by a specific transcoding profile is delivered
00:06:57 [W] Frame produced by a specific transcoding profile is delivered only ones over the expensive long Holdings.
00:07:01 [W] In an if an event of Interest occurs in a game a very play a virtual replace enf is being provided on demand. It creates a clip the chose. For example, how one player has grabbed the flag
00:07:16 [W] Pressing it was from the sport point of view and so on so you've got the idea and I hope it's clear why serverless is a good Paradigm for this type of workload.
00:07:32 [W] Mobile journalism is another use case and as its name suggests.
00:07:42 [W] It's about producing a life contribution with production support functions set up on demand in the 5 G Edge itself close to the event. Basically a journalist working for a broadcaster is involved in
00:07:51 [W] That sounds so she uses her application on the 5G mobile phone to talk to the part of the application running in the 5 G media platform collaboratively the application and the platform select an
00:08:07 [W] production support functions based on the journalists selection of functionality in this example the journalist selects speech-to-text and face recognition functionality as supporting production
00:08:23 [W] Can be different in another session or it can change in the ongoing session. So after the edge is selected.
00:08:30 [W] The V splitter video tekton this speech a spawned as function as a service orchestrated to work together and this splitter is externally exposed as a service.
00:08:47 [W] The video comes into a splitter is splitter forwards it to this speech T v-- detect which produced the metadata upon finalization of the session the metadata and video a sink to the non-volatile storage and the
00:08:59 [W] Splitter is splitter forwards it to this pitch. We detect which produced the metadata upon finalization of the session the metadata and video a sink to the non-volatile storage and the broadcaster is informed
00:09:01 [W] That the contribution is ready. The broadcaster fetches, the files merges them edit them and reduces them into the news program similar applications are in use today.
00:09:16 [W] So it's not such a big invention on the application side, but making a full production remotely on demand just in time so that it shortens time to the news broadcast is
00:09:28 [W] 94 the broadcasters and it can make a real difference for them.
00:09:35 [W] All right. So this is all good and nice, but when we say that the applications are executing at the edge. What do we actually mean by that conceptually 5G media followed the ad c-- multi-axis
00:09:53 [W] Back framework architecture.
00:09:58 [W] It's not important to understand every little detail about the neck architecture.
00:10:10 [W] What is important is that there is a CNF for something that is called Mac platform.
00:10:13 [W] This CNF runs in close proximity to the 5G radio Access Network and offers services such as for example function as a service to the applications.
00:10:24 [W] Yes.
00:10:24 [W] Let's run in the Mac.
00:10:30 [W] This would be a good point to make a distinction between serverless that the used so far in this presentation and fast serverless is a broad concept and when I say serverless and everybody in this audience can
00:10:46 [W] Defined fast is a specific serverless programming model where the level of abstraction is a function not a container or service that scales to 0. So for example que nadie, if is obviously a framework for
00:11:02 [W] S HTTP servers, but it's not fast.
00:11:08 [W] It's not function as a service in general.
00:11:15 [W] Every fast framework is a serverless framework, but not every serverless is fast.
00:11:18 [W] So open whisk that is the logo that is shown here open. This was our serverless was out fast framework, basically. Okay. So let's move on a typical use case for fast in
00:11:30 [W] You see we push the envelope a bit and we use it for media intensive applications.
00:11:41 [W] As I said, we use Apache open this because I'll fast framework and the functions run on kubernative.
00:11:52 [W] basically Apache open risk of floods functions to grenet is that standard feature in the patch open whisk and kubernative serves as our Network function virtualization infrastructure.
00:12:01 [W] We're all aspects of Mac using the application themselves and managed by manual.
00:12:12 [W] We used open-source manual with Sam and this way Sam can be deployed anywhere can be deployed somewhere in the cloud.
00:12:18 [W] for example, so this is our environment in a natural and at this point you might be wondering where is our goal.
00:12:28 [W] Where is Canadian and what about the orchestration so we are getting
00:12:31 [W] Just pick just getting there.
00:12:34 [W] So remember I told you that it was a journey for us. So initially we created this osm open whisk plug-in and this allowed us to Leverage
00:12:55 [W] this networking and shuttling while maintaining high level of a subtraction by using open whisk
00:13:04 [W] but then we understood that we cannot really orchestrate serverless applications with mono.
00:13:16 [W] What we needed to do was to stir some functions upon service instantiation potentially.
00:13:20 [W] Nothing should be started upon stand situation upon some event for example originated in an application in the application itself start more functions configure the rest of the service to work them than when this function
00:13:32 [W] The day out so the service should continue suits reconfiguration and we do it again and again and again, we discussed management flows, and we wanted to have for the network service developer and operator. We wanted to have
00:13:48 [W] the kubernative knative experience
00:13:52 [W] What we have this man was no real modeling concept for serverless.
00:13:59 [W] No customer management flows.
00:14:00 [W] No natural hooks to cater for events.
00:14:05 [W] No kubernative knative devops experience and increasingly, it felt like an exercise in futility because we were trying to orchestrate containers from outside of kubernative better than kubernative should do it itself.
00:14:19 [W] And that was exactly the point where we've discovered Argo about one year one half year ago now I need to walk you quickly
00:14:37 [W] Is animated diagram because it understanding it is important to understanding the demo that I'm about to show so we have kubernative we have our go workflows and are we dancing
00:14:53 [W] Gateway and sensory controllers into one line, but they are separate controllers.
00:15:00 [W] Of course.
00:15:01 [W] This is just for breathing and administrator all some application automation script requests and instantiation of service package previously on boarded 2000 SM.
00:15:15 [W] let's say for the sake of the discussion that the functions are by the way, I should have called them cncf snot vnfs.
00:15:23 [W] the name bootstrap VN F 1V n f 2 and F 3 bootstrap is a special function that service developer Persona ads when she assembles services from Individual vnfs
00:15:40 [W] our invention addition to the methods and it will become clear in a second what we mean by that osm would unpack these functions in the order of
00:15:56 [W] This package one by one.
00:16:04 [W] So bootstrap will go first and then f 1 and f 2 and F 3 and so on now each time osm and packs of vnf the end of descriptor.
00:16:15 [W] We aim to instantiate it in the background.
00:16:22 [W] There is a polling task that continuously pulls them to get the metadata of the vnfs that it asked him to work to instantiate for example IP and Port of this VNS so
00:16:34 [W] In Star City, for example IP and Port of this vnfs. So bootstrap goes first. Okay, and now the first thing that it does it actually applies
00:16:43 [W] And sensory yellow see ours to kublr lenses.
00:16:57 [W] And then what happens is that controllers of the Gateway and the sensor pick the cri-o up there watching them
00:17:04 [W] rollers of the Gateway and the sensor big the cri-o up there watching them and then the gate and sensor pod start executing together
00:17:12 [W] Start executing.
00:17:12 [W] Together these payor Gateway and sensor is what we call serverless orchestrator.
00:17:17 [W] Now the entry point for the service orchestrator is Gateway.
00:17:24 [W] It's exposed externally as a service and it's a private serverless orchestration for these service.
00:17:35 [W] It can be very customized this service now because of this polling in the background the metadata about the Gateway can be added to the metadata of the bootstrap this URL
00:17:47 [W] Now because of these polling in the background the metadata about the Gateway can be added to the metadata of the bootstrap this URL of the Gateway and now you can
00:17:50 [W] Pink and now you can question osm and get this URL and this is your handle for orchestration now at some point request an HTTP request just comes into the gateway asking
00:18:03 [W] Eight serverless fast.
00:18:09 [W] We NF1 and nf2. Okay.
00:18:12 [W] So what happens gate with passes it to censor the reason payload on the message with the operation and the zero configuration and sensor could conditionally triggers Argo workflow. That just does their castration
00:18:24 [W] Configuration and sensor could conditionally triggers Argo workflow. That just does their castration.
00:18:27 [W] So here the Argo workflow appears and it runs using the Argo workflow controller and then instantiation configuration of NF1 and nf2 just happens
00:18:38 [W] Using the Argo workflow controller and then instantiation configuration of the NF1 and nf2 just happens managed by our workflow now after that happens at some point in time.
00:18:45 [W] Our workflow now after that happens at some point in time. Another request comes in for example to instantiate in F 3 and then
00:18:54 [W] Captain's those two sensors answer triggers in other castration float.
00:19:00 [W] Okay, because of this polling happening in the background, you see that the metadata such as IP and Port of the functions also is propagated to the orchestrator such as well as am okay.
00:19:16 [W] So it's not very complex.
00:19:21 [W] So essentially that was step two of our journey.
00:19:28 [W] So what they created on the right side, it's basically serverless orchestration based entirely on Argo workflows and Argo events. Torque is straight everything we had to orchestrate in our use cases.
00:19:42 [W] Ross use cases which was related to fast and then driven activities in this architecture.
00:19:51 [W] Every service has its own customizable event-driven management and orchestration plane running entirely in kubernative the service developer Persona gets all these different CNS from Network equipment providers and
00:20:04 [W] Into services and along the way she can now create kubernative knative orchestration flows with Argo packet in a standard way with by using this bootstrap configuration.
00:20:20 [W] just adding couple of your moles there which will bear these configuration when instantiated would create this gate when sensor and bingo you have your service orchestration for this instance of the service.
00:20:35 [W] All right.
00:20:45 [W] So this is all nice but then we scratched our heads and said hey gateways and sensors would proliferate in this architecture wouldn't they even if there are no events torque is straight the gate
00:20:50 [W] Pause the still sitting there and consuming resources.
00:21:06 [W] Yeah, it might be peanuts for one service but across the portfolio that can amount to some serious figures and somebody has to pay for that and it's not exactly pay as you go right so we decided to make both
00:21:09 [W] First clean knative services and they'll show you how it worked out in a second.
00:21:18 [W] You're welcome to check the repository that contains K negative events Fork to see if it what we did make sense to you.
00:21:24 [W] Also.
00:21:28 [W] will be happy to hook up is argue events folks to hear what they think in any case we thought maybe this can be a good feature in Argo events irrespective of our specific use case.
00:21:37 [W] Okay, and now it's time for a demo, right?
00:21:49 [W] So the demo will be based on on use case of mobile journalism.
00:21:58 [W] This is just to recap I hope you still remember this splitter face recognition speech recognition rtmp server in this demo splitter image face recognition and spiffe.
00:22:07 [W] Shrink ignition will be really fast functions and rtmp is Princeton seat.
00:22:15 [W] Okay, so, let's see.
00:22:18 [W] Will be a very simple demo without Wes a man to the end. Also without open whisk you'll just spawned put directly on kubernative.
00:22:31 [W] so we've applied both gate when sensory animals and they start executing you can see it in the middle window at this point the services on boarded on kubernative and it's ready for orchestration, but there
00:22:56 [W] Rate for an ollie dance. So why waste resources since argumentation is based on knat for both gay too and sensor then after a grace period
00:23:12 [W] Gail to zero so let's fast forward a little bit and they start terminating so gateway gateway goes down first scales to 0 first and then the sensor scales to zero.
00:23:29 [W] So give it a little bit more young.
00:23:34 [W] Let's fast forward.
00:23:36 [W] Okay.
00:23:39 [W] Yeah, so in the middle, so at this point the service is there but gate when sensor and not consuming resources and now to the orchestration part on the left you see the application progress,
00:23:57 [W] So at this point Gateway receives an HTTP request asking to start a new session for mobile production and the sensor triggers the orchestration flow that we follow in Argo GUI.
00:24:17 [W] In this demo, we expose every pot is not Port so that's why you see so many of them and in the uppermost window we can see which posts actually running
00:24:34 [W] we see that splitter with detector with speech everything is running and there are some completed steps these supports the basically Argo was running to complete the
00:24:50 [W] And orchestration flow related to the session.
00:24:58 [W] Okay. So at this point everything is ready and stream content starts go into the edge into the splitter and you see in the bottom window that media files start accumulating.
00:25:08 [W] We just use some test file here and just playing it right just simulating a journalist.
00:25:18 [W] It's not a real event that we are showing you can just some test.
00:25:26 [W] By the way, did you notice that in the middle window the Gateway and sensor started terminate because there are no events right now to orchestrate so they are not they sing resources anymore.
00:25:44 [W] They did the orchestration part now the scale down to zero again.
00:25:55 [W] Okay. So at this point basically we are drawing to the conclusion.
00:25:56 [W] Yeah stream is completed.
00:25:57 [W] And so the media files and method that I created.
00:26:04 [W] And the broadcaster so let's see what you've got now test file.
00:26:25 [W] There is no voice but that was not something I was expecting. But anyway, you see that there is a face recognition here and we have people talking and
00:26:45 [W] That I was expecting. But anyway, you see that there is a face recognition here and we have people talking and these are the captions believe me.
00:26:47 [W] they're talking so you can try to get it from the captions.
00:26:55 [W] eyes
00:26:58 [W] It's drawing to an end.
00:27:01 [W] They're talking about tying these a physicist talking about time. So my time is up or almost up.
00:27:15 [W] Thank you for your attention. This concludes the demo and now I want to provide some remarks some concluding remarks.
00:27:24 [W] So first thing Argo was a lifesaver for the project the found it really really delivering on its motto on getting things done with granite is and
00:27:40 [W] It's remember I was talking about the journey. So at this point in our journey is starting during that maybe we do not need other piece traitors at all.
00:27:54 [W] Maybe kubernative was just enough and just see the demo that I just showed you right?
00:28:04 [W] Everything has been done by grantees Argo Argo events and so on.
00:28:05 [W] So indeed, what's osm role in this architecture or even if it was something else for example, it was on app for example instead of it.
00:28:17 [W] What would its role be?
00:28:19 [W] Of course, there are many more topics in orchestration there for example, OSS BSS governance, whatever but orchestration, maybe we just need kubernative and at the very least I would say
00:28:32 [W] Traditional orchestration eight engines still around much more functionality should be delegated to kubernative as it can complete a lot of stuff autonomously.
00:28:48 [W] I'm sure many people might disagree, but I'd rather to spark a discussion about this.
00:28:59 [W] Another point is that the basically followed Mama mindset because that's how we progressed in this project.
00:29:03 [W] And man is very workflow oriented but workflows and not really kubernative knative style for castration admittedly.
00:29:15 [W] We push the envelope here.
00:29:16 [W] We used Argonaut.
00:29:17 [W] what data pipelines orchestration by the way, we are doing this in another project but for Network function virtualization orchestration, but if you want to be grown at least knative we need to have sort of never-ending work flows because we never
00:29:31 [W] Forex tration admittedly we push the envelope here.
00:29:32 [W] We used Argonaut foot data pipelines orchestration, by the way, we are doing this in another project that for Network function virtualization orchestration, but if you want to be kubernative knative we need to have sort of never-ending
00:29:33 [W] So you can kubernative this and assume that the applications components are continuously failing. So operators one Natura linkerd Burnett is and we are looking at them, but we don't want to cancel advantages of the workflows.
00:29:47 [W] All these Journey kind of continues and hopefully next time I will be smarter and can share some answers to these questions that I posed until then.
00:30:01 [W] Thank you very much for your attention, and I'll be happy to answer your questions.
00:30:05 [W] Hello.
00:30:20 [W] so
00:30:23 [W] hello.
00:30:32 [W] thank you very much for coming to this session.
00:30:37 [W] It's a little bit like experiencing out-of-body experience kind of see myself from the outside.
00:30:49 [W] So I don't have the contact with the audience and it's a bit difficult. But let me let me try answering your questions if you have any.
00:30:51 [W] So let's go to the Chop.
00:30:57 [W] Let me go to the chat back.
00:31:06 [W] One question was about whether this is a reconstruction of the players.
00:31:25 [W] It was about the first use case that we have about telling immersive media.
00:31:30 [W] Yes. It was a 3D reconstruction of the players.
00:31:34 [W] It's a time-varying meshmark.
00:31:48 [W] To really to this new generation of the network of the mobile network known as 5G.
00:32:00 [W] so very 5G use case these people.
00:32:06 [W] Actually moving inside a virtual reality.
00:32:14 [W] It's a virtual world.
00:32:16 [W] They can move 360° in this world.
00:32:28 [W] And this is what the world was. Also another question of what tell immersive gaming actually is its simulates your presence in
00:32:33 [W] And contact with other Gamers. So basically the next generation of these games is going maybe to have haptic response so that if somebody
00:32:49 [W] Haptic response so that if somebody throws something at you in this virtual world, you're going to feel it going to feel pushback and stuff like that.
00:32:59 [W] So this is this is a family of use cases.
00:33:05 [W] Basically, it's not about gaming. It's also about learning.
00:33:09 [W] It's about teleconferencing. I think that
00:33:14 [W] If we had had a platform like this this time and maybe our experience it could con 2020 would look a little bit different.
00:33:30 [W] Maybe you could throw some things at me and I would feel it for my bed answer. So you would applaud I would hear you and all that without you know, special sensors just using cameras and gesture seems and stuff like that.
00:33:41 [W] So any other questions?
00:33:44 [W] Okay, I'm familiarizing myself with this interface as I go.
00:33:55 [W] So question 7, I don't actually see it.
00:34:09 [W] A platform like this at this time and maybe our experience it could con 2020 would look a little bit different.
00:34:21 [W] Maybe you could throw some things at me and I would feel it for my bed answer. So you would applaud I would hear you and all that without you know, special sensors just using cameras and gestures teams and stuff like that.
00:34:23 [W] So any other questions?
00:34:23 [W] Okay, I'm familiarizing myself with this interface as I go.
00:34:23 [W] so questions 7, I don't actually see it.
00:34:24 [W] So question 7, I don't see questions on I only have could okay.
00:34:26 [W] Thank you Argo function streaming media or other ages passing files.
00:34:28 [W] Okay. The role of Argo is in orchestration.
00:34:33 [W] You have two projects, right Argo workflows, which is currently
00:34:38 [W] part of the cncf sandbox landscape, I think and you have and you have argue events, which is not yet part of cncf
00:34:54 [W] Okay.
00:34:54 [W] thank you Argo function streaming media or other gauges passing files.
00:34:55 [W] Okay. The role of Argo is in orchestration. You have two projects, right Argo workflows, which is currently
00:34:56 [W] Part of the cncf sandbox landscape, I think and you have and you have argue events, which is not yet part of cncf
00:34:57 [W] They are just about orchestrating things triggering resources and kubernative.
00:35:12 [W] And one of the resources can be a workflow. Now. The actual job is being done by containers which we pack which obtained from serverless.
00:35:19 [W] So basically the developer creates things like transcoders for example in whatever language of choice. We had some functions in
00:35:35 [W] In Python, we have some functions created in Java in ogs and we had something in C++.
00:35:49 [W] So basically wherever you can you just create these functions on on the fast framework and then containers created for you.
00:35:59 [W] don't need to think about containers and they are managed by Copernicus and by this you can
00:36:05 [W] You can have all the advantages of the kubernative scheduling and networking and and stuff like this and with Argo you can also have orchestration.
00:36:21 [W] But Argo itself doesn't have to do anything is you know, streaming media or passing media doing things like that.
00:36:28 [W] Wouldn't it be better to use when Argo workloads instead of opening this to bootstrap Argo workflows instead of opening this to bootstrap the production of art events, I guess.
00:36:44 [W] Pattern can be applied also to why I'm Argo workflows.
00:36:55 [W] I'm not sure that I am Argo workflows. I have been around when we needed them, but we definitely because it's it's project actually started three years ago, but I think definitely need to take another look at this.
00:37:05 [W] this. Thank you. Thanks for the lead.
00:37:08 [W] So thank you very much for coming.
00:37:15 [W] I will be lingering for another 15 minutes at least on slack and I'll be happy to take your questions from them.
00:37:24 [W] Thank you.
