Live Migration of Production Workloads from Apache Mesos PaaS to Kubernetes: XFJN-9101 - events@cncf.io - Tuesday, August 18, 2020 8:30 AM - 67 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:05 [W] Hello everyone. Welcome to this live migration production workloads from Apache mrs.
00:00:15 [W] Pastor kubernative session.
00:00:19 [W] My name is Maria and my name is gouffran and we work for Nokia and Nokia is producer of network equipment and software and services for our communication
00:00:31 [W] Yes, and as you all know that Nokia and driven by its award-winning Bell Labs no Casey leader in the development and deployment of 5G networks. So 5G, you know, it's going to be the core of Connecting People
00:00:48 [W] Portworx already have any actually so we're still kind of give people.
00:00:53 [W] Yes, we do.
00:00:54 [W] This is the story.
00:00:59 [W] So in today's session what actually we're going to talk about we're going to talk about migration story our migration Journey from mrs.
00:01:08 [W] Based pass to kubernative.
00:01:14 [W] So just imagine as you can see already also on this slide there is a gift which is showing that two trains moving side-by-side first one definitely the messes something that we start working on in the beginning of the project. So messy,
00:01:24 [W] Running all the workloads providing all the services and so on and then kubernative comes in and sharing the same platform resources, right, you know moving side by side and then the workloads are migrated from one platform
00:01:39 [W] And the one without interrupting the existing services without interrupting the users so as seamless migration on a shared platform, we got to talk about this today in this session our journey of Macy's pass to kubernative,
00:01:55 [W] Yeah, right.
00:02:00 [W] So a little bit about our project.
00:02:02 [W] What was it all about?
00:02:06 [W] So the mess was is only the orchestrator or kubernative later on on top of the orchestrator. What we have is a big data analytics platform.
00:02:17 [W] We provide a set of services for end users who bring Network specific data into our platform there.
00:02:26 [W] A store this data, they use several tools but the platform provides for analytics, they use a bi tool for presentations. So this is never stopping process of different data
00:02:40 [W] in
00:02:43 [W] Hundreds of users hundreds of data analysts working on the clock to provide analytics for our customers and on the screen you can see the high level architecture or of this platform.
00:02:59 [W] You can recognize probably the hello goals of several open source components.
00:03:05 [W] So we concentrated on using open source.
00:03:07 [W] So this is Apache mesos. We are not using mesosphere.
00:03:10 [W] Right.
00:03:15 [W] So the goal was to switch keep the platform as it is keep our users working as they were but in the in the lower level move slowly from
00:03:27 [W] Leslie you don't say yes a from mesos to kubernative us orchestrate.
00:03:38 [W] Yeah, and just to mention a few things to this is a big data platform.
00:03:41 [W] So it's we had around five five approach instances across four different continents and thousands of users.
00:03:53 [W] You know, this this platform has been also used to do things like suggest MDT minimization of protests in our predictive analysis and process.
00:03:57 [W] You know terabytes of network element data in a performance data and so on and do some analyses is stored in the database and and visualize it there are also many different successful even a customer cases as well
00:04:13 [W] Is apart from has been used actually for doing those things.
00:04:22 [W] I think we started this project around 2015 or incorrect time frames, but by 2018, we noticed that you know, kubernative was getting a lot of Industry attention
00:04:32 [W] But by 2018 we don't understand, you know, kubernative was getting a lot of Industry attention investigators were starting to use it.
00:04:39 [W] It was starting to become Industries darling. And we also wanted to adopt it for a million different reasons and many different reasons and you know kubernative was getting becoming the center of a growing Community quickly reaching
00:04:50 [W] Clearly reaching production will maturity and there are more and more features being promised to kubernative. And while we actually noticed the same time that mrs.
00:05:04 [W] Was getting less and less or done less and less features come to miss us but kubernative was getting more and more people working on it and also one of the reasons could be that mrs. Was at that time, you know productized
00:05:14 [W] On it and also one of the reasons could be that mrs.
00:05:15 [W] Was at that time, you know productized or are there was any dress version and there were less and less people working in miss us but also for kubernative sized arresting such as you know, David sets the deployments, you know
00:05:24 [W] Just say no Damon said said you'd want man. So, you know defying your application that had chairs placed among the benefits that we saw, although there were some leggings on the achievements Parkside that you couldn't run Spire creatively and kubernative,
00:05:36 [W] Managing these simple pretty simple Liam's and Krista, but the benefits were much much more than you know, some of those things so bucks.
00:05:52 [W] Yeah, and since we did a spike where we identified how you would like to migrate so though, we're not really any issue for us because we bet planning to run both the platform's
00:05:59 [W] Slowly migrate components one by one in a really strict and manner prioritized and also they were rollbacks and features like, you know, since they're sharing the same
00:06:15 [W] This developers were also being able to use those things.
00:06:22 [W] So we started moving to communities right he bit of a mess is over always about my sauce exactly so we can take a look at the high level architecture as you can see on the left side of
00:06:34 [W] we have the basic highly available cluster 3 masternodes to and stand by one active Nats leader zookeeper in the back end keeping the leadership on and the worker knows who actually
00:06:50 [W] The workloads.
00:06:53 [W] So how the workloads get there.
00:06:55 [W] all the worker nodes provided their availability and the resource situation to the master the master hosts the application definition through this application model and when the application also called framework
00:07:11 [W] Yes, Miss. World is ready to launch a job at ask it uses a schedule.
00:07:22 [W] So selecting the available node based on the available resources the schedule launches an Executor and the executor hosts tasks.
00:07:35 [W] Yeah, these tasks are actually the application the the if we take for example spark a participant as an example. So Apache spark as a framework doesn't do.
00:07:42 [W] Anything when when it's ready to process data through mesos Master, it selects the appropriate worker or workers and launches the executors who actually do the data analysis and on the other hand, for
00:07:57 [W] Somebody Martin framework that have been using it's one of the popular Frameworks for mrs.
00:08:05 [W] To around, you know containers don't necessarily have to be containerd.
00:08:10 [W] You can run some tasks or even some scripts using it. So in mrs. Screeching it works that you've got different Frameworks and registered to mrs.
00:08:16 [W] They're getting you know resources from the resource pool from mrs. And working based on this, you know dynamic resource fairness scheduling policy. Yeah, so that's the basis of review.
00:08:28 [W] And if we look at this kubernative server being here this pictures as you can see basically the same thing is almost the same things.
00:08:35 [W] Of course, you know, both of them have are sharing ancestry Google Borg, but also in kubernative you can see the architecture is like three Master nodes or you know, there is even like elections going on and leader and I've got this
00:08:50 [W] I'm gonna try my job this stuff and the work in those you can see Qibla to which is basically, you know, making sure that the containers were running important to keep proxy.
00:09:06 [W] You take care of the and tracking Etc. But in the kuma mess aside the mrs.
00:09:07 [W] Slate for mrs. Agent actually process that was at the in girls similar things.
00:09:16 [W] So they are very much similar in terms of you know, how they're working this cugini one. Also you can see here on the right. Basically you see
00:09:23 [W] Allure to mrs.
00:09:25 [W] Then this is the picture together like the marriage of messes and kubernative.
00:09:29 [W] Yes, that is true.
00:09:35 [W] So the way we selected to go is to host them together not on site. So two clusters working together in the same pool of resources.
00:09:45 [W] We didn't want to have separate clusters separate deployments. What we wanted to do is to keep the existing production.
00:09:51 [W] Thumbs up and running and basically hook kubernative into this setup.
00:10:01 [W] They would share resources on the on the control plane. And also on the workload management, they would be completely invisible to the end users and applications that were already working on
00:10:15 [W] You to do so and the new applications or the migrated applications would be hosted on the kubernative cluster running in the exactly the same place.
00:10:30 [W] So as you can see Master notes.
00:10:32 [W] Same three four methods and kubernative and worker nodes all of them sharing both mesos and kubernative workloads.
00:10:47 [W] this there is a small gray box in the in the worker nodes which represents our magical script which is called cookie kubelet lovely preparation before upper.
00:10:57 [W] Yes, so we will talk more about the kublr proper, but this was just one more messes up.
00:11:02 [W] Nation that was running in the background.
00:11:10 [W] No, he user interface, but it was taking care that the kubernative workers were up and running and we're able to consume some resources from the host and hence
00:11:19 [W] Loads, yes. So basically when you run the kublr Trevor Martin boom, you've got discover in this cluster, you know, and interesting thing is that they are not fighting with each other's resources as you can see here in this Cupid preparing
00:11:34 [W] And fighting with each other's resources, as you can see here in this Cupid preparing marathon in this slide. You can see how keep it river is running in marathons.
00:11:45 [W] So basically imagine you do not your application is not doesn't necessarily need to be have a container it can you can just run any any script script or tasks know there is mrs.
00:11:51 [W] Containerd as as well so we can see here achievement river running in Marathon and with this Marathon job.
00:12:02 [W] what we can do is we can control how many nodes from the cluster will be, you know sharing resources and become yeah also become kubernative not and also we can control the resources how much CPU is in mammals they will have and
00:12:14 [W] I'm with this, you know kublr system reserved parameters, then kubernative will not be confused with, you know, mrs. Youth resources.
00:12:29 [W] And so basically all the users that are used by mrs. Is seeing the kubernative system reserved and you know, then there will not be any other subscription or in are any issues with the you know limitations of resources of fighting with the resources and
00:12:42 [W] Mrs. Also on the other side is able to see how much resources kubernative he's using from particular node. And so on you can actually even run kubelet with no resources assigned at all. So basically that is that could be used for Automation and stuff like that
00:12:57 [W] This is assigned at home. So basically that is that could be used for Automation and stuff like that. And and so, you know, even a even a no Discerning kublr. It doesn't necessarily mean that it is it has resources we can control those from this.
00:13:07 [W] So this is really a very nice magical script.
00:13:12 [W] Okay, it looks very simple but we we try to follow in our This Kiss principle. Keep it simple stupid, you know systems work best when they are kept simple and we also are a bit lazy we try
00:13:22 [W] to do less and gain a little bit more. But of course all these are coming from Spike which we started, you know, when we started thinking to move to kubernative, but now that we have seen the picture of a cute like a rapper in
00:13:37 [W] And we also are a bit lazy.
00:13:37 [W] We try to do less and gain a little bit more.
00:13:38 [W] But of course all these are coming from Spike which we started, you know, when we started thinking to multiple mirantis, but now that we have seen the picture of a cute like wrapper in math on Maria like to say something
00:13:39 [W] Let's say something how we actually package it.
00:13:40 [W] Yeah, so how it all worked.
00:13:42 [W] On the platform major components.
00:13:53 [W] we're actually packaged into a VM image and this VM image was transported to the Target cloud with the platform was supposed to be deployed on yes, and this gave us the possibility to deploy fairly on any cloud in
00:14:03 [W] Or in our internal Nokia Cloud, which was the actual environment where we had a production clusters Runnings.
00:14:18 [W] So from the list on the screen, you can see all the components you can see mesos you can see marathon kubernative and so on. So these are the open source applications that we would deploy.
00:14:27 [W] The platform and as part of on the little box on the right, you can see that that's part of the kubernative role or qualities folder is where we have the wrapper. So basically, you know is using Packer. Basically, we're just creating the
00:14:43 [W] Folder is where we have the wrapper. So basically, you know is using pack are basically we're just creating the images and all the necessary binaries and scripts.
00:14:51 [W] You know that we would like to let say carry offline in certain offline cases, which was actually one of our major requirements as well that we would be able to deploy it offline.
00:15:02 [W] And so you basically, you know pack up everything in your laptop or in a USB stick and dividing a customer premise or in North environment case where you don't have access to Internet.
00:15:10 [W] So packaging the be an image now that we have it in the VM image.
00:15:15 [W] We launch it from Marathon.
00:15:27 [W] Yes, so we're ready to deploy with image. And yeah and this you can see here is just some AB definition in my throne, even the killer River itself also deployed in a metadata driven deployment way. Which
00:15:32 [W] if I doing our skips his spine can sorry there is bike that we can leverage the existing way of deployment so that it's much easier for the developer teams to you know,
00:15:47 [W] I meant so that it's much easier for the developer teams to you know, migrate their applications.
00:15:50 [W] So as you can see here this app type Helm so in Epcot llamo the developers would put AB type Helm after creating their hand chart, of course for their application and then our command line tool
00:16:04 [W] Now our command line tool will just we just identified as and you know Helm application and it will this install with him and if they didn't provide it with me that they didn't need to make any changes.
00:16:16 [W] You know applications that are running and messes that you need to make any changes.
00:16:30 [W] So the existing way of was also working and we also were able to gradually move to kubernative in a based on priorities and release Silas cycles and so on.
00:16:37 [W] So on the bottom side, you can see there is an example of couch TV.
00:16:42 [W] We don't have this app time happen. So this was actually a marathon application.
00:16:45 [W] Yeah, so that's how it's been deployed and although it leaks all these things look very fair.
00:16:49 [W] Simple, you know, definitely there are many other things underneath but these are simplifying for the presentation see vying for the presentation.
00:16:56 [W] Yes, here is a picture of little things what we have learned from this project.
00:17:05 [W] Jerry also, although there are a lot more than a lot more. Yes little and big things so we kind of found within practice and while implementing the side-by-side deployment of the balls clusters.
00:17:20 [W] He's using them side-by-side and troubleshooting of courses as usual you have issues on the way. So we found out that part of the of the winning kind
00:17:33 [W] A picture of little things but we have learned from this project just sharing also, although there are a lot more a lot more. Yes little and big things so we kind of
00:17:35 [W] Found within practice on while implementing the side-by-side deployment of the balls clusters using them side-by-side and troubleshooting, of course as usual you have issues on the way.
00:17:37 [W] Scum from the correct strategy. So and the point in the achieving the best strategy is to study first.
00:17:44 [W] So we did a spike us confirm mentioned implementing the side-by-side deployment hosting workloads and making sure that the resource consumption was
00:17:55 [W] controllable for both clusters following the kiss principle. Keep it simple, right?
00:18:03 [W] Yes and achieve more with less.
00:18:15 [W] So we don't need more facile planks, you know complex systems term. Yes, what we need is to keep running as with it but introduce these proper little cluster and
00:18:22 [W] Other thing also here we can see we're clearly saving resources.
00:18:34 [W] You know where Chloe is saving some different complexities. Like if you would like to have another kubernative cluster deployed, you know with dedicated hosting stuff like this then you know backup and restore you need even more resources and it gets
00:18:42 [W] Walk in the new cluster into an existing platform.
00:18:51 [W] We took advantage of the logging management of the Matrix management the Telemetry system where exercise nginx land we didn't move them to kubernative.
00:19:02 [W] So there were being shared between the both platforms. And since we use the same overlay Network all the logs
00:19:08 [W] Every container that was running there was collected by the let's call it old system.
00:19:20 [W] So everything was working as expected with a slight difference that some applications were hosted on kubernative.
00:19:27 [W] Yes and one immediate measure.
00:19:28 [W] Is this kubernative manages a demo and sets? You know, very smoothly.
00:19:34 [W] it's very nice and also the deployment for the helm applications, you know, the climate preparedness, although in the beginning.
00:19:46 [W] I remember at there was this him to and there were some issues with you know, accuracy are deers.
00:19:48 [W] Yes, and it's very good.
00:19:49 [W] Yes and button with Kuma his Helm 3 has been resolved.
00:19:55 [W] Yeah, So Meta driven.
00:19:58 [W] Tway was really helpful for us and kubernative and mrs.
00:20:06 [W] Passive properly you may have issues.
00:20:19 [W] Let's say, you know the applications requiring certain resource that none of you are and nodes or what kind of actually providing and it can happen even for spok jobs as well.
00:20:30 [W] Yes, which is one one thing that now that you mentioned that they mentioning topic is very important because it did happen to us at least in the beginning where development teams were getting used to the fact that if they are going to deploy the application
00:20:41 [W] Mess with us anymore. But on kubernative they would need to tune.
00:20:50 [W] Yeah, the resources assigned to kubernative through the kublr is rubber. So the magical script was not so much you go anymore if you didn't provide the right information to exactly yes.
00:21:03 [W] Yes. So there was some effort needed from everybody to kind of keep in sync between resource consumption and migrated applications.
00:21:09 [W] So basically we also didn't
00:21:12 [W] Have any duplicates within the within the shared platform, so we were sharing or for example, you know Telemetry systems and even the FCD same activity was being shared, you know, so we were also saving
00:21:27 [W] Interview if you have you don't necessarily get multiple Services, you know one for each.
00:21:35 [W] Yeah dedicated for each.
00:21:37 [W] Yeah, so that's basically it there are a lot more.
00:21:42 [W] Feel free to Ping us.
00:21:43 [W] We will definitely share and here is a bonus just a picture of some of the tools that we have used and loved.
00:21:51 [W] Yes.
00:21:54 [W] Yeah and Maria has myself as mentioned during this session already some of these you know that
00:21:57 [W] probably you're already using and kubernative these they're bigger.
00:22:05 [W] It's dangerous darling and our new baby.
00:22:08 [W] Yeah.
00:22:09 [W] or it's not new anymore. But yeah.
00:22:10 [W] Hi, so this is the end of our session.
00:22:16 [W] Thank you very much for joining and we are ready for your questions.
00:22:24 [W] We have some had some already in in the chat to have time for more.
00:22:28 [W] So please write your questions.
00:22:29 [W] Meanwhile, we can maybe share what questions were asked one of the questions were what is marathon.
00:22:37 [W] Is it a nap?
00:22:38 [W] Yes, it's an app actually second one was how did we handle the player for load balancing where the applications from Messy side accessible from the kubernative says yes,
00:22:52 [W] Algol to be able to share, you know, similar risk like that all the resources and all the services within the both of the platforms to be shared.
00:23:07 [W] So for example Telemetry systems monitoring and alerting all these things. They were being shared before even being moved to kubernative. And while we gradually moved from one to another way we're able to make use of the existing Services. Yeah,
00:23:19 [W] To mention and we didn't say it in the presentation that the nginx was one and only for both clusters stairs.
00:23:29 [W] There is also a question here.
00:23:30 [W] Yeah.
00:23:32 [W] Do you like to read it out?
00:23:32 [W] Yeah, sure.
00:23:33 [W] So cash. If is asking how will the whole system behave in case of resource congestion?
00:23:41 [W] Very good question.
00:23:41 [W] Yes.
00:23:43 [W] Yeah.
00:23:44 [W] So as you know that the during the presentation we have mentioned.
00:23:49 [W] and like messes is able to know how much you discover and diseases in in Kuma is also knows what is its limit and also we have got this, you know Telemetry systems monitoring and alerting where we were watching like
00:24:05 [W] Certain thresholds will get alerts in terms of you know, CPU or memory condition.
00:24:15 [W] So definitely we were getting alerts before you should happening in Ras Ras. We're taking a characters.
00:24:16 [W] But yeah so messes and and kubernative both the Clusters, even though they were sharing resources from the same resource.
00:24:26 [W] I pulled from the note, you know, they were not getting like in fight with each other.
00:24:32 [W] And before even there is another question.
00:24:39 [W] how do you decide false request limits for CPU? And memory do you use the vertical pot out of scalar or do you have a smarter algorithm?
00:24:48 [W] So I think not basically of those options I can answer that this one what we had. We had a predefined resource requests time limits for
00:25:03 [W] That we're migrated to kubernative from essos and we have estimated based on our experience in conducting these tests yet performance tests how much resource they would maximum be allowed to consume and how much they need
00:25:19 [W] So we would have signed kind of a fixed set of requests and limits for those applications.
00:25:26 [W] There is is there any more questions not?
00:25:38 [W] But these are really very nice questions. And you know with the migration is actually everybody has whoever have used some other clusters before before kubernative Z not they would have story magazine story and probably there are many
00:25:57 [W] People are following different approaches or our cases. We also wanted to save resources we couldn't just you know, go to have new set of resources in a new cloud account and you know deploy the kubernative cluster
00:26:13 [W] Set of resources in a new cloud account and you know deploy the kubernative cluster separately over there and then migrated, you know, that would be very costly for us.
00:26:22 [W] Yes, but this was really nice because you know, we were just not really wasting any resources.
00:26:25 [W] We're how many children do we have?
00:26:36 [W] conflicts for running mesos and kubernative master processes on same nodes
00:26:45 [W] No, when we don't have we had those are predefined we all the host ports that we had. Actually they were identified and any other products, you know, I mean, we'd overlay networks. You have got this for containers
00:27:02 [W] Some kubernative master processes on same nodes.
00:27:03 [W] No, when we don't have we had those a predefined we all the host ports that we had actually they were identified and any other products, you know, I mean, we'd overlay networks. You have got this for containers
00:27:05 [W] Unique IPS. So yeah, they are not conflicting with the parts.
00:27:11 [W] But basically we took care of defining the ports on specifying the port's carefully.
00:27:18 [W] Yes waffle it because the conflicts. Yeah.
00:27:20 [W] what platform did you use on premise if you refer platform like the cloud hosting Merlin on-premise our prayers? Yes, so on-premise we had open stuck.
00:27:33 [W] so
00:27:34 [W] This this platform of ours was running in in Nokia premises and we have an openstack cloud and okay has I think it's already known that one of the largest
00:27:50 [W] Provided to the internal developers and so on.
00:27:57 [W] So we were using that and it's built on top of openstack.
00:27:58 [W] Yes. There is one more question.
00:28:05 [W] Have you thought of running kubernative on top of mesos and not beside it likes question?
00:28:09 [W] Yeah with it and we decided not to go for that.
00:28:13 [W] Yes.
00:28:14 [W] And basically why because we wanted to get rid in the end.
00:28:25 [W] We wanted to get rid of mess with all together.
00:28:26 [W] Want to go this layer over layer?
00:28:32 [W] And side by side is actually then, you know basically they're independent of each other even though they're sharing resources when you have like one is different of the other than if you have issue with the one of them, then you have issue with the other one, you know?
00:29:05 [W] Any other questions we are running out of time counting 3 minutes.
00:29:22 [W] Yeah, but basically this mess kubernative on top of mesos was the mesosphere approach and they provided this service as part of the mesosphere which we didn't use.
00:29:29 [W] Yeah, we didn't use the Enterprise version of messes. So we were using the open source versions and you know, basically using as much as or was it 90 over 95%
00:29:39 [W] Symptoms the components where open source.
00:29:42 [W] yes, of course. We were in on tweaking changing adding stuff.
00:29:51 [W] I think everybody's doing that based on your requirements and this is serious. But yeah any other questions
00:29:55 [W] thank you very much for this questions. These are very nice questions. And was there another one actually, you know?
00:30:12 [W] Okay, so we can end up broadcast whenever yeah.
00:30:17 [W] Yeah, if there are no more questions, I think we can we can end the broadcast and thank you very much for joining and hope you enjoy the cube conned.
00:30:31 [W] Yes, the virtual one first-ever. Yes.
00:30:31 [W] Thank you.
00:30:32 [W] We have enjoyed.
