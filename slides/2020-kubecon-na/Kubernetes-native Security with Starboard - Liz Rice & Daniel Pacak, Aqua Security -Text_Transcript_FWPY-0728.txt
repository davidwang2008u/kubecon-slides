Kubernetes-native Security with Starboard: FWPY-0728 - events@cncf.io - Thursday, November 19, 2020 2:57 PM - 36 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Hi there.
00:00:01 [W] My name is Liz rice I run the open source engineering team atque security where we build tools to help Enterprises secure their Cloud native deployments and I'm here with Daniel patsak.
00:00:11 [W] Hi everyone.
00:00:50 [W] Hi there.
00:00:51 [W] My name is Liz rice I run the edge and Source engineering team at core security where we build tools to help Enterprises secure their Cloud native deployments and I'm here with Daniel patsak.
00:01:02 [W] Hi everyone.
00:01:03 [W] I'm a software engineer and aqua taking care of our open source projects including starboard.
00:01:10 [W] And today we want to share with you some background on what starboard is and describe some of the design decisions that we've made as we've been developing it and then talk a bit about the way we see starboard
00:02:16 [W] Can cut off our open source projects including starboard?
00:02:21 [W] And today we want to share with you some background on what starboard is and describe some of the design decisions that we've made as we've been developing it and then talk a bit about the way we see starboard
00:02:36 [W] so first of all, the motivation behind starboard meet our friend Dave Loper he uses kubenetes and to do so, he uses tools like keep control and perhaps our users our dashboard like
00:02:50 [W] So he uses tools like keep control and perhaps he uses a dashboard like optin or another kind of idea interface that uses the kubenetes API to access the cluster and
00:03:05 [W] to access the cluster and manipulate resources within that cluster now if they've is also interested in Security today, he has to learn to use a variety of different
00:03:21 [W] They all have different interfaces.
00:03:23 [W] They generate output in different formats. Maybe some of it is in HTML reports and some is in Json files.
00:03:32 [W] The idea behind starboard is to bring all these disparate tools into the world of kubenetes.
00:03:39 [W] So we've created the starboard CLI tool that provides an interface a familiar Q control plug-in interface that Dave can use to run security tools and it creates the
00:03:55 [W] Bring all these disparate tools into the world of kubenetes.
00:03:56 [W] So we've created the starboard CLI tool that provides an interface a familiar Q control plug-in interface that Dave can use to run security tools and it creates the
00:04:38 [W] Form of came in at ease custom resources that they can access using keep control and the dashboard so over to Daniel to show us the CLI in action.
00:04:54 [W] Austrade how we can run the kubenetes security tool via the starboard CLI interface.
00:04:59 [W] What I have here is a local kind cluster with 4 nodes 3 worker nodes, and we also have to install starboard binary in here.
00:05:10 [W] I'm installing it from the crew index and we have to initialize.
00:05:16 [W] Starboard, it's one time command.
00:05:19 [W] It is creating all the CRT definitions and service accounts and configuration map. And with that we could trigger kubeedge scanner since we have 4
00:05:34 [W] trigger kubeedge scanner
00:05:38 [W] Since we have 4 nodes, we are spawning for kubernative jobs, which are scanning and or running benchmarks on each node.
00:05:47 [W] Once it's done we could list the results.
00:05:51 [W] So as you can see for each node, we do have all the checks run and you can see immediately that there are some failures for those who are more familiar with user interfaces or graphical user interfaces.
00:06:07 [W] Starboard plug-in and this plugins allows us to navigate to the list of nodes select a particular node, and we contributed as he is communities Benchmark, which simply shows the same information as you saw in the terminal.
00:06:25 [W] So the CLI allows our friend Dave to run security tools and manually through Q control starboard.
00:06:34 [W] The next step is to automate this using an operator.
00:06:39 [W] So we've created a starboard operator at the moment. It just runs vulnerability scanning on workloads resources.
00:06:48 [W] So the operator watches for new pods starting in the, Connecticut.
00:06:55 [W] Stir and it runs a vulnerability scanning tool.
00:07:00 [W] We have a couple of options already implemented and what we're talking about that later having run the scan job the operator writes the vulnerability report custom resource so over
00:07:15 [W] As the operator in action.
00:07:17 [W] Yeah. So let's take WordPress as an sample application would you can see is the deployment descriptor? But this time I'm going to use a octant apply your mail file feature to create this
00:07:32 [W] Feature to create this deployment.
00:07:23 [W] And now if we switch to the starboard operator nature is this is where we run.
00:07:29 [W] This is the knative pace in which we run the operator itself. And in the same namespace, it's pain immediately.
00:07:36 [W] Ask Angela.
00:07:36 [W] It is an updated so we could actually figure out which workloads it is scanning and it's related to the active replica set of the WordPress deployment. If everything is fine this job is out.
00:07:51 [W] Automatically clean it up and the operator will create a vulnerability report and associated with this replica set.
00:08:03 [W] So we could also go and see what is going on.
00:08:08 [W] And what is the descriptor of this image?
00:08:12 [W] There is an innate container.
00:08:13 [W] There is a WordPress containerd.
00:08:15 [W] That's actually the command that we running and says octant is automatically refreshing the UI has been completed switching back to the default namespace WordPress.
00:08:30 [W] And here is where we make this vulnerability information available.
00:08:33 [W] There is a status card component and the plug-in displays the stats if you want to clear down drill down we have the vulnerability Tab and here is a list of vulnerability items the
00:08:48 [W] So I worked on the rolling update event.
00:08:50 [W] if we bump up the version of the deployment to see if the newer version has less critical vulnerabilities.
00:09:00 [W] We will see that in the same way.
00:09:02 [W] There is another scan job in the starboard operator namespace.
00:09:07 [W] It is using a different set of labels because now the active replica set for the application has changed, but if everything goes well, you will see the report updated.
00:09:24 [W] In here for now, it is still scanning. And here we are. The latest version has only two critical vulnerabilities and
00:09:38 [W] Again, we could drill down and see all the details here.
00:09:44 [W] Thank you, Daniel.
00:09:45 [W] So now you've seen starboard in action.
00:09:48 [W] Let's talk a little bit about some of the design decisions that we've taken while building it and you've seen how security report information is created and is associated with particular
00:10:03 [W] And we're trying to generalize handling different types of security report associated with different types of resources. As you saw we using labels on the security related resource to
00:10:04 [W] Cuban that he's results it relates to so we can use label selectors to extract the right security information for a particular Cuba Nettie's resource.
00:10:01 [W] But we're also using an owner reference and the good thing about this.
00:10:05 [W] is that when the owning resource gets deleted the associated security resource that owns. It also gets deleted.
00:10:15 [W] We simply don't have to worry about garbage collection because Kuma Nettie's takes care of it for us.
00:10:22 [W] Deciding to use this owner reference approach actually settled a whole other design decision for us.
00:10:29 [W] We've been going back and forth on whether it would be useful to maintain historical security reports and by using this owner reference.
00:10:42 [W] We know we're going to be cleaning up security resources when the associated resources deleted so we can't hold on to
00:10:51 [W] Historical information and actually that makes a lot of sense because kubenetes isn't intended to hold a historical database of things that have happened in the cluster in the past.
00:11:02 [W] So there's no reason why it should hold onto security reports from the past either.
00:11:07 [W] There are other options for that log the information and store it elsewhere outside of the cluster.
00:11:13 [W] Each of the security report resources initially.
00:11:16 [W] We thought of using a uuid because it would definitely be unique but it's a random string that's meaningless to humans. The alternative would be deterministic name, but when we were still thinking about historical reports weaveworks,
00:11:32 [W] We thought it would be more complex.
00:11:11 [W] We could we could solve the problem. But to make those names unique would involve doing something like including a timestamp if we wanted to make it a human readable name.
00:11:21 [W] So we initially lentils The Simple Solution which was just to use uuids and know that they would be unique.
00:11:31 [W] Once we've decided actually we're not going to store historical reports.
00:11:36 [W] There will only ever be one security-related custom resource related to a particular resource.
00:11:45 [W] The whole naming issue stopped being so complicated. We could use deterministic names because concatenating the resource type and its name gives us a unique ID within the namespace and it's meaningful to events.
00:12:00 [W] A custom resource related to a particular resource.
00:12:02 [W] The whole naming issue stopped being so complicated. We could use deterministic names because concatenating the resource type and its name gives us a unique ID within the namespace and it's meaningful to events.
00:12:31 [W] Also have a useful implication in the implementation right Daniel.
00:12:37 [W] Yes, since we are using the controller runtime Library as part of the starboard operator code base, which is using a pretty Advanced communities client with its own cache this
00:12:52 [W] Solve the problem of duplicate vulnerability reports that we happen to create from time to time because we were not leveraging at this whole caching mechanism.
00:13:02 [W] So the eventually the resource name like a deterministic name rates better in the CLI interface, but also improves the reliability and implementation of the operator.
00:13:17 [W] When we first spoke with customers about starboard something their doors happen, very quickly was role-based Access Control.
00:13:25 [W] generally speaking.
00:13:27 [W] Dave should only have access to the security information related to the resources that he has access to so putting those reports in the same namespace as the resources can make our back configuration pretty straightforward.
00:13:44 [W] But as you saw starboard needs to run jobs and we have to decide what namespace to run those jobs in we decided to do that in a separate name space for starboard for a couple of
00:13:59 [W] It's in the same namespace as the resources can make our back configuration pretty straightforward.
00:14:06 [W] But as you saw starboard needs to run jobs and we have to decide what namespace to run those jobs in we decided to do that in a separate name space for starboard for a couple of
00:14:36 [W] First of all, it means starboard doesn't need permission to run workloads in your application name spaces.
00:14:42 [W] And that's better from the point of view of the principle of least privilege has we want to give everything as limited permissions as possible. So starboard can only create these jobs in its own namespace.
00:14:57 [W] The other advantage of this is that when Dave is looking at the applications running in his name space.
00:15:04 [W] It's not cluttered up with the occasional scan jobs that starboard starboard operator would be automatically creating.
00:15:15 [W] Now for the CLI the scan jobs run in a starboard namespace and for the operator they run in whatever namespace you're running the operator in right?
00:15:26 [W] Yes, not this also that not every resource building a kubernative is a scope to in a space.
00:15:34 [W] there are nodes and for the and you saw in the demo that we run qu Branch for each node, and then we associate report.
00:15:45 [W] With an old so in this case, we also distinguish between namespaced and cluster scoped Custom Security resources.
00:15:53 [W] So vulnerability report would be nice pursed report where as already mentioned kubeedge reporta que Canta report is a cluster scoped resource.
00:16:03 [W] Dating a security Report with a resource when it comes to running workloads.
00:16:08 [W] We actually had a few options to consider remember that we're trying to make it easy for Dave Loper to find out the security information about his workloads who's running applications now if he runs
00:16:24 [W] It's pretty straightforward that the vulnerability report is associated with that and manage poddisruptionbudgets. We're talking about deployments.
00:16:25 [W] There could be multiple instances of each pod.
00:16:29 [W] And if we return associate vulnerability reports with those pods, we have duplication those reports can actually be pretty large so it could turn into a practical storage issue to store vulnerability reports
00:16:44 [W] So we decided not to do that.
00:16:45 [W] and alternative might be to think about associating the vulnerability Report with the deployment after all, that's the resource that Dave is typically going to be manipulating but there is a problem with this
00:17:00 [W] Replica set color deployment and if we're if we have multiple replica sets they may have different images in their pod specs.
00:17:07 [W] So win the different vulnerability reports for those images those different images that they refer to.
00:17:15 [W] So the conclusion is we need to hold vulnerability reports associated with replica sets.
00:17:23 [W] When you come to think of it unmanaged pods can also be replaced with a pot of the same name but a different image. So for that reason, we include a label with a hash of the pods back so that we can tell if the security
00:17:38 [W] In a pod is out of date.
00:17:41 [W] Even if we're storing these vulnerability reports per replica set from Dave's point of view.
00:17:47 [W] He's probably interested in queering it related to his deployment.
00:17:52 [W] So we've made it easy to Traverse the hierarchy so that you can make a query at the deployment level and it looks up the vulnerability information from the associated replica set and over
00:18:07 [W] It he can make a query at the deployment level and it looks up the vulnerability information from the associated replica set and over to Daniel to show us the hierarchy.
00:18:14 [W] All right, so just to show you the current report that we have in our cluster.
00:18:19 [W] We scanned all the nodes with kubeedge and as you can see we set the under reference for this report to point to a kind worker node, but also you see that it's
00:18:34 [W] Note, but also you see that it's because of this great control tree plug-in.
00:18:41 [W] We see the whole hierarchy of objects.
00:18:43 [W] It's even more interesting when we display it for the WordPress application since we did a rolling update. We have two replicas sets.
00:18:51 [W] sets. One of them is active as you can see this ready status here, and we also created a to vulnerability reports which are linked back to the replica set and just to show you
00:19:03 [W] What we mean by traversing the hierarchy of objects. So remember that even though we don't have the report associated with the deployment object, we do display this information, right because we can do programatically Traverse the tree and
00:19:18 [W] The vulnerability information right in the user interface.
00:19:26 [W] So we talked about how we envisage starboard being extendable and be used to show security reports generated by multiple different tools.
00:19:38 [W] Now, let's talk a bit about how or what you would need to do if you wanted to add support for a new security tool in to starboard.
00:19:52 [W] Hey beauty time.
00:19:53 [W] So here what you can see is like a quick explanation how starboard schedules jobs and how you can contribute or security Wendell can contribute with its own vulnerability scanner
00:20:08 [W] Could plug and play experience yet. But in general, we believe that we could support other tools out of the box. Like we have this reconciliation.
00:20:13 [W] Look that is constantly watching deployments or pods that are created and then starboard is taking care of scheduling a job adding all these labels that we explained and eventually persisting the report and here what we expect from
00:20:28 [W] To implement a simple interface to provide a pot template spec.
00:20:23 [W] This is where as a prerequisite. We expect that your vulnerability scanner is containerized so you could give us its image and then also build up the command that is used for scanning in case of 3D which is the default
00:20:39 [W] Aboard the command is pretty simple.
00:20:36 [W] It's like a image reference and then the treaty output converter.
00:20:41 [W] This is a piece of code.
00:20:42 [W] that is reading a controller poddisruptionbudgets previous model to the starboard model, right which in this case is the vulnerability to report it has its own schema, but we can't know what is the model of the third party tools of
00:20:58 [W] Stupids have to be implemented separately.
00:20:59 [W] And if we move to the next slide, you will see a simple interface called vulnerability Scanner with those two callbacks one is get bored.
00:21:07 [W] Template spec.
00:21:08 [W] That's the one where you specify.
00:21:09 [W] What is your image reference? And what is the actual command and all the arcs?
00:21:16 [W] And the second method is a callback to parse the stream of logs coming from the pod.
00:21:26 [W] if you intend to reuse all the Custom Security resources that we defined as part of spire starboard, you could also swap for example Polaris, which is used by default as a config Outlet tool,
00:21:42 [W] Because you comply with this schema of config audit report, you could reuse for example plugin. You don't have to build your own dashboard or something like that.
00:21:47 [W] Just fit the data with your tool and we will visualize it for you the same applies for other ideas for which we don't have plugins now, but since the crd is a common
00:22:02 [W] In communities and since we added additional printer columns, even the default UI for displaying custom resources in lenses.
00:22:24 [W] So today starboard is extensible.
00:22:28 [W] It's possible to add support for new security tools.
00:22:33 [W] You do need to write some code where we would love to get to in. The future is the ability to just add new security tools through configuration.
00:22:44 [W] Imagine that it's really a simple case of saying
00:22:51 [W] Telling the operator.
00:22:52 [W] I want to watch a certain type of resource. And when there are changes in that resource, I want to call a particular security tool and it will generate custom resources of this particular type
00:23:07 [W] Adding support for a new type of security tool would be a case of creating a new custom resource definition and adding in the the definition the configuration for that new tool.
00:23:17 [W] So that's the vision of where we want to get with plug ability today.
00:23:21 [W] It is a little bit more complicated. You do need to write a bit of code. But this is this is the ultimate goal and we would also be very keen to hear feedback on the
00:23:32 [W] resource definitions that we've created so far. We hope that they're flexible enough to plug in other alternative tools, but we're very open to hearing feedback.
00:23:47 [W] The last thing that we wanted to talk about in terms of the future of starboard is helping Dave Loper ask the question.
00:23:57 [W] What are the most security most important security issues in my class stir or what are the most important security issues in the particular namespace I care about
00:24:10 [W] We want to get to a point where we can summarize the most important issues from across these different types of security report. And you starboard to make it very easy for Dave to find out what security issues.
00:24:25 [W] security most important security issues in my cluster or what are the most important security issues in the particular namespace I care about
00:24:13 [W] we want to get to a point where we can summarize the most important issues from across these different types of security report and use starboard to make it very easy for Dave to find out what security issues.
00:24:44 [W] About so if that sounds interesting to you, you can download and run starboard from GitHub.
00:24:52 [W] It's also available on the artifact Hub and the operator Hub and we would love for you to get involved D come and check out the starboard repository on GitHub.
00:25:04 [W] You can get in touch with us or reach out to us here at the conference with love to hear from you.
00:25:09 [W] Thank you very much.
00:25:10 [W] Thank you.
00:25:19 [W] Hello.
00:25:21 [W] I had one.
00:25:25 [W] So I guess now we're in the slightly weird position of having answered some of the questions in typing as the presentation was going, but maybe we will we can also answer there's also a question or
00:25:40 [W] Black so we could cover those two.
00:25:43 [W] So one question that's coming on slack Daniel.
00:25:49 [W] I'll have you answered. This one. Is it possible to ignore given vulnerabilities or certain vulnerabilities? Like you can when using trivy in Harbor? Yes to some extent we
00:26:04 [W] None of the underlying scanner in particular 432 you can specify an array of severities that you want to show or saving a CRT or not.
00:26:14 [W] For example, if you are not interested in in low severity vulnerabilities, you could edit the starboard config map.
00:26:21 [W] That's the one that is created by the starboard init command. If you're using CLI, we have a very well actually the same config map structure for the operator. The operator on Startup is ensuring the
00:26:32 [W] this configuration parameter and you can and you can basically ignore those vulnerabilities vulnerabilities.
00:26:41 [W] We don't have a way to whitelist or you know deny this some of the vulnerabilities but I think at some point in the initial design phase we were thinking about kind of a another custom resource
00:26:57 [W] Some better structure than the config map which is, you know, untyped key values store which will allow us to implement this kind of functionality. But as of today of time of recording this video
00:27:09 [W] Capabilities but we would like to have such a feature if you have ideas how to do that.
00:27:06 [W] I believe we should have a CRT which not only represents the vulnerability reports. But also some kind of an advanced configuration of the scanners. Let us know and join the discussion we can do that.
00:27:20 [W] And another question that I think we've answered yet is does installing starboard automatically install trivy and the atque CSP and other dependencies, which is a sort of yes, but no kind of question.
00:27:36 [W] Trivy is open source and delivered as a container visually we can just run from starboard.
00:27:42 [W] Anchor CSP. You you do need to be a customer at codes to use that integration.
00:27:49 [W] So we can't just create a job and pull the component for that.
00:27:57 [W] Do you want to add something to that Daniel? Yeah. I think it's
00:28:02 [W] It covers how we currently Works 3D is the default.
00:28:08 [W] We pulled the tree V image from the docker Hub.
00:28:10 [W] As I said the prerequisite for a built-in scanners and potentially pluggable third party for diabetes cancer is that they are containerd I so we could run them as a kubernative job.
00:28:23 [W] I think we want change this underlying mechanism because we it's pretty easy and in terms of operation operations, but
00:28:32 [W] On the other hand, there are some requirements that we already heard about pulling the tree image not from Docker Hub, but from private registry even so I think we will put that on our roadmap and
00:28:47 [W] Back currently it's based on the configuration.
00:28:47 [W] So you have to edit this configuration config map, which I mentioned in my previous answer and then you have to restart so we are not yet there in this Plug and Play experience, but definitely the last slide that leaves showed was
00:29:02 [W] Say there's a really good question come in about the resource requirements for starboard and I can think of to interesting aspects of resources usage one is about the
00:29:10 [W] Use of resources. So if we're creating particular vulnerability reports that can be pretty large reports. If you have a image with a large number of vulnerabilities, there's a lot of information to store so we haven't
00:29:24 [W] And Tatian yet, but there is a question mark at what point, you know, does it will we hit in any issues in storing that information in that CD.
00:29:33 [W] It's an art and answered question at this point, but a very good one now, obviously if you don't have any many significant vulnerabilities that it's a problem that you won't hit so ideally we never have to deal with that but
00:29:48 [W] We should deal with the other interesting thing is about running jobs simultaneously and Daniel recently made an enhancement to apply back pressure.
00:29:59 [W] So perhaps Daniel you can talk a little bit about that.
00:30:02 [W] Yes. One thing I agree.
00:30:07 [W] This is a very good point one thing is a resource consumption in terms of data storage units CD which has its limitation and by creating too many
00:30:16 [W] New resources, we will employ we might impact the latency of the community see a pi server will try to measure it what it makes sense how many reports it is reasonable to store by default, but then also there is a
00:30:31 [W] Request and resources limits for each scanner currently it's hard coded to a default sensible values, but I think eventually we will make it configurable.
00:30:40 [W] So depending on the number of workloads or resources that you have or you want to pay for maybe we will allow you to run 3v with higher resource limits and
00:30:55 [W] The one last thing to mention here when we are talking is this back pressure when you install starboard operator on a not empty cluster, but on the cluster on which we haven't run starboard yet, but it has lots
00:31:06 [W] Empty cluster but on the cluster on which we haven't run starboard yet, but it has lots of workloads. The the the informers will detect that we need to reconcile, you know, the desired state for us is that there is
00:31:18 [W] Reconcile, you know the desired state for us is that there is a vulnerability reports associated with the particular workload.
00:31:24 [W] So it will potentially create a lot of scan job. So programmatically it is configurable.
00:31:31 [W] I think if I remember correctly the number of five or three concurrent scan jobs will be run other ones will be put back on the worker Q which is used internally by the show you former, so we are trying to optimize it so we do not flawed
00:31:47 [W] Stir with too many jobs, but as I said, this is kind of a this point maybe primitive configuration, but I think it's enough to not kill the cluster.
00:32:04 [W] I think something else that we could probably briefly mention that didn't exist at the time.
00:32:03 [W] We recorded the talk, but at that point we had the integration with octants and we've just added integration literally in the last 24 hours Daniels released a
00:32:19 [W] Ring of an integration with the lens IDE, and it seems like there are some other pluggable dashboards coming along. There's headlamp from Kinfolk.
00:32:31 [W] So I think we're really pretty interested in being able to integrate with these different viewers and dashboards and ideas.
00:32:43 [W] So if you want to add anything on that Daniel.
00:32:47 [W] Yeah, I think it's very tempting because this architecture on one hand.
00:32:51 [W] It's pretty simple.
00:32:52 [W] It doesn't require installing some external databases.
00:32:56 [W] So implementing plug-ins for such dashboards as octant or lens or even the I forgot the name the default kubernative - portal was always available.
00:33:08 [W] It's pretty easy. But on the other hand, we are thinking about mechanisms for
00:33:17 [W] Sending the scan results that we produce somewhere else via the web hook mechanism Etc.
00:33:25 [W] So this is also I think worth mentioning that on one hand, it's cool because you don't really need to install anything.
00:33:32 [W] you ready to go, but on the other hand, it's like a very common question what happens with that CD Howe impact performance of the API server Etc.
00:33:42 [W] So we would like to have more precise answers and I think we
00:33:46 [W] I think plug-ins for such dashboards as octant or lens or even the I forgot the name the default kubernative - portal was always available.
00:33:54 [W] It's pretty easy. But on the other hand, we are thinking about mechanisms for sending the scan results that we produce somewhere else via
00:35:41 [W] on the Project's read me or website Nats that relates to Duffy's question about having a mechanism for pushing security reports off cluster for retention, which we don't have today, but
00:35:57 [W] This idea of a web hook mechanism, which could be used to do things like generate alerts or send reports to long-term storage or anything like that
00:36:12 [W] I think we will publish one of those discussions which is currently happening somehow internally at Aqua to the Pradhan so you could track the progress, but it did we plan to have an option configuration option or in parallel send out the payloads of reports.
00:36:25 [W] The cloud to databases whatever you want to store it.
00:36:27 [W] So I think we're about to be cut off from the live Q&A. But Daniel and I are in slack.
00:36:34 [W] You can find us on you know on GitHub on Twitter.
00:36:38 [W] We're really pleased to hear your thoughts about starboard, and if you have ideas for us, we're really grateful. So thanks very much for joining us today.
00:36:49 [W] Thank you very much.
