Constructing Chaos Workflows with Argo and LitmusChaos: CJAP-0313 - events@cncf.io - Wednesday, November 18, 2020 4:57 PM - 45 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Hello, everyone.
00:00:02 [W] So founder and Chief Operating Officer at my data, and I'm also one of the maintenance on listeners chaosmesh a project in this session.
00:00:11 [W] I'm going to start with the litmuschaos project introduction and then boom it is going to talk about our go and do a quick demo of construction of a chaos workflow using litmus and Argo
00:00:26 [W] Let much it was is a cncf project.
00:00:22 [W] It is accepted as a Sandbox project early this year or mission is to help kubernative Sr. He's in developers in practicing chaosmesh Engineering in a cloud right away.
00:00:36 [W] Mayadata, integrate and Amazon or the current maintenance of this project is have is an asset to the project where all the chaos experiments.
00:00:49 [W] Our whole state together the community.
00:00:53 [W] Why chaosmesh knative kubernative?
00:00:56 [W] It's because your application resiliency depends on host of other Cloud native services or Cloud native applications.
00:01:04 [W] In fact 90% of the resilience of your application depends on some other Cloud native service or kubernative itself the how do you achieve resiliency the answer is
00:01:19 [W] Engineering, right?
00:01:18 [W] So what is chaos engineering?
00:01:19 [W] It is a practice of introducing a random fault into a system that is running at steady state and then observing if the steady state has been regained or not if s then
00:01:35 [W] Not you condom weakness the how do you do this on kubernative?
00:01:29 [W] You follow the kubenetes knative principles where the lifecycle of such an experiment is run using the chaos operator and the management is done using a set of custom resources
00:01:44 [W] Is run using the chaos operator and the management is done using a set of custom resources. In this case. Let us provides a chaos engine cri-o.
00:02:09 [W] How do you run this chaos and practice chaosmesh engineering at scale?
00:02:15 [W] So for that let Moses is introduced. It gives her clothes.
00:02:19 [W] He has workflow is built on above and Argo workflow or it uses an auger workflow to run multiple experiments.
00:02:28 [W] can configure to run them in sequence or in parallel and then this litmuschaos chaos workloads Allah dates the results of such experiments to give
00:02:39 [W] Meaningful result to the user because this entire workflow is run.
00:02:49 [W] Hitler a tively or configure declaratively you can practice chaosmesh engineering using gitops practice.
00:02:57 [W] Let's look at litmuschaos gasps architecture.
00:03:00 [W] Let us provides a Helm chart with which you can install a litmuschaos portal and then you can run a change litmuschaos agents on different
00:03:15 [W] Stutters where you need to practice a also engineering or you need to run ksx parents.
00:03:22 [W] This can be the same cluster on which installed portal.
00:03:25 [W] So once you have that you set up.
00:03:29 [W] Okay also workflow which will be picked up by the chaos operator and results in turning of the in experiments as per the flow defined the chaos for flow.
00:03:42 [W] And that results in a set of metrics chaosmesh trips and events, which are then uploaded to Prometheus for your analysis from litmuschaos Portal. You can run chaosmesh.
00:04:11 [W] Your Enterprise and it's not just a set up experiments that you're putting together, but it's a tool set that provides the entire infrastructure required for running
00:04:27 [W] scale across your clusters in your Enterprise
00:04:25 [W] Let's also look at chaosmesh.
00:04:55 [W] A label for you, you can stacked the remaining experiments using litmus SDK and if you think this new experiment is going to be useful.
00:05:10 [W] Your users you can also Upstream such an experiment you back to the hub.
00:05:05 [W] Let's look at a list of experiments that are available primarily.
00:05:11 [W] They are divided into generic and application-specific.
00:05:13 [W] You will see that there are currently there are about 22 genetic chaosmesh Paramount's the most famous One paying for delete.
00:05:23 [W] delete. That's the one that everybody starts using whenever they try.
00:05:29 [W] it must write one of the other important one is also a cubit service skill, which is an important function to test when you kubernative is
00:05:44 [W] Production and surveying at scale. This experiments covered a lot of variety across Network CPU memory disk and services
00:05:50 [W] And node in general using this generic experiments.
00:05:42 [W] You should be able to cover much of your chaos and training needs.
00:05:48 [W] One of the other important aspects of litmuschaos is how easy it is to build new chaosmesh ferments. We call it as bring your own chaosmesh.
00:06:18 [W] Ready to use that experiment into a chaos workflow.
00:06:21 [W] So how do you get started it let Miss litmuschaos provides Helm chart with which you you get a litmus portal and use that litmuschaos portal to select a predefined chaos will flow
00:06:36 [W] Net on your choice of kubenetes cluster.
00:06:39 [W] This is how let must portal looks like and once you login you will have a set of predefined experiments here.
00:06:52 [W] I'm showing a setup workloads that are already scheduled and run and you can go on schedule you a new workflow and that gives you
00:07:04 [W] a set of predefined workflows which you can choose and then you can tune the Vestige of experiments that are part of that workflow and then you schedule it when it is run you
00:07:19 [W] how a given chaosmesh flow was executed did everything go right or not, and it gives a good picture of the sequence of experiments that were run and also
00:07:27 [W] Bill provides a good amount of analytics around this chaos experiments and as stated earlier the mission is to help developers and stories, too.
00:07:34 [W] Pascal's and drink on kubernative in kubernative knative way with that introduction.
00:07:37 [W] Let me switch this session you submit
00:07:45 [W] Hello, everyone, as Kuma has given overview of litmuschaos its architecture and plug in infrastructure.
00:07:52 [W] We are one of the recipient of leveraging this plug-in infrastructure.
00:07:58 [W] I am smitten Ogle and today I am talking about chaos were flow with let much and using other workflow how we are leveraging the work flow capability.
00:08:11 [W] Little bit about me.
00:08:12 [W] I work for into it was a proud maker of TurboTax QuickBooks and mint I play kubernative lot of Open Source being in Java and python for a long time doing a lot of testing and performance work
00:08:27 [W] Loud on observability platform.
00:08:27 [W] I am leading a reliability engineering team as part of that team.
00:08:32 [W] We are building a paved road which helped which is on open source tools providing infrastructure and reliability for any specific service.
00:08:42 [W] It has a three solution of chaos engine performance and infrastructure. Now, this team is actually helping the Intuit developer platform, which is building next.
00:08:52 [W] Extend kubernative split some for into it.
00:08:56 [W] We have thousands of developers and hundreds of clusters with the more than 2,000 plus Services already on-boarded and this one is going Leaps and Bounds.
00:09:10 [W] this is a elotl architecture of this sin to develop at plate from where we are building a paved Road for any onboarding service and we give them a template so that they can onboard build their specific
00:09:25 [W] Thump, which is primarily on the kubernative hell leveraging AWS infrastructure.
00:09:21 [W] There are a lot of informations are available. And that here we come and be part of that this platform.
00:09:30 [W] wanted to build a very robust reliable and stable as well as we want that to be scale.
00:09:38 [W] Little bit about my chaosmesh Arnie. I've been working on chaos from last couple of years initially been working million the application side where we were building the historic circuit breaker as well as
00:09:53 [W] Like AWS chaosmesh and key and seminar me kind of stuff.
00:09:48 [W] We did some game day. So that bring lot of awareness about chaos last year. We started working on the this chaos toolkit.
00:09:57 [W] We build lot of use cases specifically from the application cloudbees AWS platform, which is a kubernative.
00:10:04 [W] We added many extensions when hence many extension and later.
00:10:10 [W] We wrap it up in service and created node buildpacks.
00:10:12 [W] this use case during that time there were many incidents happen not to our platform but a few of our products which being there in fraud that create a bit awareness about that how someone
00:10:27 [W] And build the resiliency for this. So what we started doing is that we try to see that if we can put this work to the kubernative and then we figure it out that it is a little challenging.
00:10:34 [W] We cannot pour that because of security compliance and the snot knative kubernative.
00:10:39 [W] So we did the initial piercing with the litmuschaos and we have many use cases more than 70 plus use cases specifically from application cloud and platform side weaveworks.
00:10:50 [W] No, we don't want it to rebuild everything from scratch.
00:10:53 [W] So what we have use and we build with the small PLC and help from the community.
00:10:59 [W] We build a plug-in infrastructure where all our work has been being executed by a custom resource and later point of time.
00:11:09 [W] We figure it out that how this work can be added as part of the ci/cd and workflow. We work closely with our workloads team and build the solution.
00:11:21 [W] And after that we have introduced the performance as well as the chaos, I'd by side and executed via Jenkin speculative pipeline.
00:11:33 [W] So this is the overall setup what we have for the chaos design where we are installing this chaos operator, which is coming as part of the litmuschaos as well as the few see IDs in one of the namespace
00:11:49 [W] Scent and after that we have introduced the performance as well as the chaos side-by-side and executed via Jenkins facility pipeline.
00:11:54 [W] So this is the overall setup what we have for the chaos design where we are installing this chaos operator, which is coming as part of the litmuschaos as well as the few say IDs in one of the namespace
00:12:25 [W] Reinstall the Argo workflow as well as Argo controller on another name space and we create many custom resources. This custom resources are the one which is actually being invoking our framework and with
00:12:40 [W] Our framework and with the right kind of our back. We are targeting specific application as well as the cube system specific animal species and all the data we are right
00:12:55 [W] Into various monitoring and observability solution, and this has been executed by Jenkins pipeline.
00:13:03 [W] Taking one level down how this magic is happening.
00:13:06 [W] We have this framework, which is actually being called in this custom resource custom resources are about what and then when you have created that chaos of operators will look for those custom resources and when
00:13:22 [W] Executing a chaos in aereo's that time the chaos runner part will come up which try to bring this experiment which is nothing but your container code which has a logic and then it will finish that
00:13:36 [W] Push the data to the kubernative event and then we have done internal integration of pushing the data to operation data leg. So it pushed to our operation data late. There is a one session on operation data like by Amazon widget,
00:13:46 [W] And then the all the result we are pushing to the chaos result.
00:13:48 [W] So by this time you have that idea that how this overall structure will there.
00:13:54 [W] I will go one level down that how this framework works.
00:13:56 [W] So we have this framework being exposed through custom resource.
00:14:00 [W] This custom resource is using an image which is a python-based containerd image and in this python-based containerd image. We are using chaosmesh will get framework which has many extension we use existing as
00:14:14 [W] As we build out and then it has a specific logic return which is using with the steady state hypothesis.
00:14:21 [W] It says steady state hypothesis before and after and then you go and execute the chaotic operation and later. It will go and push the data to operation data link.
00:14:33 [W] So everything in a nutshell if you wanted to take it out how this one is the so we are writing these use cases these use cases are nothing but our chaosmesh and test these tests. We are putting in
00:14:48 [W] This Argo workflow is a code, which is been shagging in the gate gate. We have integration with the Jenkins Jenkins pick this specific code and with Cube context it interact with one of the namespace and it's
00:15:03 [W] Go Argo will execute a workflow.
00:14:55 [W] this workflow will look that whatever instruction has been provided as part of this workflow that experiment exist.
00:15:05 [W] So this experiment which already being set it up on the specific name space.
00:15:10 [W] It picked that specific scenario it launched the chaos Runner. This chaos ruler will be be using and our existing framework image.
00:15:21 [W] JH and launch the experiment this experiment is ticking the code and using the cluster roll our back and Target specific part.
00:15:36 [W] And once the test is done it will go and it will bring the the result as well as the report to our oppression dipali now why Argo workflow? So
00:15:51 [W] We have seen that you can execute keep cattles and animals and then you can execute but logically speaking if you really wanted to execute everything as part of pipeline many scenarios it become very challenging.
00:16:01 [W] was one of the thing now with Argo workflow everything is coming as a one yawm Al where we can just use one of the parameter to the Argo submit and we can invoke that specific thing and everything is a code so you
00:16:05 [W] It and we can invoke that specific thing and everything is a code. So you don't need to maintain the various different kind of animal and we have scenario of a hundreds of clusters it become very very challenging how we roll it out as we are using Argo.
00:16:18 [W] go there are a lot of already cost optimization and resource utilization optimization already done that which is actually helping in the cost, which is I think one of the more important thing in the current pandemic going and
00:16:33 [W] We have introduced the chaos with the performance.
00:16:36 [W] We are getting more reliability.
00:16:38 [W] We are not only looking for statefulness of the chaos. We are getting the stateless nice of the performance and then we merge both of them.
00:16:45 [W] It helped us to build lot of complex scenarios, which is in Practical writing a script subtly Amal is not possible. And as this whole exhibition is happening in a manner that it is a very
00:17:00 [W] Scuttle yawm Al is not possible.
00:17:00 [W] And as this whole execution is happening in a manner that it is a very predictable it bring lot of trust and confidence in the overall setup last but not least
00:17:16 [W] Bring lot of trust and confidence in the overall setup last but not least it because it's a code self-service an onboarding is very very easy.
00:17:26 [W] And then as we are using workflow it become the complete lifecycle, whatever you have set the base state it will finish the same basted again.
00:17:37 [W] Now this is the final chaosmesh low set up how it will look like where you could see that we are running the chaos as well as the performance execution.
00:17:47 [W] I will go for the demo.
00:17:53 [W] We have this place where we put all our code base of all the animals and I will be executing two scenarios one scenario.
00:18:04 [W] is that from this namespace am creating chaotic operation and application and Cube system and I will try to do it with the existing framework as well as through go workflow.
00:18:17 [W] So right now here I have the space.
00:18:21 [W] cific
00:18:24 [W] Namespace where I have the nginx demo running and then I will just try to get this experiment added here.
00:18:40 [W] And then I can validate that.
00:18:47 [W] And then I will apply the are back.
00:18:50 [W] Of all the animals and I will be executing two scenarios one scenario is that from this namespace am creating chaotic operation and application Cube system and I will try to do it with the
00:21:05 [W] once I applied our back I can go the execution which is
00:21:12 [W] the chaos experiment using kubectl Critters python by the time it started. The runner pot has come up and they're on your part will initiate the
00:21:24 [W] Container which has a framework which is here.
00:21:27 [W] This container will try to do certain action based on the table how we have configured that so
00:21:39 [W] I have kept one experiment 1 so here you could see that we are using one of the image from litmuschaos.
00:21:47 [W] Chaos. Chaos toolkit image.
00:21:48 [W] This is our custom resource and then here we have provided certain parameters and this is the experiment. We actually use we overwrite those parameter and then we specify which specific experiment we are executing
00:22:04 [W] See her now here. It actually deleted that in the next demo, which is another app and it bring down that delete and then the runner part. So with this we are able to do
00:22:19 [W] This is a demo script and to have available at your fingertip.
00:22:12 [W] Now.
00:22:13 [W] Let's go to the another scenario where we want it to do this, but we wanted to use the Argo to do that.
00:22:19 [W] So now in this scenario where we apply a yarmul-claus I have parametrize everything and those parameters are that I want attacking one of camperdown the cubed M system and this time I'm passing a different.
00:22:34 [W] Closed toolkit file and then here I am just executing and then this will launch the Argo overflow.
00:22:43 [W] let me just go and grab that so Argo workflow when it will launch it will again do the same thing run at parties will execute and then there are no point job is to initiate that
00:22:59 [W] container
00:23:02 [W] and now here you could see that km pod has been terminated and then you could see that the run chaosmesh will be finished and then we will bring back the chaos them back to the same state I have
00:23:18 [W] The workflow also available through the nice UI.
00:23:22 [W] going grab that so Argo workflow when it will launch it will again do the same thing Runner party to will execute and then there are four job is to initiate that
00:23:33 [W] container
00:23:36 [W] and now here you could see that km pod has been terminated and then you could see that the run chaosmesh will be finished and then we will bring back the chaos them back to the same state I have
00:23:52 [W] The workflow also available through the nice UI.
00:24:06 [W] So this is the way it is executing now, everything is done now, I will go and I will so that I wanted to execute the chaos with the performance.
00:24:16 [W] That's the give me the value add of that if during chaotic operation. Something is happening to my and point.
00:24:24 [W] I'm going and this time I'm executing the test and it will impact the application part.
00:24:32 [W] And here I'm side-by-side running the performance test as well as I'm running the chaos test.
00:24:43 [W] So here chaosmesh Runner has been started.
00:24:48 [W] So here you could see that the flow has been started chaosmesh execution started as well as the test.
00:24:54 [W] Also. I started they both are going in parallel. I can go and look for
00:25:02 [W] workflow
00:25:04 [W] So here the pdb create happened and then I am execution as well as a performance test. Both are having side by side. Now one cares has been finished and you could see that the test is still going and the application
00:25:20 [W] Cooperation something is happening to my aunt point.
00:25:22 [W] I am going and this time I'm executing the task and it will impact.
00:25:27 [W] the application part
00:25:30 [W] and here I am side-by-side running the performance test as well as I'm running the chaos test.
00:25:41 [W] So here chaosmesh Runner has been started.
00:25:47 [W] So here you could see that the flow has been started chaosmesh execution started as well as the test.
00:25:52 [W] Also. I started they both are going in parallel.
00:25:56 [W] I can go and look for
00:26:01 [W] workflow
00:26:03 [W] So here the pdb create happened and then I am execution as well as a performance test both are happening side by side. Now one cares has been finished and you could see that the test is still going and the application
00:26:53 [W] Brought down I can go and look for my logs here, which is the performance test during this time.
00:27:03 [W] Here you could see that during certain time. There is a pod has been impacted impacted you could clearly see that and if I go and look for other one.
00:27:17 [W] I am right now running to part. So now with this you could see that we can go and identify all the problem on your application and we probably need to put the resiliency build on the tap application.
00:27:32 [W] Much.
00:27:32 [W] Thank you. So MIT, but that wonderful demo with that.
00:27:35 [W] We have come to the end of this session on creating chaos workflows using litmus and Argo is do take a look at the GitHub projects of both Lake Merced Argo.
00:27:49 [W] Thank you again for watching have a wonderful conference will next time.
00:27:55 [W] see you. Bye.
00:27:57 [W] Thank you.
00:28:17 [W] then why you want to start with the
00:28:25 [W] Questions that you can find experiments on the Hub
00:28:40 [W] Equivalent is notes doesn't matter whether it's on VMware not but if you have looking specifically for design Liam's on chaos such a of convenience, you can
00:28:51 [W] You can donate using the SDK provides and and it's pretty easy and we also have
00:28:56 [W] It's pretty easy, and we also have some beers in progress.
00:29:10 [W] Liam's so that's one question and there's also question about question from Christopher picks take existing work here.
00:29:25 [W] The question is we need help.
00:29:29 [W] delete testdir.
00:29:36 [W] really working or not. The most likely possibility should work if it comes back up, but the
00:29:52 [W] The trick will get it comes back up. But in the real world for then it comes back up but didn't
00:30:10 [W] What did Nick comes back up but it might work one. The particulate bodies come back for that litmuschaos
00:30:26 [W] Update most problems which simply means that you can Define purposes right?
00:30:37 [W] Well what should happen and it's totally customizable. So you can Define the test result Behavior so through that you can
00:30:55 [W] On this case called out.
00:30:52 [W] There are also question on what Bill I had no idea reporter. Like the state is one of the key enhance.
00:31:08 [W] As Connie said to intubate help.
00:31:22 [W] The two men in development projects the portal has it is in Alpha.
00:31:31 [W] It most likely it will go to be have the coming months.
00:31:36 [W] That's it.
00:31:50 [W] Whatever it is without all these things together will make a comparison very busy.
00:31:59 [W] right? So those are the question I won't say something to you.
00:32:15 [W] Chris vitess that this is pretty neat how it works in practice. So failure Friday or game day our engineering principle. It is tough to implement.
00:32:28 [W] Alright, so those are the question I won't say something to you.
00:32:44 [W] Come on, Chris.
00:32:45 [W] that is pretty neat how it works in practice.
00:32:49 [W] So failure Friday or game day our engineering principle. It is tough to implement.
00:32:57 [W] It's more about the culture.
00:32:58 [W] right Telco set of tools and you you get the right angle a judgment you build those things in Yalta prod you will be able to execute that. We are also on the journey we are not saying that we are running the game.
00:33:13 [W] Every Now open but we are working to make sure that all our clusters.
00:33:19 [W] we'll have our game day all specific time those who want what they can participate there was another question. Can we use litmuschaos for my application as Services both and kubernative + VM? Yes for kubernative.
00:33:33 [W] Definitely you can use that and Kuma mention about that so we can do that for VM, which is not specific to kubernative. I think.
00:33:43 [W] You probably need to get back on that or if you can raise the issue we can provide more insight, but right now it's more toward the kubernative knative.
00:33:56 [W] there was a question about the
00:34:05 [W] yes operator deploy is a demonstrate or is it a regular part to run experiment so chaosmesh?
00:34:35 [W] They will be running as Gaiman and based on the system results definition of the custom resource your defined you invoke experiment.
00:34:44 [W] This is the demo you could refer to that and you can get more insight. But yeah, it is a kind of running dominant anytime you give the instruction it will go and execute the expense.
00:35:00 [W] Yeah, and II can generally get your I said, what is that?
00:35:09 [W] How do I experiment or they're my team and
00:35:28 [W] infrastructure there and we have introduced the concept of reasons one is to host all the chaos experiments for various kubernative State sources and application
00:35:39 [W] That one's so that the community can pull those experiments and tune them and use them the second one more importantly is you may want it
00:35:52 [W] Need and that experiment needs to be managed right over a period of time.
00:35:57 [W] So you have something like public, you know, and that is very much possible.
00:36:46 [W] Continued to use in your own private repository.
00:36:53 [W] There's also a question on so you require data Lake to store your results.
00:36:59 [W] What are the trinamool cloudbees sources required to run chaosmesh modest two questions. One is the minimum requirement litmuschaos is pretty thin it requires two.
00:37:14 [W] Of memory and point when called upon you that, you know, if you are running multiple experiments for longer time depends on your customers experiment in terms of the results.
00:37:27 [W] The results are also formulated into custom resources.
00:37:20 [W] So by default chaosmesh.
00:37:45 [W] This question litmuschaos portal has a very small database that is more deeply the socio consideration and it also supports gitops your I mean, it's still in the making
00:38:02 [W] Video on gradually and gitops way to store in terms of results.
00:38:22 [W] Yeah, so there are a bunch of other Christians are one is related to that.
00:38:29 [W] Anna has asked about that. Let Mark on kubernative scale issues any finding so right now how we are executing is that per cluster? We are doing operator and it's a end-to-end kind of scenarios
00:38:44 [W] As we we are using Argo workloads given cluster we will be able to do that. But if we are going centralized can definitely be might have faced the issue.
00:38:47 [W] It's a more decentralized way of execution of I'll go there was another question about we are able to run the chaos tekton Windows container.
00:39:01 [W] Yeah, as long as you are on kubernative, so you should be able to do that without any issue.
00:39:11 [W] Arceus experimental manually, or they can be scheduled. I think this is a good question.
00:39:16 [W] We chaosmesh reduce the scheduling Concept in a very recent releases as well as Argo workloads.
00:39:23 [W] So Have a scheduling capability. So right now it's possible, please go and check our documentation.
00:39:30 [W] It has us more information.
00:39:34 [W] what is the resource footprint of the litmuschaos so there is still some work going but it is pretty lightweight you can go and configure even the smallest of the CPU and memory you will go and execute
00:39:50 [W] Executing as part of the execution once the test is or the execution is done. The resource will be get back to the kubernative square.
00:39:52 [W] Yeah, so maybe I can also add an answer to an escalation on scale. Some of the community members have reported customization is a need when you go to scale
00:40:08 [W] The strobes feature was built based on the feedback.
00:40:04 [W] There were a few instances where the ability to set up the experiments is good, but I don't know how things should be handled my requirements at scale.
00:40:19 [W] It is the application Behavior varies. So the props were added to that but otherwise experiments at scale because it runs is a kubernative
00:40:31 [W] Ocean and it turns to the deployment you can increase the replicas.
00:40:35 [W] So we we were we were saying this at experiences at scale as well.
00:40:47 [W] This is the portal have an API.
00:40:49 [W] There are two sets of apis one is for the portal itself.
00:40:53 [W] The other one is all configurations or based on mlperf Lon. The portal has some all rest apis. Come on graphql.
00:41:08 [W] It appears the manage that portal functionality. The bottle functionality self is in Alpha the demo flies that are shared or in Alpha mode soon.
00:41:19 [W] soon. They're going to be coming out and I shared the link in one of the questions to the portal you can go to the litmuschaos fo and look for litmuschaos portal directory doesn't take me there.
00:41:36 [W] his reward chaosmesh
00:41:49 [W] Question from David. Yeah.
00:41:52 [W] Yeah, so it is the main reason why we want to reward is that you want to bring flux as well as namespace in the same stage and that is the only reason initially we had some issue where we have to
00:42:07 [W] That makes the best breakfasts that whatever you have set it up you get that thing cleaned up because you really don't want it to hang those resources on the kubernative.
00:42:11 [W] circleci. That's that's that's a reason we are being the real world.
00:42:28 [W] Okay, there is another question.
00:42:30 [W] Would it be possible to trigger other things during a chaos and such as AK bench workloads to take measurement in the middle of chaos.
00:42:40 [W] Yes.
00:42:40 [W] Those are completely tunable. And that's where the work flow comes in right workloads.
00:42:46 [W] Nothing by a sequence of experiments that you can do and you can do them in sequence in serial or in parallel.
00:42:58 [W] if you are aware of the Argo functionality, it's a very that's one of the reasons why litmuschaos shows Argo integrate with for being able to
00:43:13 [W] Things end badly in this case. If you want to do K bench start at a bench and let it run in parallel is start running experiments.
00:43:16 [W] Everything will become one of the workload and it's very easy to do and then at the end of the workflow you can run one one job that
00:43:31 [W] Somebody's is the result and you can upload the results into your own configuration or metrics database and or we can use the built-in Prometheus best
00:43:36 [W] Are my picks database and or we can use the built-in Prometheus best indication of the eight months?
00:43:42 [W] We do have so much fun.
00:43:45 [W] Yeah, just to add to that.
00:43:49 [W] This is the one of the main reason we are using the performance and the chaos engineering together cave and sees another performance to and that will be quickly integrated with the dresser adding a small workloads. You could reverse one of
00:44:04 [W] the our the demo GitHub repository for more information how you can do that and there's another project called distro, which is mainly on on this concept that how we can bring the performance and the chaos testing Hardware.
00:44:20 [W] We also have integrated recently with another project called keptn.
00:44:29 [W] There is call jmeter tests. You run jmeter test and then you run here as well blow. And then you see how exactly it happens. There are many ways you can
00:44:44 [W] Really gives you flexibility and being mlperf Lee things are pretty much flexible and configurable.
00:44:59 [W] All right, so I think again, thank you for attending this session.
00:45:04 [W] Please join us on the slack the litmuschaos community slack is available within the kubernative slack workspace and we are on litmuschaos annal and will be available
00:45:19 [W] But I did some slack workspace and we are on litmuschaos annal and will be available to answer for the questions in the other cncf slack channels as well.
00:45:22 [W] It feels like channels as well.
00:45:23 [W] Thank you. Again.
00:45:25 [W] Thank you, everyone.
