The Cloud Native Journey at Adobe: NMYF-5790 - events@cncf.io - Thursday, November 19, 2020 4:52 PM - 14 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Hello and welcome to this talk about cloudevents a at Adobe.
00:00:04 [W] I'm gonna talk to you about how we use kubernative and other cncf projects.
00:00:17 [W] Hello and welcome to this talk about Claudette. If your knee at Adobe, I'm gonna talk to you about how we use kubernative another cncf projects.
00:00:28 [W] What went well what things didn't work. So hopefully you'll learn some lessons that will help you on your own teams and join me in these in this journey.
00:00:42 [W] So I'm A Cloud engineer at the top experience manager cloud service.
00:00:47 [W] This is a product that will give more details that part of the dhobi portfolio and and have a background on open source. I wrote started a
00:01:02 [W] Background on open source. I wrote started the junkies kubernative plugin, and I contributed at Jenkins X Apache Maven for many years Eclipse Foundation Etc.
00:01:18 [W] It's a lot on the on the open source community.
00:01:20 [W] So Adobe experience manager what it what it is so we can understand better.
00:01:27 [W] What are the challenges we have to go through?
00:01:30 [W] So this applies to my team inside this Adobe experience manager cloud service that we started announcing at the beginning of this year, but there's other teams at in am
00:01:45 [W] Are there so many teams in Adobe a lot of them using kubernative stew. So this just so you know applies to my team other experienced manager is a Content management system digital Asset
00:01:59 [W] Roger man forms and it's used by many Fortune 100 companies companies you you already know are already customers of adobe experience manager.
00:02:12 [W] And now we are providing this cloud service.
00:02:15 [W] It's an assistant distributed job application.
00:02:18 [W] You have author instances where authors can create content published instances where visitors can see that content that was created and this can all is scale horizontally.
00:02:31 [W] So this already existed before the move to kubernative.
00:02:35 [W] This has been already around for years.
00:02:39 [W] The stock is using the Java with osgi and a lot of Open Source components from the Apache software Foundation.
00:02:48 [W] There's a huge market for extension developers that right modules that run on am in process.
00:02:57 [W] And I'll go through why this is important to understand later on the challenge for us was to run other experienced manager on kubernative.
00:03:08 [W] So getting into it we are running on a sure we have more than ten clusters and we keep having clusters multiple regions us Europe Australia and more coming and
00:03:23 [W] We have at Adobe a dedicated team managing clusters for multiple products.
00:03:27 [W] So it's not that we don't create clusters ourselves.
00:03:30 [W] There's another team that takes care of that.
00:03:35 [W] I am environments some multiply every customer can have multiple am environment that they can Self Serve so they can create environments on their own and for each customer we have at least three
00:03:50 [W] Development Stage production environments. We also have some boxes that are evaluation like environments and all of these is managed by the customer themselves through Club manager, which is a separate services
00:04:02 [W] Thrown its own web UI an API. So customers can have multiple environments that match to multiple communities namespaces.
00:04:11 [W] on the names on the environments the for us the name spaces provide the scope like a network isolation court has permissions we use that kubernative us already and for
00:04:26 [W] Oh, man, we use a lot of in it containers South Korea containers to apply the vision of concerned. So we have said Cal containers that do storageos realizations or we have httpd
00:04:38 [W] The job application or exporting Matrix.
00:04:37 [W] We also use fluent bit to send logs.
00:04:39 [W] And another example is have a javathread dump collection where we gathered the threat Thompson and store them.
00:04:51 [W] So we have several sidecars custom-developed like the thread dump collector The Source initialization.
00:04:59 [W] There are very particular to our use case open source, like flowing beat and some that we extend it from from open source like httpd.
00:05:09 [W] And we have to scale these two hundreds of customers thousands of some boxes.
00:05:14 [W] So for us that that's the big it's a big challenge to make sure that this whatever we build Services we built around it.
00:05:23 [W] They will scale.
00:05:26 [W] Some of the issues we face with the scaling you can run unless your APA rate limits, especially in operates.
00:05:36 [W] So we have to limit each cluster to a few hundred nodes. So you could solve this also having bigger notes. So you get high bigger cluster sizes with the same number of nodes and we use the
00:05:51 [W] We have to limit each cluster to a few hundred nodes.
00:05:53 [W] So you could solve this also having bigger notes. So you get higher bigger cluster sizes with the same number of nodes and we use the kubernative vertical and horizontal part of the scale
00:06:09 [W] horizontal part of the scalar extensively
00:06:15 [W] for about the vertical poddisruptionbudgets
00:06:42 [W] One thing you have to be careful with the vertical planetscale are is that changes to the request neat Pottery starts to become effective and make sure that you don't set of EPA to do it automatically because otherwise you would get some
00:06:57 [W] To start and depending on your application that may be a problem.
00:07:04 [W] We also use the horizontal part of the scalar and we set it to scale up on requests per minute. And one thing that you have to be aware of is that you cannot use the same metrics for HPA mvpa.
00:07:18 [W] That's on the documentation of cornetist.
00:07:24 [W] One service we built to manage the scale of the Clusters.
00:07:31 [W] We implemented something that we call hibernation for environment environments that are used by engineering and Son boxes that are suddenly used so we scaled
00:07:46 [W] These environments on this allows us to have a book plasters and unsafe a lot of money by doing that and putting being able to put more resources into into one cluster how this works is
00:07:53 [W] We have a cornetist job that checks Prometheus metrics if there is no activity in the last and number of hours.
00:07:54 [W] with killed a bunch of deployments down to zero.
00:07:58 [W] The customer the user is German message to the hibernate by clicking a button and that's that's all there is to it. And in this this allows us to scale the Clusters and get more packing
00:08:13 [W] Ideally, we will just the hibernate how to matically right on a new request like functions of service cane knative these sorts of things. But you have to account that jvms in this product it
00:08:27 [W] Five minutes for Star depending on how much content you have how many things you have on the store?
00:08:29 [W] But unless you use new jvm microframeworks the jvm. If you are taking a existing application, it's probably going to take a good amount of time to start.
00:08:46 [W] Networking. We we use the networking capabilities from kubernative, which is it's a bit complex and we have to account for multi-tenancy.
00:09:00 [W] We are running multiple customers on the same cluster.
00:09:04 [W] So we limit things Services cannot connect to other services in other namespaces and we block everything by default and we open
00:09:16 [W] Specific cases as needed. So we start from a fully blocked and then open up in as needed.
00:09:25 [W] Everything is virtual kubernative are networking this allows flexibility, but introduces complexity of course, but this is managed by kubernative and we
00:09:40 [W] But overall it works it can work pretty well.
00:09:44 [W] We use psyllium for networking and uses EPF instead of iptables is more efficient and performant and allows us to have custom Network policies at level 7.
00:09:58 [W] So things like policy some path HTTP headers HTTP methods. So it's a it's a higher level API that allows us to Define more
00:10:13 [W] restraints
00:10:04 [W] we use their Network policy object to block or allow traffic.
00:10:09 [W] We block access to all the other namespaces and we just allow someone to cut going HTTP and common parts customers may also want to allow a specific things like Iris IPS.
00:10:23 [W] say we have a you have a development environment and it can only be accessed by your IP range of your private Network.
00:10:34 [W] So we can we can do that, too.
00:10:40 [W] For Ingress we using our Contour Fork the has more features and also has more features that did standard kubernative singer subject.
00:10:51 [W] So we use block list allow lace path based routing stuff like that and it uses them void behind the scenes. So we use we heavily used and boy
00:11:05 [W] I'm voice.
00:11:06 [W] It's something that is like a kind of love hate relationship where you can do things.
00:11:15 [W] It can break be many different ways and you can Brave badly.
00:11:20 [W] Raishin, you update your configuration and is wrong and then you restart Envoy. It will clear all them wear out. So you get a cluster wide outage and we have issues when the rate of change is too high when it
00:11:30 [W] locked on and things just Crystal start crawling back crawling down, but it's very very powerful and we had to do some work to fix issues and
00:11:41 [W] Play and things that we will for instance now is validation of all the conflicts both that build time and runtime.
00:11:44 [W] So this is to prevent causing any any problems as I said, it's very powerful.
00:11:52 [W] if you do something wrong, it's being used everywhere and can cause a cluster wipe outage.
00:12:02 [W] For logging we use fluent bit sidecars that sends logs to centralize the store. We also use graph on a lucky for for love aggregation and for monitoring and alerting
00:12:17 [W] For logging we use fluent bit sidecars that sends logs to centralize the store. We also use graph on a lucky for for love aggregation and for monitoring and alerting
00:12:41 [W] Nephew's graph on and then we are agait all the Clusters data and we have alerts coming from alert manager.
00:12:50 [W] So that's very typical stock.
00:12:53 [W] We have a feature that is the customer login.
00:12:57 [W] So customers can also need access to some of these locks and we use fluent be to send the locks to either log stash and recently lucky and the customer can see them on this.
00:13:11 [W] Cloud manager UI and get those laws and see what whatever it's in the Lovesong broth from the application or their custom code.
00:13:23 [W] lobsters, for instance we are moving away from it because it's a jvm heavy and it uses a lot of memory and we're thinking that lucky lucky is a better option
00:13:38 [W] of these multi-tenant services
00:13:43 [W] resiliency and self-healing some things that you have to have be aware of so you have to have Readiness lightness probes.
00:13:54 [W] Make sure that your services are unaware armor can available if there's any problem and that the average started automatically.
