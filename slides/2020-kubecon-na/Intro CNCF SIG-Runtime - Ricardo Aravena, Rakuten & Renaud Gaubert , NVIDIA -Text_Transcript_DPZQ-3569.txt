Intro: CNCF SIG-Runtime: DPZQ-3569 - events@cncf.io - Thursday, November 19, 2020 3:47 PM - 36 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Hi everyone.
00:00:01 [W] I'm excited to be here at UConn North America.
00:00:06 [W] In today, we're going to tell you about.
00:00:09 [W] Up, you can learn about the sick and maybe you get excited about contributing to the Sig or also contributing to one of the projects in the Sig.
00:00:25 [W] so our Charter
00:00:27 [W] so sick runtime.
00:00:31 [W] Is there to enable the successful and widespread execution for all kinds of workloads and that includes any latency sensitive type of workload or any type of batch workloads?
00:01:01 [W] We have to Toc Liaisons cncf Toc currently. We also have three chairs and also a tech lead. Our meetings are every first and third Thursday of every month
00:01:17 [W] To be used or fpgas and all of them with cloud data of environments in mind.
00:01:11 [W] We have to Toc Liaisons cncf Toc currently, we also have three chairs and also a tech lead. Our meetings are every first and third Thursday of every month
00:01:39 [W] Eight a m-- pacific time. Our communication channels are the email list. And also we have a slack Channel.
00:01:52 [W] So what is it?
00:01:54 [W] So sick runtime is at the Forefront of the cloud native space.
00:02:00 [W] So we want to reach out to new and exciting projects within this runtime scope.
00:02:08 [W] I want to have helped increase that contribution to those projects and also contributions to the cncf.
00:02:16 [W] And we also want to support some of those existing projects or other projects help navigate that cncf Universe there.
00:02:26 [W] There are many projects in the cncf and they can be quite confusing about which projects are needed for what or what the capabilities are for each one of these projects.
00:02:38 [W] We also interact with other relevant 6, so we interact with six that are in different technology spaces like sick absorbability or seccomp delivery or other six like Sig
00:02:53 [W] Many projects in the cncf and they can be quite confusing about which projects are needed for what or what the capabilities are for each one of these projects.
00:03:05 [W] We also interact with other relevant 6, so we interact with six that are in different technology spaces like six observability or sick AB delivery or other six like Sig
00:03:37 [W] Energy, which helps projects set up a framework on how to grow and how to become more popular and get more contributions.
00:03:50 [W] Another one of our goals is to educate and users and also educate the community on the projects on the Technologies and some of the other six and also the cncf
00:04:06 [W] So in the scope of the Sig we have several projects. Some of them are in different stages in the cncf.
00:04:13 [W] Some of them are not even in the cncf. Here are some examples of these projects for example, containerd e or cry or four runtimes or k3s and kubernative for workloads orchestration, or you have kubenetes.
00:04:36 [W] So we also have different areas with where these projects actually fitting. You have the general workloads stration area and kubernative k3s volcano or in this area.
00:04:50 [W] They allowed to run workloads and cloudevents.
00:04:54 [W] Eames rbms type of projects and in this scope and this area we have runtimes like cryo or containerd E.
00:05:03 [W] We also have things like webassembly in this example. We have wasm 3, which is a runtime or Wa-Wa SEC which is webassembly secure capabilities connector, and we also have
00:05:18 [W] Three projects like Harbor another space is the operating systems for containers and two examples of these are flat car and Talos.
00:05:18 [W] Very lightweight operating systems that are meant to be just for running containers.
00:05:24 [W] Then the sick is also interested in projects or has an interest in the MLS edge and a I type of space.
00:05:32 [W] There are also some projects that are in that area.
00:05:37 [W] For example seldom cord that allows you to serve your machine learning models.
00:05:41 [W] We have a cube Edge, which is currently an incubation in the cncf and we have something like f*** flow which is similar to kubeedge the large to run workloads at the edge.
00:05:56 [W] And then we're also interested in workers with currently only have one workgroup and as we get more contributors, we would like to have more but our current work group is the container orchestrated device work group, and
00:06:11 [W] Well, which is similar to kubeedge the last to run workloads at the edge.
00:06:14 [W] And then we're also interested in work groups.
00:06:16 [W] We currently only have one workgroup and
00:06:20 [W] As we get more contributors, we would like to have more but our current work group is the container orchestrated device work group and we're now we'll talk about this in the presentation.
00:06:35 [W] So in the general workloads stration area, we have a few projects.
00:06:41 [W] So one of the projects is volcano currently in sandbox, and this project allows you to run kubernative knative badge workloads.
00:06:51 [W] You can run different kinds of workloads with scheduling mechanisms.
00:06:58 [W] For example, a program provides gang scheduling it helps you with tensorflow training.
00:07:03 [W] It has custom resource definitions and kubernative that allows you to substitute the standard job mechanism and kubermatic with its own job mechanism that is richer and has more capabilities.
00:07:16 [W] You can also use this project to run batch type of processing using specialized Hardware like gpus or fpgas.
00:07:26 [W] And also helps you to handle some of the errors for some of these batch workloads currently. This project is in sandbox.
00:07:37 [W] Another interesting project.
00:07:38 [W] It's kada and that's kubernative event-driven auto-scaling.
00:07:44 [W] And this project allows to allows you to Auto scale your pots or containers and resources say in your kubernative cluster.
00:07:54 [W] You can also use this project to run batch type of processing using specialized Hardware like gpus or fpgas.
00:08:04 [W] And also helps you to handle some of the errors for some of these batch workloads currently. This project is in sandbox.
00:08:15 [W] Another interesting project.
00:08:16 [W] It's kada and that's kubernative event-driven auto-scaling.
00:08:22 [W] And this project allows to allows you to Auto scale your pots or containers and resources say in your kubernative cluster based on events, and these events can be anything
00:09:04 [W] Ryder service like a NATO BS Q mechanism or a cough that cue that it triggers some events for some topics, or maybe you have a database trigger
00:09:20 [W] Database trigger that there's some data actually gets stored in the database or some lesser charge gets passed to a database.
00:09:28 [W] database. So multiple events can be actually seen and then you can also scale your kubernative.
00:09:39 [W] cluster or kubernative spots based on these events
00:09:43 [W] Typically, it helps to scale function parts. So it actually works in that serverless space.
00:09:51 [W] It is vendor agnostic and supports multiple. Crab Cloud providers and plugins.
00:10:00 [W] Another project that is currently in sandbox in the cncf is metal cube that I owe.
00:10:07 [W] Essentially this project allows you to provision bare metal machines.
00:10:12 [W] And your cloud provider like Amazon where you may have bare metal machines.
00:10:16 [W] We're just your data center or your Cola where you have your own machines, it makes use of kubernative itself to provision this machines.
00:10:28 [W] Would you send the cluster API another kubernative project?
00:10:32 [W] It allows you to provision all these notes.
00:10:35 [W] It could be kubernative notes running on bare metal.
00:10:40 [W] So it allows you to provision the components like the kublr head and everything that you need to run in a kubernative snowed.
00:10:48 [W] Presented in the SEC is no resource interface.
00:10:53 [W] This project allows you to manage resources in kubernative nodes.
00:11:00 [W] It's an interface from manage these resources and what are these resources when you talk about containerless will resources you talk about CPU slices or memory slices or even devices on this nodes.
00:11:15 [W] Underway to manage some of these resources and targeted, you know for things like kubernative.
00:10:58 [W] It actually Builds on what the container network interface has so the container network interface or cni-genie.
00:11:16 [W] It's a containerd e sub project and it's still in the works.
00:11:19 [W] So a lot of stuff going on. This was started by folks working at Apple right now, and I think it's just early but it will soon will soon have more developments.
00:11:36 [W] So in the runtime and BMS and container space there are some other projects so you have Harbor which graduated a few months ago. It's a container in which registry and
00:11:50 [W] Just not a regular a regular container registry which is the single process.
00:11:55 [W] It's a multi fault-tolerant container registry where it allows you to store your metadata in a Chase system high availability systems and allows you to have a cash in system with redis. It also allows
00:12:10 [W] container image registry and
00:12:09 [W] Just not a regular a regular container registry which is the single process.
00:12:14 [W] It's a multi fault-tolerant container registry where it allows you to store your metadata in a Chase system high availability systems and allows you to have a caching system with red ass it also
00:12:41 [W] Or and multiple nodes using physical volumes. So it allows you to set your container registry behind a load balancer.
00:12:52 [W] So full-scale container registry.
00:12:57 [W] Currently in graduation or graduated so interesting project. It's very mature project now.
00:13:05 [W] Another interesting project that presented in our meeting, it's Lapine and this is not operating system or a colonel or a mini Colonel.
00:13:17 [W] would say that it sits between what you know Colonel is an irregular kernel or a regular Linux kernel is
00:13:27 [W] So the idea behind unit kernels is that you package everything together with your application your system calls your Colonel everything together and you just run it and that can be very costly in terms of the tooling and and
00:13:42 [W] Out there.
00:13:43 [W] So this project it's a different take on that where it actually strips down a regular Linux kernel and it makes a really lightweight and so when you run it actually doesn't take a lot of time to boot up
00:13:58 [W] Time it's compatible with the most important or the most popular types of workloads, like databases like run times four languages so you can run most of your workloads and you don't need to
00:14:02 [W] And at the same is very lightweight.
00:14:03 [W] As opposed to a regular Colonel regular Clinic can just run everything you will have some limitations here.
00:14:09 [W] again, you're trying to address more of the more popular applications that you may run.
00:14:17 [W] This is targeted more towards serverless type of workloads where you maybe want to instantiate a VM with a very lightweight kernel just to run a function.
00:14:28 [W] So Cloud providers has some of these with something like firecracker, but it but they don't necessarily have something like Lapine.
00:14:34 [W] that is a very lightweight Colonel that allows you to run for example, like an AWS Lambda function very quickly or not.
00:14:44 [W] just one but like many many of them at the same time and instantiate in them and then turn them down.
00:14:54 [W] So another interesting project that presented is w a s CC which is webassembly secure capabilities connector.
00:15:06 [W] And there's been a lot of Buzz about webassembly and how that's actually going to be used to run Cloud native environments in the future.
00:15:14 [W] And the reason for that is that webassembly is a very transferable format.
00:15:22 [W] Systems provided there's a runtime.
00:15:23 [W] So it's just like a binary cuddle like you have a Java binary that is interchangeable between what you can run on the web and then you can also run on just regular systems.
00:15:36 [W] So this project allows you to connect.
00:15:39 [W] All of these webassembly modules that you may have but each one of them having very unique capabilities that are very granular.
00:15:49 [W] So you may have just a module that talks directly to your database, but you may also have a module that implements your business logic.
00:15:59 [W] So you can couple this these webassembly modules together with something like waa waa sec.
00:16:08 [W] And these are just an example of to webassembly modules, but you may want to actually connect hundreds of these these different webassembly modules in Cloud native environments.
00:16:20 [W] So the idea here is to facilitate the connection between these modules and allow you to run a full blown Cloud native application on a full or a full set of multiple microservices.
00:16:35 [W] The other scope that the Sig especially having presentations for is the operating systems for containers space.
00:16:44 [W] Writing system that is very lightweight and it's just meant to run containers.
00:16:38 [W] It's minimal. It's immutable it allows you only to interact with it using just regular API is not just you know by ssh in or doing an SSH connection to the operating system, but this external
00:16:53 [W] Not just you know by ssh in or doing an SSH connection to the operating system, but this external way of interacting just using apis.
00:16:51 [W] And then philosophy here is that you have more security. We have more control of what can happen inside that operating system in you can do things like empty LS Mutual Authentication.
00:17:02 [W] you reduce unknown factors with immutable infrastructure.
00:17:09 [W] So the idea is to simplify your infrastructure to run containers.
00:17:16 [W] Another project is the presenter is flat car.
00:17:20 [W] In flat car is an evolution of chorus chorus chorus just reached the end of life. And this is a continuation or chorus would more capabilities.
00:17:33 [W] They've actually
00:17:35 [W] gotten a lot of adoption just because korres also reached an alive and they're not necessarily an API based operating system. But the idea is the same behind coredns that you want to
00:17:51 [W] Just reached the end of life and this is a continuation or chorus would more capabilities.
00:17:59 [W] they've actually
00:18:02 [W] Gotten a lot of adoption just because korres also reached an alive and they're not necessarily an API base operating system. But the idea is the same behind course that you want to
00:18:35 [W] 8 operating system just for running containers and you reduce your attack Surface by having less components and just having the components necessary for running. Your container images clearly is getting a lot of
00:18:50 [W] Popularity and it keeps on growing.
00:18:55 [W] The other space where the sick actually has had presentations is The Edge machine learning or mlsp Ace or AI or artificial intelligent type intelligence type workloads.
00:19:09 [W] For that we have a project that is actually an incubation.
00:19:12 [W] It's called Cube H + Q qh allows you to run workloads at the edge, but also managed to a centralized location using kubernative.
00:19:25 [W] So everything runs on top of kublr Daddy's you have this Cloud Core component the central to Burnett its location and then you have the edge core component running at the edge where you cubelet runs where you actually
00:19:39 [W] Run your your workloads and that edge component also talks to all these different devices that may be gathering information at the edge.
00:19:48 [W] You may have transmitters sensors cameras through tooth devices anything that may be actually got their Gathering data at the edge.
00:20:01 [W] So the core another project not in the cncf per se but they had a presentation in our meeting and they allowed you to serve machine learning models using either a rest API.
00:20:16 [W] Stephanie be gathering information at the edge you may have transmitters sensors cameras new tooth devices anything that may be actually got their Gathering data at the edge.
00:20:30 [W] some of the core another project not in the cncf per se but they had a presentation in our meeting and they allow you to serve machine learning models using either a rest API
00:21:05 [W] grpc API
00:21:07 [W] So you will build your model model with some kind of tool.
00:21:11 [W] They also have another tool themselves to build it or you could use something like kubeflow. And then once you build that model you need to serve it and that serving means creating that inference graph of inference on the fly.
00:21:26 [W] To serve it and that serving means creating the inference graph of inference on the fly.
00:21:33 [W] It supports this very simple inference graph, but it also supports it is very complex in France graphql.
00:21:39 [W] You have this really complex machine learning modules.
00:21:44 [W] entrance interesting project
00:21:48 [W] We have also some other projects coming up with that are presented in that. We actually reached out to so we have wasn't 3 which is a webassembly runtime. We have Frau which is a container image
00:22:04 [W] registry we have kubeflow for running the whole pipeline of machine learning type of workloads bearing that allows you to run Raspberry Pi type of workloads at the edge at the edge
00:22:19 [W] it allows you to run Raspberry Pi type of workloads at the edge at the edge using a I reach out maybe to Cloud kernels, which is a
00:22:30 [W] team working on different Cloud kernel so minimizing Colonel type of projects.
00:22:36 [W] And crosslet it's another project from Microsoft that helps you run webassembly modules on kubernative.
00:22:45 [W] So it allows you to substitute that Cube length with webassembly module and then that could talk to kubernative.
00:22:52 [W] So be managed by kubernative.
00:22:55 [W] So lots of interesting stuff and I think that's about it is that I have for the sick itself and now I'll hand it off to Renault and he will talk about the
00:23:10 [W] Workgroup.
00:23:11 [W] thank you Ricardo.
00:23:12 [W] Let's talk about the container orchestrated device.
00:23:15 [W] where poop or Cod work group.
00:23:18 [W] We are a small group of device vendors containerd runtime maintainers and contributors as well as Community sick members. The problems that we're trying to solve is related to the fact that we've seen an exponential usage of devices in the past five years
00:23:34 [W] Bi machine learning deep learning to network data plane or encryption/decryption acceleration devices such as fpgas.
00:23:38 [W] gpus. Nick's or even is X have become quite ubiquitous in the data center.
00:23:44 [W] And so the chart of the word group is really to enable device support across the cognitive space what that means is that we're trying to enable these new workloads who are trying to make it so that you as a user or a cluster administrator.
00:23:58 [W] A production experience and being as users as well as vendors and Custer administrators. We have a feel for what the problems are.
00:24:11 [W] And so we've actually set up a road map that is kind of layered so that you can build on top of each brick the first problem that we're trying to solve really is the ability to actually expose a device to containerd tone. And the reason we're
00:24:26 [W] Problem first is that the space is very fragmented kubenetes has a concept of device plug in well known that has its own concept of device coredns, very different doctor has a concept of Entry plug-in mechanism while pain man has a
00:24:37 [W] Concept of Entry plugin mechanism while conman has a concept Hooks and Alex. He has even its own concept of hooks.
00:24:37 [W] And all these different or all these differences across the space makes it very difficult for vendors to provide a uniform experience for users across these different projects and that makes it very difficult
00:24:52 [W] Features or the same features across these projects meaning that some projects have different capabilities than others.
00:24:59 [W] And so the next problem that you want to solve or that we want to be able to solve is that when you are offering computer a task to the device one of the main reason you're doing that is speed and choosing the right CPU choosing the right
00:25:14 [W] Mitch we're choosing the right device is very important. If you have the wrong CPU in the wrong device, it can sometimes destroy your performance and nullify the effect of actually offloading the computer to another device.
00:25:26 [W] Let's problem when you are in a Data Center and you have for example tasks that need to be spread across multiple nodes test and need to talk to each other most of the time you won't these nodes to be close to each other
00:25:41 [W] Example in the same Rex and so figuring out where the right knobs one of the right policies where the right extension points is very important. It's a hard problem, but it's a very excited.
00:25:50 [W] And so the first problem that we've tackled as mentioned on our roadmap is really the ability to expose a device to container and our answer to that is ci/cd container or the containerd device interface.
00:26:03 [W] It's a unified plug-in architecture for rent times its space on cni-genie container network interface and it basically tells the runtime what are the devices that are available in the note and where are the operations that the runtime
00:26:18 [W] To expose that device so here on this slide what you can see is that we have one device vendor vendor a.com slash device or one device kind and it exposes one single device my device
00:26:30 [W] Ice in the operation that must be performed here is to expose to device known and / death and so from a user perspective what this really means is that instead of typing my container Run - device
00:26:37 [W] What this really means is that instead of typing my continual Run - device stuff like card and that's just of I still have my card. Wonder what you'll be typing is really just Docker or my cat a
00:26:52 [W] Are my cat a runtime Run - device my device and then my image and my ceiling command.
00:27:03 [W] From a roadmap perspective.
00:27:06 [W] What were we we've created this roadmap to give you a feel for where we are and where we're going.
00:27:11 [W] We are still in the stage 0 we are building pocs.
00:27:18 [W] We have to pee Oh see so many containerd e we are still building these foremost spec whether in go and in writing and we are talking about the idea with different people what we're hoping to achieve probably and hopefully by the end of
00:27:32 [W] your is the integration and run times maybe as an alpha future is the ability or the kubernative kept and the intersection or talking about CDI and how it can enable other powerful
00:27:48 [W] working or storage
00:27:50 [W] and the direction that we're going really is integration with as many runtimes and having multiple plugins built on top of us.
00:27:59 [W] And so we've decided to plant it for a 100 flag saying that this this will be stable.
00:28:05 [W] This will be 100 as an API, when we have to run times. They're using it when we have more than three plugins and when we are better kubenetes giving a feeling for users that this is a feature that is actually going
00:28:20 [W] In a direction, that is Doctrine.
00:28:24 [W] And so let's see I but don't let CD and I discourage you the cardboard roof still has a ton of huge IDs and exciting ideas that haven't been thought through completely and we'd be super happy
00:28:39 [W] Tributes just have a different opinion in a different view of how these ideas should be addressed.
00:28:36 [W] We'd be also super happy. If you want to give us some feedback what we've built and if you think that there's an intersection with your ID, we'd be happy to hear from you if you want to filter traits or build on top of CEO. I
00:28:52 [W] It is feel free to just drop by and we'd be happy to hear from you.
00:28:42 [W] And that's it.
00:28:44 [W] That was this a runtime presentation.
00:28:46 [W] Go on cncf Dy o to see same runtimes description.
00:28:53 [W] You can join the slack. You can also look up the GitHub that has a lot of information and we have bi-weekly meetings on Thursdays.
00:29:02 [W] Feel free to join the segment.
00:29:03 [W] I my weekly meetings join our community.
00:29:06 [W] Unity and give us some feedback. Thanks a lot.
00:29:15 [W] Okay seems like we have one question.
00:29:21 [W] I'll read it out and I think it's for you or not.
00:29:26 [W] So so any reason Caesar is asking any thoughts on how a single device that can support multiple contexts can be shared among containers where each container
00:29:41 [W] He's cold.
00:29:38 [W] So the thoughts that turn the thoughts that we've had for devices and especially shared devices has been that pretty much each device has its concept of sharing.
00:29:53 [W] Has been that pretty much each device has its concept of sharing and so trying to bring up maybe a concept of granularity or a concept.
00:30:00 [W] or a concept of percentage usage is kind of always tricky because it doesn't mean the same thing for a GPU and Nvidia GPU or an fpga
00:30:15 [W] Direction that we've been thinking through has been mostly that poor sharing devices.
00:30:22 [W] We would expose that device to multiple containers at least for example, if you're at the node level the ability for a container one time to manage the device would not be present.
00:30:37 [W] Where you would say is I want multiple containers to have access to a specific device.
00:30:42 [W] And then your you as a vendor would have a plug-in that will allow you to specify where interact with the user in such a way that for example here is talking about context
00:30:57 [W] Text would be assigned to specific experiment place for orchestration.
00:30:57 [W] It becomes a bit more becomes even more tricky and there's a lot of ideas that are being thrown around just because for example in kubernative use today devices are numbers. It's easier as a first step to
00:31:13 [W] It as an integral and so we fractional device but as I've mentioned it really depends on the device and so that ID that effort hasn't been pursued
00:31:26 [W] It's because because of that because of that significant problem.
00:31:31 [W] I hope that answers the question.
00:31:35 [W] So in the meantime if there are other questions we'd be and if we'd be happy to answer them, but we do have some prepared question that I'm happy to ask Ricardo the first one being
00:31:50 [W] Bit about the graduation for a a graduation process that you went through.
00:31:58 [W] Yeah, so
00:32:02 [W] I've actually had the chance to go through the graduation process for Harbor.
00:32:10 [W] So basically when a project in the cncf goes into incubation, there is a Toc member that
00:32:27 [W] Like step project or it's very interested in that project and that person becomes the sponsor for that project.
00:32:38 [W] And once that happens the sponsor works with the project maintainers in creating a due diligence document and that contains lots of information about the project like
00:32:54 [W] Jupiter's whether it's being used in different environments or whether the project is continuing growth so many different aspects of the project
00:33:02 [W] That diligence due diligence is done. Then that's for incubation that goes into this the TOC for a vote and basically the TOC
00:33:08 [W] To include it in the incubation stage by doing a majority vote.
00:33:10 [W] I think about 70 or 75% of the TOC vote.
00:33:15 [W] So once the project was a project is incubation, then the next step is graduation and and in and that's more about adoption of the project
00:33:30 [W] How many users are actually using the project in say production environments and there's a set of specific requirements that are listed on the TOC GitHub repo, you know
00:33:43 [W] Certifications you actually have this stats that stats that are certain numbers. And so once you've reached that stage then then your TLC sponsor
00:33:56 [W] Containers and talk to the TOC sponsor and they decide.
00:33:59 [W] okay, we want to go for graduation and we want to use the due diligence document as a framework to become part of the graduation.
00:34:09 [W] So what the TOC sponsor does it it reviews that due diligence again and make sure that there's additional steps that are you know needed for graduation and verifies that those steps are there.
00:34:24 [W] So that it may involve talking to some of the users of the project. So some of the end user and user other projects of the project.
00:34:34 [W] So once that's verified then the TOC does something about creating a public comment period of two weeks and then one it and people talk about the
00:34:49 [W] I think it's good.
00:34:49 [W] If I don't think it she'll graduate or maybe they actually boys are opposition. And then once that period is done and it's determined that the project is good for graduation. I'm giving that nothingness
00:35:04 [W] Then it goes for a Toc vote again and and the TOC votes, you know, 70 or 75 percent of the vote in Project goes into graduation.
00:35:09 [W] So that's the whole step and the whole process of graduation.
00:35:15 [W] Yeah.
00:35:17 [W] that answers the question.
00:35:22 [W] All right, I think.
00:35:25 [W] Thank you very much.
00:35:26 [W] I think I've answered a question in the chat. Also, the last question that was asked if I think that's pretty much it.
00:35:37 [W] This is the end of the session.
00:35:40 [W] Thank you. Everyone for joining recorded. You want to say closing word?
00:35:45 [W] Yeah. Thank you very much for joining in the few want to chat more would be happy to chat on the slack on the maintainer track or
00:35:55 [W] on the cncf slack
00:35:58 [W] and feel free to join our meetings.
00:36:00 [W] you everyone.
00:36:02 [W] Bye.
