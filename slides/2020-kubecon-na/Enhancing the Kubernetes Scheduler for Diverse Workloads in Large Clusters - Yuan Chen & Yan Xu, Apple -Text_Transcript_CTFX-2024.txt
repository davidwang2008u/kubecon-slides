Enhancing the Kubernetes Scheduler for Diverse Workloads in Large Clusters: CTFX-2024 - events@cncf.io - Thursday, November 19, 2020 3:47 PM - 28 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Good morning.
00:00:00 [W] Good afternoon.
00:00:01 [W] Good evening.
00:00:02 [W] I'm Yuan Chen from Apple Cloud infrastructure team today.
00:00:07 [W] and many collaborators of from Upstream community
00:00:13 [W] This is that you end of my talk.
00:00:15 [W] I like to start with an introduction.
00:00:17 [W] why we need to extend and enhance the existing kubernative schedulers.
00:00:24 [W] Now, I'm going to discuss and present a few use cases how to use the scheduling framework to develop new features to support state for applications batch jobs and improve scheduling.
00:00:40 [W] Nagi clusters then conclude my talks with a summary.
00:00:38 [W] Why is knative kubernative schedule is not good enough?
00:00:44 [W] Let's look at the history kubernative scheduler was designed to many support state of these applications.
00:00:52 [W] It used a port by ports are dueling strategy and apply some simple scheduling logic also.
00:01:02 [W] It's a scheduling decision is based on some optimal strategy. It means it choose the nodes scoring the nodes and choose the best of those two.
00:01:14 [W] Be assigned to a port.
00:01:16 [W] But if we look at this workloads, there are many more other workloads, like stateful application specialist machine learning deep learning and HPC applications start to run in kubernative clusters.
00:01:32 [W] They to some extent require Advanced scheduling is from gain scheduling topology awareness Advanced have been packing also the kubernative cluster size are increasing very fast.
00:01:47 [W] Today we have seen thousands. Those are clusters Consultants of nodes and clusters. The performance is very important also as the we're on more diverse workloads in kubernative clusters
00:01:59 [W] Also as the we draw more diverse workloads in kubernative clusters in a multi-tenant environment a single scheduler policy or strategy cannot meet the
00:01:52 [W] Cinco scheduler policy or strategy cannot meet the different requirements one size does not feed more.
00:02:01 [W] We need to support more customizable policy and algorithms for different workload you so here just a partial list of the new schedule new features
00:02:17 [W] Any features that we see very important to support today's workload in kubernative clusters?
00:02:30 [W] Firstly I'd like to so how do we end develops a new schedule the features.
00:02:37 [W] I'd like to give a quick overview introduction of the schedule of framework which provide a very powerful and uniform mechanism that enable us to write custom logic
00:02:52 [W] And enhance the existing schedule of scheduling logical and workflow.
00:02:59 [W] So if you look at the flow here from a poor submission to a port finally.
00:03:10 [W] Place or assigned on a node it has to go through a many steps or stages. So the schedule framework provide an API for each of these and
00:03:25 [W] four stages so the scheduling framework provide an API for each of these and extension point before and after each of the stage, for example before the filter stage, which basically is
00:03:33 [W] Or the field of stage which basically is finding a feasible nodes that can wrong a nodes or the scoring stage and gave a score to a node and rank all these nodes to choose the best nodes.
00:03:50 [W] So the schedule of framework provided this API in we can leverage this and use this and the mechanism to create and many different kind of the scheduling new features
00:04:05 [W] We can leverage this and use this in a mechanism to create and many different kind of the scheduling new features and a custom skeleton and logic.
00:04:18 [W] Compared to existing approach to extend and develop and the new scheduling policy or algorithm. The schedule framework is highly extensible and customizable because it the plug-in is
00:04:34 [W] Sable and a customizable because it the plugging is part of the scheduling free the knative and the schedulers.
00:04:43 [W] So we have only a single schedulers and can use this and the cash and error handling.
00:04:49 [W] So it's provide a much better performance and better and a handle and arrows find that it because it's right as a single schedulers.
00:04:59 [W] So no conflicts or risk condition that is in current.
00:05:03 [W] in multi schedules
00:05:07 [W] here is a summary of compared to existing or old way and to extend the
00:05:18 [W] kubectl schedules use just the change in the code.
00:05:21 [W] It's definitely not recommended because it's not compatible cannot turn the very difficult to to incorporate the new features or diversions kubelet. He's or use the scheduler extenders, but the key problems here
00:05:37 [W] It has very limited extension Point basically can only and run extender after the filter stage and also after the scoring stage also, it's right as a separate service or webhook the communication
00:05:52 [W] organizations that are ization very high
00:05:45 [W] The third project is just the wrong and a separate customer schedule an on-site with the knative schedule the problem with this approach is very hard or difficult to coordinate the
00:06:00 [W] Summer schedule an on-site in the knative schedule the problem with this approach is very hard or difficult to coordinate the schedule schedule knative Sation conflicts.
00:06:11 [W] So it will introduce the risk condition so far and it's still and open question how to solve it in our knowledge and skill and the production systems by can trust the
00:06:26 [W] Introduce the risk condition so far and it's still and open question how to solve it in our knowledge and skill and the production systems by can trust the scheduling framework and provide a
00:06:40 [W] Lightweight and Phi granularity extension mechanism. You can customize extend the scheduling flowmill logic or Arizona before and after each stage of rescheduling cycle also
00:06:55 [W] Raw and build into the scheduler binary raw as a single schedule it eliminated the serialization deserialization overhead and can offer much better performance.
00:07:09 [W] So now let's move to look at some of the use cases.
00:07:15 [W] We never use the scheduler framework to develop a new feature to support state of reports batch job and improve the scheduling performance in large clusters.
00:07:28 [W] So first use case is is about
00:07:33 [W] new features to support some state for ports which require a static or fixed IP address this mean
00:07:44 [W] whenever a state for Port is assigned an IP address in huge and have this IP address during its entire life cycle.
00:07:54 [W] This is a not uncommon requirement. We have seen and the in many and and using environments have this requirement neither for the next C and maintain compatibility with next
00:08:10 [W] Was simplify or some application in the logic this will require and some changes to the existing schedule in logic.
00:08:17 [W] So firstly we have to track this IP information and this to you have to know in the which and state for pause already as eyeing on which IP address also depending on how you manage your IP address if it's a static way
00:08:32 [W] And as eyeing a fixed number of IP address to each node, you have to make sure you check this map from the IP address to the node or node to the IP address finally during this and the filter stage of the scheduling and the decision
00:08:33 [W] We have to check make sure and we as eyeing this ported to the right and a node if it's already have IP address or if they are still free or available IP address on a node.
00:08:43 [W] So if we look at how we implement this and using the scheduler framework the simple stir and design implementation here is we have to introduce and the two plugins or extension Point.
00:08:58 [W] Y is for the pre filled during a few free field.
00:09:02 [W] Basically we have to sync up and make sure the scheduler have the right and correct information about IP State as
00:09:12 [W] out as the
00:09:15 [W] IP reservation information the second and he's it have to check and classify a poured into three different category and why is a stateful post new stable pose without
00:09:30 [W] He or existing state for pourcel with IP and a record of ports.
00:09:34 [W] just stay to these ports. Then the next plug-in new plug-in is during the future stage.
00:09:41 [W] The static IP schedule has to do some additional things.
00:09:46 [W] So for regular ports or state for behold, it needs to check whether or not and this node or a Drac have still available free IPS.
00:09:57 [W] The reject the nodes if it doesn't I have any available IPS, but if we sustained for ports, then it have to make sure the advocated IP and the node.
00:10:11 [W] Actually match means if there are some static IP already and assigned to a nodes and the educated IP should be available on this loads.
00:10:23 [W] So on the right side, this is the code segment just to show you how we could implement this static IP stock schedule plugging. This is the example of the filter plugin.
00:10:36 [W] So as you can see, it's quite straightforward and simple.
00:10:40 [W] So compared with the existing project using the scheduler extenders as a web hook the scheduling framework plugging provide a much simplified implementations also because
00:10:56 [W] As a bike with a plug-in without managing the the event cash in the self and a much easier handle errors.
00:10:55 [W] So it's much more robust and stable and also easier to maintain and manage.
00:11:02 [W] Finally without running as a separate component without the marshaling dimensioning overhead. The performance can be improved significantly.
00:11:13 [W] So here is some Benchmark performance result.
00:11:19 [W] I'll top is the webhook implementation the percentage of the time spent on the predicate logic extender.
00:11:32 [W] It's man's that as the percentage and over the entire schedule narrow Chasm and time.
00:11:38 [W] It's almost up to 50% by can trust the field plug-in only take up to four percent of the scheduling algorithm material ratios. So it's a
00:11:52 [W] very and significant performance Improvement
00:11:59 [W] next and I'm going to discuss or share a new schedule in features to support a defense against scheduling's for batch jobs so many and the batch jobs and
00:12:14 [W] And workloads spok motion Anning deep learning require can scheduling which means David a group of the pores scheduling all of them or none of them.
00:12:12 [W] So far because the existing knative scheduled only supported this prototype old group. It's missing these features.
00:12:22 [W] So one of the solution we already have in our community is a might wait coschedule plugin.
00:12:31 [W] It was a regional proposed by Ali Baba ting tang walla and it's called egos during announced a few months and we have been working very closely with the communities to improve the enhanced this code scheduling
00:12:47 [W] supporter can schedule for batch jobs
00:12:36 [W] We have the collaborators from Ali Baba Apple IBM Ten Cent and many others. So the idea is
00:12:46 [W] it introduces two labels the first Naval and just the Define a group you name it and like my PA exam my batch jobs, the second neighbors described and specifies how many
00:13:01 [W] an able and it just the Define a group you name it and like my PA exam by batch jobs, the second neighbors described and specifies how many what's the minimum number of the port should be scheduled
00:13:12 [W] Mamba of the port should be scheduled as a group.
00:13:18 [W] So in order to support this gain scheduling we have to introduce in a multiple extensions at a different stage.
00:13:26 [W] So first thing is for sorting the port's where report submitted to the kubernetes. It has to be sorted your schedule in Q instead of a doing the Prototype old in the Sorting the plug-in make sure
00:13:42 [W] The kubernetes it has to be sorted your schedule in Q instead of a doing the Prototype order in the Sorting the plug-in make sure this the port from the same Groove.
00:13:55 [W] our salty together and avoiding and it interferes with and across the different port group II and the
00:14:07 [W] addition is to check and create her product group managed by the
00:14:14 [W] Co scheduling plug-in, so make sure we have we know which Port be known to which Port group also its verify whether or not and the minimum number of reports in a class can meet the port group
00:14:30 [W] The port group and minimum requirements than can reject and reports earlier to see if the resources the third plug-in is because now we like to support to the port group scheduling and we cannot
00:14:46 [W] After finding a node for it, we have to just a reserve that Port so the reserve clocking also should have a timeout mechanism make sure it won't an occupy an resources forever.
00:15:02 [W] Force blogging is this permit plug-in it's check whether or not the port's belonging to the same group already reached its minimum number of reports to be wrong if it's
00:15:14 [W] Then we allow all these schedule reports move to next stage to The Binding stage.
00:15:17 [W] To basically to start and creating the content and supports to run the systems.
00:15:25 [W] Also, we have to manually sport groups and make sure the deletion of product group clean off the portal group also if they are timeout
00:15:37 [W] We have to clean up the port group as well.
00:15:41 [W] All these parameters can be customizable based on some parameters.
00:15:50 [W] So your summary this and the coast scheduling plug-in provides a simple mechanism to wrong batch yours to as a group support this and gain scheduling requirement
00:16:05 [W] Edge jobs it also supports to defy a product group or cross the jobs and deployment.
00:16:11 [W] And there's some mechanism to make sure the product group can be clean up and winter deleted or time and out. Also have a nice and error check mechanisms.
00:16:23 [W] so here is just an example and police a fire defy or sketching the profile to support the gain scheduling or Co scheduling so here as you can see is we just
00:16:38 [W] Port now again scheduling or Co scheduling so here as you can see is we just studied and a disco schedule plugin for the different stage the sort of stage pre-filter stage permit stage
00:16:36 [W] Test stage permit stage and Reserve stage also we can customize the parameters how to manage unipart group.
00:16:44 [W] For more information, please. Visit the scheduler plug in the repo and also the users we welcome users and also contributors.
00:16:55 [W] so moving forward they are not of the interesting or more advanced features Associated related records scheduling the community and is working very hard to address
00:17:10 [W] Into these issues and a new proposal or PR just try to improve this and label based code scheduling to Port group ci/cd based.
00:17:25 [W] Implementation also we are looking at some more advanced customer promotion. For example, When you pray am to evict a portal from Portal group, should we picked the entire or ports from the same group or
00:17:40 [W] Group that it may violate violating the minimum number of the port's requirement defined in the gang the protocol for definition.
00:17:40 [W] Also, can we improve the utilization? If we don't want to enlarge Port group reserve the resources and block some small Port group from running. So what about introducing the
00:17:55 [W] Strategy and or more advanced rescheduling strategy. Also finally as we can see there are not new requirement on this and the port group based management.
00:17:58 [W] So he introduced a more General.
00:18:02 [W] Generic and sorting plug in 3 and even a single product are for poor group consisting just poured so we can manage the port of Port group.
00:18:17 [W] Uniform we so for more information and you can look at some of the discussion and the issues and the cap the third use case is is scalable scheduling how to
00:18:28 [W] Yes, siree use cases is scalable scheduling how to improve the performance schedule performance at a scale we have seen and many very large skill in clusters
00:18:39 [W] To us.
00:18:41 [W] we have solids of tens of thousands of nodes. Also, there are not of large jobs or Services running in such clusters each have sold in total or tens of thousands of reports.
00:18:54 [W] For some of the real-time interactive workloads and auto-scaling is important to quickly scale the number of the ports for service to handle increasing workloads.
00:19:08 [W] So all these require very good performance schedule, but unfortunately today kubernative knative schedule performance can be limited by its portable port
00:19:24 [W] So all these require very good performance schedule, but unfortunately today kubernative knative schedule performance can be limited by its portable port
00:19:53 [W] Amazon and also the optimal placement strategy in very large skill clusters.
00:20:02 [W] To address that we have make two proposals.
00:20:06 [W] The first one is can we cost my some key scheduling parameters for different workloads or different tenant to better perform balance the scheduling coredns 80 and performance
00:20:21 [W] On it instead of scheduling Port Port by one by one week as I the nodes to a group of poured at a time.
00:20:35 [W] So firstly let's look at customized schedule the parameters.
00:20:40 [W] So one of the key parameters that have a big impact on scheduling performance is called percentage of notes to score which determine how many of the nodes that the scheduler
00:20:55 [W] I mean to those that have a big impact on scheduling performance is called percentage of notes to score.
00:20:58 [W] which determine how many of the nodes that the scheduler should check and scored and ranked them.
00:21:08 [W] So for example, here is a benchmark results experiment. So if we run this experiment in a 2000 node cluster
00:21:20 [W] 5% of this parameter value means will score up to 100 nodes.
00:21:26 [W] So if we find 100 feasible oats, we just stopped search and rank this $100. I choose the best one 100 means we look at up to the entire cluster up to 2,000 notes if we look at the
00:21:42 [W] Up to two thousand nodes, if we look at the results on the left the graphs you and the for very simple strategy the five percent and 100 percent.
00:21:53 [W] They don't have much difference can reach 120 points per second.
00:21:58 [W] the maximum throughput we have seen so far, but for some ports that would require advanced placement constraint like a finiti anti Affinity 5% and
00:22:11 [W] the Tempest 100% Hugh a huge difference almost the 3x difference in terms of scheduling throughput
00:22:22 [W] To address that we proposed a pro profile parameter idea.
00:22:28 [W] So the current this percentage of notes to score is a global parameters. What we proposed is to have a per profile parameters so that we could
00:22:46 [W] To address that we proposed a per profile parameter idea.
00:22:52 [W] So the current Miss percentage of notes to score is a global parameters. What we proposed is to have a per profile parameters so that we could
00:23:23 [W] Friend 2 percentage of the nodes to score two different scheduling profile then different workloads or tenant can assign or use different scheduling profile to better meet their scheduling performance.
00:23:38 [W] They are scheduling performance and scheduling Cod 80.
00:23:45 [W] The second idea The Proposal is to score and assigner notes to poured as a group.
00:23:56 [W] the key idea is we can concede a group of a homogeneous ports with the same resource requirement as a group then we just need to score
00:24:12 [W] Concede a group of a homogeneous ports with the same resource requirement as a group. Then we just need to score the notes was assigned the
00:24:33 [W] I was assigned a top key scoring notes to the port and a tie to implement that we need firstly.
00:24:44 [W] Add a port group sort plug-in which is similar to the coast scheduling plug-in sought to the poor the group together. The second applauding is the group score pluggy, which will
00:24:59 [W] And Pope case Corey nodes to the K ports, but this is still in a design phase.
00:25:06 [W] The Challenger is how can we support this port group as scheduling important? Because the current schedule framework we can customize the scheduling logical?
00:25:22 [W] Before and after each schedule is stage, but it's still impossible to customize the scheduling flowmill logic itself.
00:25:32 [W] For example, can we escape or poured for certain stage with customized some processing logical there?
00:25:41 [W] But this is a very hard problem because we have to
00:25:46 [W] Make a good balance and have good trade-off between the Simplicity robust studies and the performance and Advance the features in the scheduling
00:26:01 [W] and imitation
00:25:59 [W] Okay, so we have and discuss in the three and use cases and how to develop new scheduling feature to support the different use cases. Finally here is example.
00:26:15 [W] Pulled together creat a scheduling profile to use or this schedule new features.
00:26:12 [W] So here we should example policy with the four different profiles. Each profile is associated with different plugins.
00:26:21 [W] They have different names different plug-in. Not only constraint is the qsort.
00:26:28 [W] Plugging should be the same because they're only a single scheduling plug-in that for different.
00:26:36 [W] Profile we can Define different pluggy associate with this and the schedule profile.
00:26:43 [W] So sticky IP scheduling coschedule needy for scheduling or a integrate schedule this one we can use any combining all these three different type of the plugins together
00:26:59 [W] C and we can set different percentage of those to school for each of the profile that different workloads different tenant different users can specify different to the profiles for their workload to
00:27:08 [W] That workloads and scalability and scheduling conaty requirements to summarize.
00:27:07 [W] We have a seeing and increasing needs for new features in kubernative schedule.
00:27:14 [W] The schedule schedule framework provide a very powerful and the generic mechanism to enable us to develop new schedule new features many of them are already available.
00:27:30 [W] And under development last but definitely not least the community collaboration is the key the work we have presented today is the outcome.
00:27:42 [W] The outcome of close collaboration with the Upstream Community, especially the Sikhs scheduling community.
00:27:46 [W] More users and contributors are highly welcomed to join the community. For more information. Please visit the scheduler plug-in repo.
00:28:00 [W] We'd like really.
00:28:04 [W] Thanks, the contributors in the Upstream Community all collaborators.
00:28:12 [W] We have one Abdullah director both co-chairs of a Sikh scheduling and the Qin qiong Wang Kai Tong from Ali Baba on a cold scheduling and elastic scheduling contribution.
00:28:26 [W] We don't high from tencent on a CID based code scheduling.
00:28:32 [W] Find Annie.
00:28:34 [W] We are part of the Apple cloud service team. For more information. Please visit the Apple virtual booth and we are hiring kubernative engineer's from
00:28:49 [W] Structure to platform to application layer.
00:28:53 [W] Thank you very much.
