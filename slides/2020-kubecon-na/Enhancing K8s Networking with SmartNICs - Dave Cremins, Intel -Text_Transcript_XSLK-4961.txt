Enhancing K8s Networking with SmartNICs: XSLK-4961 - events@cncf.io - Friday, November 20, 2020 3:12 PM - 35 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Hi, welcome to Q Khan cloudevents North America 2020 virtual.
00:00:04 [W] My name is Dave crimmins.
00:00:54 [W] Hi, welcome to Q Khan cloudevents North America 2020 virtual.
00:00:59 [W] My name is Dave crimmins.
00:01:01 [W] I'm A Cloud Server architect working in the network platform group in Intel and today I'm going to talk about how we can enhance the kubernative networking model with smart Knicks.
00:01:14 [W] So for today's agenda, I'm going to talk about the edge bare metal deployments or bare metal as a deployment Target for the Aged and kubelet.
00:01:25 [W] He's then we'll cover kubermatic networking model the the simple requirements inherent in the in kubernative itself from a networking perspective and some of the trends that we've seen over the last number of years, especially as new
00:03:32 [W] artex
00:03:35 [W] so for today's agenda, I'm going to talk about the edge bare metal deployments or bare metal as a deployment Target for the Aged and kublr these then we'll cover kubermatic networking model
00:03:57 [W] On board to to kubernative platform will then discuss smart Knicks and the types of categorizations.
00:04:04 [W] We can apply this martinique's and then desegregation which I think is a key aspect of how we can enhance the kublr is networking model and maybe some more discussions around our flow techniques.
00:04:18 [W] So I want to start by discussing the age just just for a moment.
00:04:23 [W] So they did a patron here. You know, we keep hearing things around what actually is the age and the age is simply geographic distribution Computing done at or near the source of data.
00:04:38 [W] Here we have different aspects of the age of the on-premise age with the access age.
00:04:44 [W] We've near Age We fire Age, you know and it's all in terms of you know, the point of presence where exactly does it allow you from a geographic perspective, you know, and what kind of computing can we do at that location,
00:05:00 [W] We also tend to locate, you know, H Computing and there's close tie ins and alignment with the 5 G World select the move to 5 G is driving changes to H Computing and it is driving adoption
00:05:08 [W] since these five key Solutions come with the promise of lower latency higher capacity and increase bandwidth and when we start looking at the type of deployment models available from an age perspective, we see things like, you know public models
00:05:19 [W] On-prem type models and then we see a hybrid which is kind of like a combination of all of them and there are four main markets that are targeting H Computing today and they are the iot market Enterprise.
00:05:32 [W] alcohol in Cloud
00:05:33 [W] So, why would we look at a bare metal deployment for for the Aged?
00:05:41 [W] So like we have numerous Legacy applications that still required to run on virtualized platforms, you know, so there are inherently from that perspective.
00:05:53 [W] There are numerous deployment models for th with bare metal.
00:05:57 [W] We fertilize with paravirtualized etcetera, but H ployment will need small Footprints and even as we see the likes of you know, the cloud capabilities in processing moving towards the edge weaveworks.
00:06:10 [W] Things like the Telco industry adopting Cloud knative patterns and applying it to the edge the default print becomes very critical in the previous slide.
00:06:20 [W] We showed a depiction of the geographic distribution of H Prime Nats.
00:06:40 [W] Modern data center.
00:06:42 [W] We have little tolerance for extra server capacity like for instance virtualization.
00:06:47 [W] Correctly, so we get it right the first time and I think bare metal is ideal for the likes of network functions that really require that deterministic and predictable performance, you know, and why is that why is
00:07:02 [W] For for Network for Network functions as we transitioned from the the vnf world to the CNF world or we move, you know, Lexi v&f and orange team in something like kubernative.
00:07:05 [W] Well, we have full access to the harbor which is fantastic by virtue of the fact that we have full access.
00:07:12 [W] We automatically have a reduction in the amount of resources that we need.
00:07:15 [W] So we we look at this scale up model where we can scale up the capabilities of our bare metal platform versus
00:07:23 [W] Is scale-out model and I think this aligns nicely with the with the smaller footprint. So we scale up as opposed to out.
00:07:33 [W] We also have options to leverage accelerators like fpgas or qt or gpus for more types of performance gains and for more acceleration options and with with bare metal.
00:07:44 [W] I'm a firm believer that we were capable of generating higher throughput lower latency and Superior performance and this pretty much aligns with the 5 G promise.
00:07:54 [W] And even the H deployment requirements themselves, but another key aspect to why bare metal is very applicable to the age is it's more aligned with Dynamic aspects.
00:08:09 [W] We don't have you know taxes like the virtualization.
00:08:09 [W] I expect we don't have you know, static figurations that need to be in place when it comes to the bare metal.
00:08:15 [W] We can provision our system configure our host options have our are always running and then we have a number of runtimes in place. Then that provide abstractions around the governing software that's going to run on that particular platform
00:08:31 [W] Swapped easily and this facilitates, you know infrastructural changes with little side effects to Applications.
00:08:22 [W] So I do believe that the ages are the ages is our bare metal.
00:08:29 [W] Sorry is prime for 4H Employments.
00:08:31 [W] So my key takeaway is that the bare metal age is better designed to address the needs of Telco and can deliver on the Speed and Performance required by 5G Solutions today and in the future.
00:08:43 [W] So we have H we have bare metal.
00:08:46 [W] So how is kublr these fit into the picture here?
00:08:48 [W] Let's maybe examine some some Trends out there today.
00:08:51 [W] So forecasters are predicting huge increases in age Computing and this essentially is down to the fact that there are sheer quantity of age instances compared centralized Cloud servers and he's aged workloads will continue to rise.
00:09:05 [W] they'll grow more complex and they'll become more demanding. So when this when we get into this,
00:09:13 [W] particular Arena, you know infrastructure and platform resources need careful management, you know, so we need to be mindful of how we manage these aspects to ensure that we can meet the requirements of H workloads
00:09:28 [W] He's going to play a very critical role in this particular space because inherently kublr eighties is the ability to abstract the infrastructure capabilities while still providing a robust and scalable platform.
00:09:35 [W] Like this is essentially is is perfect for the likes of the H+ kubernative is doesn't really know or care about whether it's going to Target, you know, a cloud of Lyman tour an on-prem deployment or an H appointment. You know, it's it's it's
00:09:50 [W] Is the abstraction around in structural aspects so with this in place?
00:09:42 [W] How do we how do we ensure that we can Leverage The Edge platform to do what he was meant to do essentially are in terms of how do we get the best out of our of an edge deployment?
00:09:56 [W] So what we need to do is we need to start thinking differently, you know, we need to be aware of the boundaries and separate out the concerns and to achieve that we can look at things like disaggregation distribution. We need to look at how we manage our
00:10:11 [W] Resources on our platforms so it will we get the best out of our platform and we need to ensure that we have instrumentation built in from the ground up.
00:10:19 [W] So the we do have observability capabilities in place that allow us to collect process learn and even optimize kubelet is is going to be a big a big player in the in the age Arena.
00:10:35 [W] and one area in particular that I would like to focus on from an age perspective is the the kubernative networking model so that the networking model today in credit is has some simpler requirements all pods in nodes can communicate with all parts prodyna
00:10:51 [W] It applies. He's a set of eyes is the same IP that other see it as you know, so this is very primitive to two committees networking but that hasn't stopped Advanced networking models that we complex properties being deployed in Grady's all the time.
00:10:59 [W] And what do I mean by a complex properties?
00:11:01 [W] mean things like, you know tunnels and overlays, you know as advanced sidecar measures which are sorry with Advanced servicemeshcon solid care deployments iip sysdig.
00:11:14 [W] Second zero trust and we have data pane Technologies, then from the the low latency high performance domain.
00:11:23 [W] So things like DP D K and S Ray V etcetera and and then pertinent to Telco then are multiple network interfaces required on a pot and remember that kubenetes only supports a single interface from control
00:11:38 [W] and any other interfaces available via the Pod are not visible to the kubernative controlled plane it also my point here is that kubernative networking has advanced as the years have rolled on and as
00:11:27 [W] Let's say workloads types have on-boarded to the communities platform.
00:11:21 [W] So like these type of properties require platform resources to deliver under respective claims.
00:11:28 [W] So let's take an a an example of oven for kubenetes.
00:11:32 [W] So if we see here what's the idea here is that I want to try and highlight that there are complexities involved in provisioning a kubernative network.
00:11:48 [W] I've to ensure that we have connectivity that we can traffic can be directed to egress or we can accept traffic on Ingress and things like that.
00:11:58 [W] We have, you know Network policies in place and we have a whole plethora of operations and behavior that are defined from a networking perspective, you know, so like even in here just to provision a simple pot with oven
00:12:13 [W] We have the right integration without obvious.
00:12:11 [W] We have three streams of work.
00:12:14 [W] We've got the kublr these podcasts a sheet flow, which is essentially the 124 or at least the Roman numeral version.
00:12:24 [W] We have the the network settings generation flowmill. Then we have the network settings application flow. So like Allah and you will see that there are there are a number of different containers in the networking space for kublr Eddie's, you know weaveworks.
00:12:38 [W] Got other sdn, controllers - you know, we'll have equally as complex properties in configurations that need they need to deploy and manage and and you know, they these are absolutely critical for different
00:12:54 [W] Function correctly so kublr is not all that prescriptive in terms of what it mandates from a networking perspective, but we still need the extra complexity and characteristics of the sdn controllers that are deployed today to ensure that we can meet the demands of the workloads
00:12:59 [W] not kubernative
00:12:53 [W] and the another key Point here is that change is inevitable now working architectures are continuing to evolve and when they evolved to become even more complex.
00:13:03 [W] this already happening and it's the age will be targeted with these type of complex networking deployments.
00:13:13 [W] You know, we've got things like network of stability.
00:13:15 [W] We've got things like artificial intelligence and machine learning. We've got service Assurance in terms of the hole closed loop model.
00:13:22 [W] And these these kind of constructs require extra processing the daily, they'll need much more time on the CPU and access to memory. And are we a lot more going over the bosses as
00:13:38 [W] Likes of you know, very simple networking requirements.
00:13:37 [W] So we need to be careful when this happens because the networking models are evolving the computations are also getting bigger but we what we see here is that we see em an explosion in bandwidth capabilities.
00:13:52 [W] We see, you know, an increase in the amount of traffic that needs to be processed and this is kind of disproportionate to the amount of resources available on our platform.
00:14:02 [W] you know, so while they the pipeline gets bigger when our Fabrics increase our bandwidth increases the amount of traffic increases our platforms are kind of struggling now to keep up to ensure that we can still provide
00:14:17 [W] Stick performance and abide by the the SLA is that would agree to so why would we utilize our platform resources for let's what we call infrastructural boilerplate if we don't have to so we do
00:14:23 [W] in terms of desegregation where we can leverage the likes of Hardware a floats and and this I think is something that the kublr and is networking model can can easily benefit from
00:14:27 [W] So from a networking perspective, you know, we have Smart Knicks are being discussed and they're they're being targeted to things like the the aah, they're being targeted to things like the
00:14:42 [W] did for things like they say on Prime and Hybrid models and really what do we actually mean by by a smart-aleck, you know, and and how does a smart Lake afford US the opportunities to accelerate
00:14:55 [W] Working aspects are even not just the networking assets but multiple aspects of the entire workflow.
00:14:57 [W] So, you know, if you look for a definition of smart Lake, you know, it's hard to settle on any one particular definition.
00:15:04 [W] So I've put in a number of definitions that you should you will probably come across if you start researching the likes of what smart and XR. I've come across things like network attached acceleration platforms a new
00:15:19 [W] A target for a network pipeline a program will data plane a location to run infrastructure management components.
00:15:25 [W] Let's move some of the control plane aspects to to a Smart neck and another categorization or not categorization. But let's say another type of Target for the smart like then is a guarantee for
00:15:40 [W] Paradiso move their the root of trust directly to the smartness harbor. So let's let provision are networking model.
00:15:43 [W] Let's provision, you know all of our policies and enforce them at the Smart Nick layer and free up our our platforms for processing.
00:15:53 [W] take the the trust in the security model and we move it down the layer into the actual smart Knicks. So this allows, you know clouded means assisted means to prodyna.
00:16:04 [W] Graham the the networking model so that tenants can can operate without breaching security boundaries.
00:16:12 [W] But also when we look at smart Lakes, you know, we see different variations in terms of the categorization of smart next we see system on chips and then we see discrete versions, you know, so like
00:16:27 [W] Diagram here is the what we're trying to say really is the degree of smartness May Vary, right?
00:16:26 [W] So we need to look at things like a figure ability.
00:16:29 [W] We need to look at, you know afloat capabilities.
00:16:31 [W] We need to look at flexibility and efficiency also and flexibility and efficiency.
00:16:36 [W] You need a delicate balance between both of them.
00:16:41 [W] both are required. So if we look at like the system on chip model, we have like the likes of maybe programmable course if we're using an essay.
00:16:50 [W] Jack we've got you know fpga system on chip which allows us to do configurable logic if we move across and we look at look at some of the discrete models.
00:17:00 [W] We have a six that are more limited in terms of their flexibility, you know, it's hard to change them and then we have, you know combinations like a sick and fpga which provides the the efficiency and
00:17:15 [W] Our flexibility required and then we maybe have like a full-blown fpga. But you know to do this like both of these are required in terms of flexibility and efficiency.
00:17:16 [W] So and with this we can look at things like, you know performance security and a floods and these are the type of things that you know, we can move to a smart aleck to allow kubernative use to
00:17:32 [W] Get in terms of ensuring that workloads are running and in their pods are in their creators in their pots under platforms.
00:17:28 [W] And this type of you know, employment of smart.
00:17:33 [W] Nick's really is conforming to what we call it like a hybrid Computing model where we have cores available on our platform with you know, memory and storage and we also have korres and accelerators.
00:17:49 [W] Via the the smart Knicks and these are like, you know debating domain-specific architectures and the domain in our case for this particular talk is around that the networking processing capabilities required for especially the Telco
00:17:59 [W] So smart necks are essentially the for to keep it abstract for this particular talk.
00:18:02 [W] Let's I'm going to this it Define smart Knicks as a platform that has processing capabilities and our floor floor acceleration capabilities also,
00:18:17 [W] So we spoke about the boundaries, you know in terms of what our platforms at the age should do and you know, we spoke about how we could provide some disaggregation at the edge.
00:18:31 [W] So the you know the H know based on that the first diagram in the in the first slide, it doesn't have an abundance of resources.
00:18:39 [W] It's not like a data center. Right as we said it doesn't it's constrained and put potatoes in stop us wanting to buildpacks much workloads as possible at the age, you know Soda to deliver on what age Computing claims to be able to
00:18:54 [W] We want to provide predictive models for deterministic performance.
00:18:52 [W] But how you know how we going to cheat this?
00:18:55 [W] How do we disaggregate concerns from our main platforms and move it towards let's say sorry alleviate the pressure on the platforms and move it elsewhere.
00:19:05 [W] Well, we want to leverage a sidecar platform but apply that to the infrastructure as was done for let's say Delta layer for two layer 7 type applications with the servicemeshcon texture.
00:19:18 [W] By deploying, you know side cards that, you know, take care of the data plane within the pods.
00:19:25 [W] We also want to leverage the same concept and apply it to the infrastructure if we do that.
00:19:29 [W] What does that yield for us? It means Network flows can be programmed and offloaded so we have things like ovhcloud control. We have are T flow for things like DK we can offload these directly onto our list. They are smart. They can this case
00:19:45 [W] To between the the physical function to the virtual functions without going through software.
00:19:37 [W] So we have acceleration almost immediately.
00:19:40 [W] So we have no software in Play It's purely a hardware concern.
00:19:46 [W] We have inline processing that can stay in the neck and then look so you can directly transmitted to the Target.
00:19:52 [W] So no data movement back or forward within the with the host.
00:19:56 [W] So we've eliminated that and we've created a boundary that I've been speaking about.
00:20:00 [W] it's still in the neck, so
00:20:02 [W] Our platform and our utilization of our course is very very low with this type of a flute or this type of capability.
00:20:09 [W] We can also look at programming our security policies and having them managed by the smart neck so we can have our Access Control lists manage their we can have our Network policies manage their we can do EPF offloads so we can do filtering load balancing monitoring.
00:20:25 [W] Capability we can also look at programming our security policies and having them managed by the smart neck so we can have our Access Control lists manage their we can have our Network policies manage their we can do EVP FF loads so we can do filtering load balancing
00:20:34 [W] All of the things that come with the epp epp F work or at least d p DP of technology and we can also then leverage the smart Lake to deploy observability pipelines.
00:20:48 [W] So observability by today's standards is very important.
00:20:51 [W] want to ensure that we so we're already in what I would call a reactive model where we have the standard process of where we collect the information we generate.
00:21:04 [W] some insights and then we try and leverage that, you know, so it could be the case that we we we detect that a particular Network slides in 5D scenario isn't or it's going to run into trouble in terms of delivering on its
00:21:19 [W] so we can use observability pipelines to ensure that we you know, start to provision out a new slice or without we increase the the capabilities or bandwidth available in that particular aspect, but that's that's reactive, you know, so
00:21:33 [W] We collect information and then we make a decision or we make an action based on what we've collected.
00:21:29 [W] But what happens when we want to start moving towards proactive models where we have smart intelligent systems deployed sitting on our smart Nick's that are able to over provision as needed.
00:21:44 [W] Some City ployed sitting on our smart Nick's that are able to over provision as needed or we can move pods between different locations.
00:21:53 [W] So all of this again is something that you know, I believe would be come to the Forefront. Once we have fully embraced, you know, Edge Computing and the five key solutions that will accompany that
00:22:08 [W] Or front once we have fully embraced, you know Edge Computing and the five key solutions that will accompany that but the very important Point here in terms of disaggregating concerns and
00:22:24 [W] Important Point here in terms of disaggregating concerns and processes from the eight perspective is that this shift is not new, right?
00:22:35 [W] We want to facilitate advancements in networking in kubernative networking, but without the cost of the extra CPU Cycles. This is a perfect fit for each scenarios.
00:22:45 [W] follows the exact same patterns that have been deployed across data centers and clouds for the last number of years.
00:22:54 [W] So smart Nick's provide programmable Solutions.
00:22:57 [W] We can enhance our overall networking model while kublr these continues to orchestrate business value and that's the key message here.
00:23:04 [W] That is very applicable for 4H Computing.
00:23:07 [W] So now that we, you know have opportunities to enhance the networking model via a smart Nick offload and with smart neck deployments for numerous targets like the idh to forage the cloud Enterprise Etc
00:23:22 [W] Floods can we leverage? How can we also desire great other aspects maybe even of the control plane?
00:23:29 [W] We can take use things like, you know dedicated fpga devices quick Assist Technology for things like encryption and compression and GPU for more offloads for graphical of for intense processing
00:23:44 [W] GA devices quick Assist Technology for things like encryption and compression and GPU for more offloads for graphical of for intense processing which with Graphics are or even more
00:23:58 [W] Pixar or even more mathematical computations like for instance machine learning things like that.
00:24:04 [W] So my point here is that data planes can be offloaded possible to control plane concerns like encryption compression in the case of Acuity device, which can offload that and save more Cycles.
00:24:16 [W] So this embracing of acceleration I think is of acceleration and potential offloads. Is is Paramount for the for haproxy.
00:24:28 [W] Each Computing to succeed and kublr T's is very equipped to handle these type of scenarios.
00:24:38 [W] It just won't we need to bring to the table is these particular offload capabilities and ensure that we have successful orchestration in place, which I think is very very possible as smart and X are already are already deployed today. There have
00:24:53 [W] over the last number of coupons around smart Knicks and offloading things like ovhcloud the cash pad and so on like that, but this this talk really is about enhancing kubernative as it's going to be deployed at the age and how
00:25:08 [W] Valued new opportunities for us as kind order offload Technologies in order of Hardware offloads.
00:25:04 [W] So thank you very much.
00:25:05 [W] I hope you enjoyed this. Thank you.
00:25:13 [W] So looks like we have some questions in the Q&A section.
00:25:18 [W] So Intel made most is to support multiple interfaces in pods for Telco 5G along with many more advancements. But this model is still lacking a lot of capabilities since kublr these is not aware of the second interface
00:25:33 [W] Support a load balancing nor service Discovery Q proxy Etc.
00:25:32 [W] Has anything changed recently are there are some planned events that have more native support for multi interface and parts.
00:25:39 [W] That's a really great question.
00:25:43 [W] It comes off quite often.
00:25:46 [W] It's a very frequent ask not just from the Telco R 5G perspective.
00:25:50 [W] This comes from the Enterprise perspective and even the cloud as well. What I would say is that
00:25:58 [W] in the network Plumbing working group was the team that defined the essay the payload definitions for multiple attachments.
00:26:06 [W] This particular group is made up of numerous community members and they're directly is a stream of work ongoing right now spearheaded by some of the folks at Red Hat to essentially
00:26:21 [W] Isms directly into kubernative to create that awareness from the control plane perspective for multiple interfaces. One of the first piece of work that's going on here is essentially around
00:26:32 [W] Could be interfaces to ready Services one of the I think one of the biggest issues with that are at least one of the biggest hurdles that we need to overcome is the the load balancing aspect and having the right level of recognition from
00:26:38 [W] That is that is ongoing and as I said, it's a very popular popular question. There are also other aspects to multiple interfaces on the pods that are being looked at in terms of the right level of
00:26:53 [W] other aspects to multiple interests on the parts that are being looked at in terms of the right level of observability given that kublr and is not aware that these attachments are available from the in the in the
00:27:06 [W] Given that kublr and he's not aware that these attachments are available from the in the in the parts elf.
00:27:12 [W] So observability and mapping the kublr deserves.
00:27:16 [W] They're definitely two areas that are being looked at right now from multiple folks in the community. And if you want, let's say more information in terms of the details on this. We have a biweekly sink in
00:27:31 [W] We have a biweekly sink in the networking working group where a lot of that is is discussed and they are is assigned and and more follow-ups, but that answer your question.
00:27:43 [W] Yes.
00:27:43 [W] is a this is something that is ongoing right now next question zero copy communication protocols help improve the performance of DSM systems.
00:27:59 [W] Yes, so zero copy. It Ctrl copy is a very performant means for packet processing that that that's for sure and actually fact, you know, we are
00:28:14 [W] If XDP socket type it comes with the potential offering of a zero copy mode right now.
00:28:21 [W] It's not available in kubernative it given how the interface actually moved from the the host name space entertaining space.
00:28:31 [W] So what that what that essentially means is that the entire interface is moved into the pot so I can share the zero copy aspects with with other parts on the same note.
00:28:40 [W] my point is it doesn't really scale.
00:28:43 [W] Once we overcome that I do think that something like a zero copy offering will become, you know, a prominent model in the networking space for kubernative, especially as workloads become more intense and more
00:28:58 [W] But yes, I do believe that a zero copy communication helps to improve the performance. We would incorporate his her for sure and it is something that is actively worked on.
00:28:59 [W] Just some some more questions.
00:29:01 [W] Could you please quick describe what you mean by not rocket network-attached acceleration platform?
00:29:08 [W] Yeah, absolutely.
00:29:09 [W] So I this is a term that you know, internally the Intel we use quite often and by network-attached acceleration platform what we're really saying is that from a smart aleck perspective. We have a lot of processing power within
00:29:24 [W] of and this presents opportunities to maybe as I said during the talk is to offload some of the infrastructural processing components and move them directly onto that particular platform itself given the fact that it's
00:29:33 [W] Processing components and moved him directly onto that particular platform itself that given the fact that it's essentially an external card or smartly car that's plugged into your platform the it came about that.
00:29:43 [W] It's kind of a network-based given that it's you know, it's the sh T. It's the medium to the to your tour or your switch configuration.
00:29:52 [W] So it's a network attached platform given that amount of processing capabilities on it.
00:29:59 [W] And I'm going to I don't think this this term is is purely from internal at Intel dive seen. This used quite often during different discussions with different folks moving on to some other questions.
00:30:18 [W] How you see if you have portability versus diverse Harbor options on uh, I worked at a telecom vendor before and it was always the headache not even for agent Cloud, but always do you see kublr Eddie's or cncf would be able to change
00:30:36 [W] Another great question a very popular ask from from companies and this one is very applicable to the Telco industry given the Telecom vendor engine there.
00:30:49 [W] So when we look at vnf portability this this is an issue in kublr t so kublr it is all about abstraction.
00:30:58 [W] It's all about, you know, keeping things as simple as possible providing the right level of extensibility.
00:31:04 [W] Two phases for your workloads to plug into and then we have the the vnf type applications that need to be Hardware.
00:31:15 [W] We're right and and the same will become this the same type of concept wrote will carry over to the edge So my answer to this is that from a portability perspective we have there are technologies that are will be will
00:31:30 [W] He's in the next 12 to 18 months.
00:31:31 [W] And I think while they may not be able to Target the same level of performance as the let's say the let's take for instance.
00:31:42 [W] If we have a vnf test everything something like this or IV, right or virtual function.
00:31:47 [W] There has to be a certain level of awareness of the hardware itself, right?
00:31:51 [W] Right? And this absolutely breaks the abstraction layer. So what we really want to do when we run
00:31:58 [W] what to look towards is something that is able to provide a good enough performance but allowed out that the right level of portability and and that means essentially masking or abstracting Hardware options
00:32:13 [W] Towards let's say new offerings are new technologies that you know cater to that the portability.
00:32:12 [W] Let's say criteria. And this I think is something that would be applicable.
00:32:21 [W] This would be something that is applicable to age and Cloud Enterprise and to hold different bucket of deployment models. So I yes, I think VN affordability is a hard one right now, but I think there are
00:32:35 [W] Geez, that will be embraced soon.
00:32:39 [W] that should be able to deliver on good enough performance. But what have the right level of portability so we can really look and actually be part of the cloud native.
00:32:52 [W] Let's say ecosystem just moving on.
00:33:00 [W] It's reviews mentioned as an option for part in again with limitations bypass most features provided service load balancing policy cetera.
00:33:07 [W] Do you see other viable cni-genie for high speed low latency networking age for gup. I fear I do you like a bpa-free be or artery EPA for VP or srib is still only viable option here.
00:33:19 [W] So another great question that is very related.
00:33:22 [W] So I will be very honest here.
00:33:26 [W] I don't want CS R AV going anywhere anytime soon given that we are still trying.
00:33:29 [W] Is essentially as you know, the actual VM been carried over using something like you virt or vertices and pay that right?
00:33:29 [W] So I don't want CSRA be going anywhere.
00:33:32 [W] It's still a very high speed solution for networking and even in kublr these but I do see a lot of potential with something like EPF and this again is is will be part
00:33:48 [W] The work that we're doing right now with Intel is to explore options with EPF filters and BPF maps to ensure that you know, we can build in certain levels of observability at the earliest point in in the
00:33:55 [W] At the packet injection, so I do believe something like e bof will be would be a prominent networking player incorporate.
00:34:01 [W] He's going forward given that there is a lot of support already in certain kernel versions onwards and I think a lot of these current versus n will be part of your standard containerization systems.
00:34:14 [W] yes, I do think that something like that will absolutely contained with HIV tufin.
00:34:21 [W] Deployments as well.
00:34:22 [W] Absolutely. I believe in that he is.
00:34:26 [W] So our our lock-free reads possible VAR D M8 Nick handshake.
00:34:33 [W] I'm uh, I'm not a hundred percent.
00:34:35 [W] sure.
00:34:36 [W] I need to come back to you on that particular school question. I need to look at that further.
00:34:41 [W] Maybe you tell you one more. Also how we spiffe or API is important smart neck.
00:34:47 [W] the smart egg roadmap will have support for P4, but P4 is let's say neuvector.
00:34:56 [W] Way for first Martin aches and I it's it's still kind of an evolving API and once we hit certain levels of maturity, I think then that the you'll see a prominent support and across numerous.
00:35:11 [W] Offerings that can Target P4 deployments but P4 does have a lot of potential but it's a slightly different model and we'll probably meet some extra work to ensure that it's primed for something like kubernative.
00:35:28 [W] It's a slightly different model and will probably meet some extra work to ensure that it's primed for something like kubernative.
00:35:25 [W] So I think that's all we have in terms of the live QA.
00:35:29 [W] So to keep the conversation going, please visit Josh to Q Khan networking on our slack Rook space after the session ends. Thank you very much.
00:35:38 [W] Hope you enjoy the rest of your gun. Thank you.
