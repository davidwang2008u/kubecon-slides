Logging: Fluentd & Fluent Bit: WZQX-9865 - events@cncf.io - Wednesday, November 18, 2020 5:46 PM - 37 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Hi everyone.
00:00:01 [W] Thanks for coming friendly and printed it split decision.
00:00:04 [W] So my name is Martha how friendly developer of the project data in this session.
00:00:45 [W] Hi everyone.
00:00:47 [W] Thanks for coming friendly and printed it split decision.
00:00:50 [W] So my name is Martha a friendly developer of the project data in this session.
00:00:55 [W] I talk about the free tree overview article on the use cases for new friends of the users either though. We talk about the friend to beat in the second part.
00:01:06 [W] The first is our friendly over bill.
00:01:12 [W] Currently is designed to hold the streaming data collection. So this means fluently continue to read the data from data sources and write data to the destinations in so leaning manner currently consists of the core part on the
00:01:36 [W] problems the friend to beat in the second part
00:01:41 [W] Okay, let's start. The first is our friendly over bill.
00:01:47 [W] Currently is designed to hold the streaming data correction. This means fluentd e continue to read the data from data sources and write data to the destinations in so reigning monarch currently consists toxic or pot on the
00:02:02 [W] Sells for get the correction and the Providence pot and cover lecture use cases. For example, So reading data from the other sources and writing data to the databases.
00:02:12 [W] The fluentd E is written in Ruby with C extension and friendly units resumes for the probability distribution so we can use whole new vehicle system for private development all set up.
00:02:25 [W] We provide are several approaches.
00:02:27 [W] example, so friendly Community provides the OS spok case like the RPM and msf buckets so you can run friendly on Linux and windows.
00:02:39 [W] Of course for the committee provides the container images for there are the currents the kubectl statement set.
00:02:47 [W] Apparently on the fill tube, it has a locking part in cncf so bad. It is and related to products used fluentd e and great week for the data correction remedy also is the cncf products for example currently has a primitive screaming
00:03:02 [W] Switch the Matrix to solve the problem that occurs.
00:03:10 [W] This is one example of the sort of data collection for the local files in this case frontally model files friend application rates low goes to the local files friendly these Rose immediately and the same drugs to the central server
00:03:25 [W] D. So the make the list approach is no need to wait all data are loaded in the local files. You can see the new one looks quickly in Rook server via the dashboard over as answers.
00:03:34 [W] And production so we have lots of rows and collect it for the businesses.
00:03:39 [W] For example, so collecting the data service or system removes. These looks are used during the kpi or machine learning or sucks motoring or more.
00:03:50 [W] So we need 200 various local Types on the real world.
00:03:58 [W] Anthony has are probably actually picture for solving this program.
00:04:01 [W] We can be the unified reading layer with fermented e friendly is a groovy your data pipeline. We can collect the data from a data sources and send the data to the LEDs Nations.
00:04:14 [W] Okay. Next is our friendly architecture.
00:04:19 [W] Again, so friendly consists of the core part on the program starts. This page shows the details of the front zipper design.
00:04:28 [W] Friends of the core provides several important features for the direction for example probably is don't do in the three previous the complicated to buffering or little iron mechanism in each home is implementation.
00:04:40 [W] V
00:04:38 [W] You know Jones currently provides a similar help us for pathology.
00:04:43 [W] So selecting timer set up XD server and more providing developers can focus on implementing a quadratic of the probability by using the help us. This is why friendly has a lot of plugins by the committee.
00:05:01 [W] In this is a structural fluentd is one event print the event consists of the three elements tag on the time and record.
00:05:11 [W] For example, if you have an Apache Rose, so one look Ryan is combative during to this structure.
00:05:19 [W] The tag is used for the event to looting and identifying the data sources.
00:05:23 [W] The important point is the actual content is converted into the Json object. Not true story.
00:05:30 [W] Json object is easy to mutate or 82 filtering and it is to transform to the as a whole must associate's degree, or as a binary homeworks.
00:05:40 [W] So in addition to popular middlewares recently, the salafis can accept adjacent orbital knative Ray. So this is why friendly uses a Json object for you get the record.
00:05:55 [W] This image shows the event processing flowing fluid to be incoming events pass through this pipeline from the right to left.
00:06:02 [W] I think the problem is a starting point of the data pipeline into the program and disabled a deceived or either data data sources and Emma terms the data pipeline important point is input the program, but it's the rules for the structure drawing.
00:06:10 [W] Throws to the data pipeline important point it's in put the plug in positive zeros for the structure drawing.
00:06:04 [W] logging Locos were converted into friendly event in into the plug-in.
00:06:12 [W] Computer programming is a simple filter or mutated events.
00:06:16 [W] So for example, so a dingo stole name to event record check the condition to ignore unnecessarily logs.
00:06:24 [W] of course free to play we could be chain so you can apply multiple filters to the data streams.
00:06:34 [W] Before Proline is a use the inside is auto plugins.
00:06:37 [W] So notice and our own incoming events storing to buffer before rights to destinations, but for patterning is a call over robust buffering and the little mechanism for dr. Provine soap if you use file buffer data
00:06:52 [W] I think that this this opposed to data loss even faintly crushes.
00:06:57 [W] crushes. So we recommended to use the higher buffer on production.
00:07:02 [W] Part of the problem is very simple just in the data to the destinations.
00:07:12 [W] This picture also shows us how to be Hunters gitops rims.
00:07:15 [W] Incrementally data streams are split into small chunks this approach makes our it right cheaper and ready to recover unlike the large batch model with a small chunks so we can easy to process data concurrently.
00:07:31 [W] Approach also improve the latency between the data sources and of this nation, this is the method of storing data collection and widely uses solving approach.
00:07:42 [W] Okay, the committee did this is a lots of install plug-ins so you can collect the data from the databases or data services or other monitoring tools.
00:07:58 [W] On the committee also released a lot of out to plug in so you can send the data to the any databases data object storage and web services.
00:08:07 [W] So you can easy 200 buggers data sources and let this nation's by the peregrines.
00:08:16 [W] Next we choose the popular use cases.
00:08:22 [W] This is a simple use case.
00:08:24 [W] So useful in 2D for data collection from multiple data sources leader local files and receive data from the application and winter descends data to the databases.
00:08:35 [W] So like mongodb or rdbms.
00:08:42 [W] This is a conflation example for this year's cases. The Confessor syntax is Apache like hormones so selective or the instagramming the market elect or not. Elect a Peregrine this example does the harbor Twitter for example, sorry.
00:08:58 [W] We have shown somatic detective as the toggle button for the event the routine for in this case events from Tel Aviv to proving as the operatic style.
00:09:02 [W] So these events so are going to the mongodb.
00:09:09 [W] A friendly also supports multiple destination so you can send the data to the different destinations for different purpose in this example.
00:09:18 [W] So use elastic search for real-time dashboard and use how the way to deface or but and archive box.
00:09:29 [W] the friendly support smart styra model with original hoarding protocol widely followed the protocols suppose that to debris semantics or Kuma Sera Sera Teresa wants High availability and the load balancing for multiple aggregators
00:09:45 [W] GMO that is mainly for high-traffic environment. If you like the restrain this model check the link on this page.
00:09:39 [W] Okay, that's the part. I talked about the container and the friendly.
00:09:46 [W] Friendly is widely used in the containerd logging.
00:09:49 [W] So I will talk about how to correct errors from the correct containerd.
00:09:55 [W] First I chose this video resources for the containerd logging.
00:10:01 [W] So we provides the RP and Divya images.
00:10:05 [W] So we recommend you to use the Debian images of production because the Divya images works is 60 million the jmark we use jfrog to optimizes our memory usage.
00:10:18 [W] Who kubernative we provide the demo set setting and images of the popular destinations for classic start your Kafka and other this nation support advisor for sure Repository.
00:10:32 [W] In addition, so Helm officer repository provides a stable friendly chat so you can learn friendly on poke and prod promise with these resources.
00:10:45 [W] Can you next week?
00:10:46 [W] We sure we talked about the how to correct Rook screams containers.
00:10:50 [W] Both Flint video entry but by default so you can send application logs to the friendly using revealing driver.
00:10:49 [W] The Matrix is no need to write a python code to your application.
00:10:53 [W] The infinitely site you can is flatly probably to receive looks from Docker.
00:11:00 [W] This is Doc a specific approach but easy to use no need to modifying your application.
00:11:11 [W] Second approach is using frontal local library printer Luca is implementing during each playing language.
00:11:18 [W] This approach is mainly for the application data or Matrix with this approach. You need to login code in your application, but you can connect to any data with fluently.
00:11:30 [W] And if it's any consolation at the same as the Caribbean driver use holding up the plug-in to receive data from Winter logger.
00:11:40 [W] On qualities we use demo set for collecting data from containers kubernative storage container laws into the bottle containerd directory and the friendly it these drugs using Intel Peregrine or
00:11:55 [W] And if it's any consolation at the same as the Caribbean driver use holding up the plug-in to receive data from Winter logger.
00:11:57 [W] On qualities we use demo set for collecting data from containers kubernative storage container laws into the bottle containerd directory and the friendly it these drugs using Intel Peregrine or
00:12:25 [W] images use this approach follow correction
00:12:31 [W] and the amount of Damages in Greece the metadata metadata filter by default.
00:12:35 [W] This filter gets better data from cuentas API server and automated data to the event to record for example hostname or containerd name for today at it. So you can use this metadata on what data
00:12:51 [W] all the aggregation or the filter
00:12:57 [W] This is a summary of the logging method for the containers. So you can choose these approaches for your knees. So for dr. Looking to read by its popular approach and only kubernative.
00:13:08 [W] So we is Intel probing for the containerless files.
00:13:18 [W] Okay, let's depart is finished. Next is the fifth week by Eduardo.
00:13:26 [W] Thank you, Massa. Hello everyone.
00:13:29 [W] My name is Eduardo Silva and I'm one of the maintainers of the fluent bit project flowing beard is part of the fluid ecosystem and it's a project that started around 2015 initially for embedded Linux, but quickly evolved to solve
00:13:44 [W] It's under the Apache License. Of course, one of the advantage of fluentd in general is that it's written in C language. And this is very optimized for a low CPU and low memory footprint.
00:13:53 [W] Actually it already has a probable architecture when you can have more than 60 plugins available built-in natively in C. So what this is one of the advantages that when you deploy the agent, you don't need to insult a
00:14:08 [W] I'm from a Delaware field perspective.
00:14:02 [W] It's very similar to fluently we have an input section where we collected a from. We have the parsers to parse the data and convert from instructor former to sort of format. We have the filtering phase for Darren Richmond
00:14:17 [W] We need is you need to reach your data with kubernetes a metadata like labels annotations?
00:14:19 [W] We have all these buffering section and groaning make a mess and to send your data from one place or many others this kind of destinations or the input source of data.
00:14:29 [W] All of them are configured by lichens and fluentd in general is made for a high performance at low cost solution. So if you have for example you're working now.
00:14:42 [W] in a common Cloud environment and you have a very intense application that generate a lot of looks actually what you want is to have that your agent consumed as list you as possible but the employee procedure data and
00:14:57 [W] It's fluid kubernative.
00:14:58 [W] You can have many notes, right plus it has a master API you have notes and you have your applications inside codes.
00:15:06 [W] So in this is kind of a scenario, it's a is not that easy to process the locks and ship all the loss at the months as Master said in the previous present in the previous section.
00:15:18 [W] He said that yeah, we have all these gifts only can be deployed sudden onset and can solve the problem. So we follow this.
00:15:25 [W] Same pattern we are able to be deployed as a demon set and solve all these problems imagine that if you have an application that is generating for example, and Apache web server is generating the log messages, right? All of them doesn't have
00:15:40 [W] Goes to the file system or goes to journal dick.
00:15:37 [W] With these messages are generated.
00:15:39 [W] For example, if you consider a that they use in the Json Json format for the file system.
00:15:45 [W] All of them will have a every container will have its own specific blog file.
00:15:50 [W] So the agent needs to be able to correlate all this information together and that message is not just a message. It also has a string for nature and the time that when this message was created inside the kubernative snowed,
00:16:05 [W] It's really important to understand and get the context of the information.
00:16:00 [W] That's why a the API server in kubernative provide your extra information for the container or poddisruptionbudgets for example labels or annotations because at the end when you do data processing or data analysis
00:16:15 [W] Information that you care about because um to search for all the logs that a every application that has a label color equals blue as an example.
00:16:16 [W] So a simple message that is start in kubernative Soros are in airport like this becomes something.
00:16:24 [W] With more content like a the process of data right there kubernative metadata record labels annotations that spok name and so on.
00:16:33 [W] So with this we correlate all the information from the cluster and every record has all the information together.
00:16:40 [W] So when you process this is a more straightforward process and how this works internally fluid is deployed study more set but also can be deployed as a psychic cycler container. It reads a lot spok.
00:16:54 [W] File system then it goes to the pi server as I said to retreat the metadata and then to be able to finally push the old area that is correlated to your final destination.
00:17:05 [W] Final Destination can be any job service back supporter or any kind of custom HTTP endpoint.
00:17:13 [W] You can use your own elastic search graphql that we waste possibly SQL, but we have many connected for your different and favorite backwards.
00:17:21 [W] There and every record has all the information together.
00:17:21 [W] So when you process this is a more straightforward process.
00:17:26 [W] And how this works internally fluentd is deployed study more set but also can be deployed the site keptn cycler container.
00:17:35 [W] It reads the words on the file system.
00:17:36 [W] Then it goes to the pi server as I said to retreat the metadata and then to be able to finally push the old air that is correlated to your final destination.
00:17:47 [W] Final Destination can be any cloud service that supporter or any kind of custom HTTP endpoint. You can use your own elastic search cuff guys.
00:17:56 [W] Do is possibly SQL but we have many connected for your different and favorite bikes.
00:18:04 [W] So fluentd was cream 2015. We are close to have a to turn five years next year and what is really important here to understand?
00:18:15 [W] What are the new things are coming up in the project so few weeks ago. We released flowing big one that six and one of the mayor a future said that we ship our the new Enterprise connectors Enterprise. I mean that we're going to
00:19:37 [W] The project so few weeks ago.
00:19:40 [W] We released fluent bit one that six and one of the mayor a future said that we ship our the new Enterprise connectors Enterprise. I mean that we can improve is Enterprise calling for all of them are for free for use.
00:19:52 [W] Of course.
00:19:53 [W] It's for the Azure blob service where you can send your data to a block syrup so our blog or on a pendulum in Azure. Also, we have the nutrition for professional. Okay, and also with Amazon we just
00:20:07 [W] come together with the connector for Amazon S3 and Amazon fire hose.
00:20:12 [W] This is not new at least low-key and Amazon connectors are very existed in different image images provided by prodyna and vital us, but they implemented the connectors in: this time we migrated all
00:20:27 [W] Connector for Amazon S3 and Amazon fire hose.
00:20:30 [W] This is not new at least low-key and Amazon connectors already existed in different image images provided by prodyna and vital us, but they implemented the connectors in: this time we migrated all these connectors
00:20:58 [W] And which and we ship all of it by default in the primary distribution of linbit out. Of course, you came a lot of performance compared to the other patients.
00:21:08 [W] that's major thing here, if you know about filtering and reach your metadata, you will know that also is not about enrichment.
00:21:18 [W] You also can take some logical decisions like filter your data out or take some action or trigger some alerts and now if we are going step
00:21:28 [W] Are we that and we're trying to bring all these machine learning all these capabilities capabilities or analytics inside the flowing back pipeline. So they aren't in has provided a new filter to run their so flowmill
00:21:43 [W] So you can have your data which Is possessing certain metrics and you can apply them oil and if the model traps deception I assume that that is the term for that a you can create some alert for your some action.
00:21:57 [W] This is not for training inside the timeline, but just to deploy your models and apply this mode on top of your data that is Flowing which is quite powerful and can open many possibilities to do data analysis on the edge.
00:22:13 [W] From a community perspective as of last month in October.
00:22:18 [W] We hit a hundred and seventy million deployments for this year.
00:22:23 [W] I think we are going to close two hundred million in the whole year.
00:22:27 [W] So this means a huge attraction in the project.
00:22:31 [W] So this kind of the plugins are happening every day and like and this is like crazy.
00:22:36 [W] crazy. It's a crazy numbers. But if you carefully this is thanks to the help of every Enterprise.
00:22:43 [W] Button that it's a big cloud provider or a service provider actually from it. It's been supporting the three major Cloud providers again that weighs ovhcloud Microsoft and others like digital ocean and basic cloud and so
00:22:58 [W] And like and this is like crazy so crazy numbers, but if we look carefully this is thanks to the help of every Enterprise company that it's a big account provider or a service provider actually
00:23:29 [W] For you is really important that we keep all this Synergy across user end users Enterprise.
00:23:38 [W] The companies and also the developers so we try to have all this kind of party together because they feel that they do provide.
00:23:46 [W] Also if you're watching this this session life until Khan is really important. I would say that 78% of the Futures that you see influence bit is because of the fever from users review.
00:23:59 [W] On also we're looking for how to get better at Matrix.
00:24:05 [W] So we are working together with the opentelemetry team to try to integrate together and integrate a better way for them to manage blowing through fluentd more about this news.
00:24:17 [W] You will get a next year.
00:24:18 [W] So this is just a sneak peak about the work that we're doing together.
00:24:22 [W] If you are interested in opentelemetry, I you care about looks pay attention to fluentd.
00:24:30 [W] Well with Master, we just finished this introduction presentation, and now we have a lot of time for Q&A. So thanks for coming.
00:24:48 [W] Hello, can you hear me?
00:24:59 [W] Okay, we try to answer most of the questions in doing the chat and I think that what question that is.
00:25:11 [W] That is repeating is about what?
00:25:16 [W] What's the difference between fluent the and fluent bit?
00:25:22 [W] Fluently mostly I would say that this is the parent project that was created for look processing data processing and all the things and then after a years we started to think about the create a new project.
00:25:37 [W] That was a we are different Target on that time for number Linux, but that evolved to the clarinet of space. But nowadays you can see that many features of fluent bit and fluent.
00:25:47 [W] They are quite do the same.
00:25:49 [W] So as his base with basing down swear, sometimes slide for fluently. We have like a thousand plug-ins for fluent bed. We have 70 if I'm not wrong in the it depends also
00:26:04 [W] Workloads you want to do right?
00:25:52 [W] There are many use cases where fluently can be used for aggregation because maybe you're connected that you need for you back and is not available in fluent bit and you want to aggregate all the information first and fluently
00:26:08 [W] Tyrael ability so that works first if Assad good use case so you can integrate fluent bit as a forward there in your notes and put Louis and every editor but there are also many cases where the user said.
00:26:10 [W] You know, what I we just want to ship back their ability to make back in storage.
00:26:17 [W] now there are a couple of times where for example, you said am already dating or Matt more information on elastic search, but
00:26:26 [W] sometimes less is search cannot receive data or the ingestion form a hundred of notes sometime. The scalability can be a problem or maybe you need to have more and more custom setup. So one thing you can do is to have a fluent in
00:26:41 [W] Just try to control the buffer flow for the did ingestion to elastic search.
00:26:46 [W] So I would say you can use both you can use one of them but both projects actually are under the same license under the cncf as well graded project. So I would say mostly the Pains of your own use case.
00:27:05 [W] Okay, we have one question from rocket with said confluent deep collect multiple log files from within pods that the right to standard old.
00:27:15 [W] How does it work? If you put restart that start reading the file from the beginning?
00:27:24 [W] Fluently, I'm fluent bit always a read low files by default from the end of the file.
00:27:32 [W] And if you're running in production, we have a configuration to set what is called a boss fight for fluency or a database file flowing bit where we keep track of the last offset that was processed by fluently or fluid bed.
00:27:47 [W] So even if you were study agent,
00:27:50 [W] you're going to start a consumer the data from the last position. So yes, you can restart it and continue working without any major problem.
00:27:59 [W] We didn't put that the right to standard old and how does it work if the pot restart that start reading the fight from the beginning?
00:28:05 [W] Fluently, I'm fluent bit always read low files by default from the end of the file.
00:28:14 [W] And if you're running in production, we have a configuration to set what is called a boss fight for fluency or a database file flowing bit where we keep track of the last offset that was processed by fluently or fluent bit.
00:28:28 [W] So even if you restart the agent
00:28:31 [W] You're going to start a consumer the data from the last position. So yes, you can restart it and continue working without any major problem.
00:28:43 [W] Okay. Another question is say we are only using fluent bait and using kubernative horse logging and forwarding to data is that not recommended?
00:28:57 [W] I would say that I cannot talk about what is and what is not recommended. We can talk mostly about a we had knative Integrations with datadog. Actually, the fluentd team works. We have been working together with datadog to break up the connectors.
00:29:15 [W] So I would say it's a matter of use case.
00:29:18 [W] Yeah, you can use float them fluent pay to send your data to the other without any problem and that is like a certified connector.
00:29:35 [W] Another question. I hear Masa.
00:29:39 [W] I'm not sure if you want to live with someone who flew the question I saw someone about haproxy.
00:29:48 [W] I'm not.
00:30:05 [W] Okay, so we have another questions a coming in from Andhra Gupta asking when are fluent diem fluent bit office hours.
00:30:18 [W] That though is that not recommended.
00:30:25 [W] I would say that I cannot talk about what is and what is not recommended. We can talk mostly about a we had knative Integrations with datadog. Actually, the fluentd team works.
00:30:37 [W] We have been working together with datadog to bring up the connectors.
00:30:43 [W] So I would say it's a matter of use case.
00:30:46 [W] Yeah, you can you slow down through and pay to send your data to datadog without any problem.
00:30:51 [W] And that is like a certified connector.
00:31:03 [W] Another question. I hear Masa. I'm not sure if you want to address some of the fluid the question. I saw someone about haproxy.
00:31:33 [W] Okay, so we have another questions a coming out from under a Gupta asking when are fluent DM fluid bit office hours.
00:31:46 [W] Well, we have an office hours a setup for this week and is I think that it is not role is on the schedule.
00:31:52 [W] So if you want to talk to us about any specific issue, you need some kind of global assistance with your architecture.
00:32:01 [W] We are pretty happy to help you with that or if you have any, you know Barry into questions, we're pretty happy to help you too with this. We will be here around the whole week.
00:32:18 [W] Tim crooked is asking is there any connector for Splunk or Splunk only likes their own Universal agent?
00:32:29 [W] or I have heard that Splunk a lot of their tools, but I can just speak for fluently perspective and
00:32:38 [W] Yeah, we have affluent equal original connect up to send data to Splunk.
00:32:43 [W] We have the same connector version for fluently and we have many users using them to ingest data into Splunk and why don't they I would say major differences white people would use fluently of linbit connector
00:33:04 [W] Team crooked is asking is there any connector for Splunk course plug only likes their own Universal agent?
00:33:15 [W] or I have heard that Splunk to love their tools, but I can just speak for fluently perspective and
00:33:24 [W] Yeah, we have affluent equal original connect up to send data to Splunk.
00:33:29 [W] We have the same connector version for fluently and we have many users using them to ingest data into Splunk and why don't they I would say major differences white people would use fluently of linbit
00:33:44 [W] Reversal agent sent all the data by default and at the end of the day you ended up paying the amount of money per the amount of data that we ingest into the platform.
00:33:55 [W] So if you are just going to just for example going to process in Splunk, I don't know 20% of your data.
00:34:05 [W] Maybe you just want to send a fraction of your data to Splunk and the other two are different storage back-end like 630.
00:34:13 [W] Or elastic search so a people sometimes use fluid the influent bit with Splunk because influencing and fluentd you can filter the data out and you can choose or wrote a fraction of the data to a different
00:34:28 [W] So you can put your bills.
00:34:32 [W] Okay, another question to collect log files from within a pod will I need to a cycle moral or traditional demon set for me and it's a is based on specific use case right now.
00:34:48 [W] Most of our user from what we hear they use the Demons of model, but sometimes they want to have a custom parts in your custom data pipe them with filters as a sidecar containerd.
00:34:56 [W] So there's no like a magic room. The default is mostly demon set. But if you need something very customized for your own app. Yes, you can use your cycle.
00:35:09 [W] When you did this this question is going to come up. It's like parsec kubernative Zocor look scrap by fluent bit.
00:35:17 [W] Parentheses Java stack Trace multi-line being sold or should I use glue in D right now?
00:35:24 [W] I think that if you're using you're dealing with Java stack traces use fluently because we will be has the proper stacked races filter. It has a in kind of reassembly everything properly influent bit. We don't have that feature yet.
00:35:39 [W] please your fluently.
00:35:44 [W] Okay, if a cloud instance is getting terminated doesn't fluent bit flush the buffer.
00:35:52 [W] Yes fluentd Improvement has a grace period when they flush the buffer before to stop.
00:35:59 [W] Fluently allows to flush all the data that he has in the buffers but fluent bit only Flash the buffers when we have in the window of time.
00:36:09 [W] The current difference and I think that they have a graceful shutdown there still room for improvements.
00:36:22 [W] Okay, I think that we answer most of the questions.
00:36:31 [W] Okay, so thanks so much for joining this session and with maximum pretty happy that you stay with us send your questions. So we encourage you to stay on this like China for of stability. We will be there.
00:36:46 [W] Tomorrow about kubernative son Logan there's another floor bit session with possibly SQL at the end of this week. So please if you want to learn more just a tone and feel free to send us any message on Twitter our Twitter at fluidity and
00:36:47 [W] Feel free to send us any message on Twitter our Twitter at fluidy and absolutely bit.
00:36:53 [W] So yeah, just keep around will be really happy to help you.
00:36:56 [W] Thanks so much for joining and enjoy this week.
