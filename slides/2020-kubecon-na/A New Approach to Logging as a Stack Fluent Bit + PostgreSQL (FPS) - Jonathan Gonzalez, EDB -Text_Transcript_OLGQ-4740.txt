A New Approach to Logging as a Stack: Fluent Bit + PostgreSQL (FPS): OLGQ-4740 - events@cncf.io - Friday, November 20, 2020 5:56 PM - 25 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Hello everyone.
00:00:01 [W] LaMontagne knative upholstery school or preparing for fluid in the last thing, you know for my life. I mean working with data processing lock processing for reports starts analysis and everything in facade reporting even so this time I'm going to talk you about it.
00:00:16 [W] Too plain for flowmill, but what does it mean?
00:00:20 [W] This means that I want to explain you a lot of stuff related to how to process the logs on the floor bit size and push the dogs inside pull the squirrel. So let's start the talk.
00:00:32 [W] One of the motivation to pay to start this plug-in and a year and a half ago.
00:00:37 [W] It was to pay with the post SQL type Chase on B, which is apparently representation of JavaScript object notation.
00:00:44 [W] We needed to create basically to process years of flux and find one line between millions of files.
00:00:52 [W] Wasn't that easy at that time?
00:00:55 [W] time. We need to generate Jesus report infosec report for I don't know Administration Management stuff like that.
00:01:03 [W] And maybe great some start from starting from this looks like I don't know in summer.
00:01:09 [W] We have a lot of pieces on this side or this Summit user started login more stuff like that. People can ask questions.
00:01:19 [W] In the beginning the initial idea was to follow this simple process through linbit collect data collect logs from different sources using different input plugins and send them directly it into postgresql
00:01:34 [W] Abel and from there you will be installing locks, but with time and talking with my colleagues, we finally decided that a better idea will be keep fluent bit sending logs into parsec square, but first processed and using
00:01:46 [W] Language this would be allow us to separate files and between different tables or maybe processing something or even just create some rules.
00:01:45 [W] We have the logs inside our parsec UL or in our case inside our psql flowmill will send the data as the data logs as Json objects, which means that they will have a big
00:02:01 [W] Our parsec UL or in our case inside our pl/sql from it will send the data as the data logs as Json objects, which means that they will have a big Json plus some data in
00:02:26 [W] Some data in our case, it will contain times time Sam and attack plus the Json object with everything in the material will start the raw data into one main table meaning it's the table option in the
00:02:42 [W] and
00:02:44 [W] we decided to process with using pl/sql to press the split the data too many tables one table or just split the data for the table or using store them in the same table.
00:02:56 [W] That's not an issue. So we can use any object inside any feel inside the Json object to this. I went to store the data where to store it split it by using some
00:03:11 [W] Handler or anything like that, so we will take the decision based on the Json object.
00:03:17 [W] But what is Jason b or Json on pause SQL?
00:03:22 [W] Well, Jason is just JavaScript object notation in K. And in our post SQL. There's a SQL technical report that you can check out on the slide right here the employee which is the implementation
00:03:37 [W] In in our place SQL there's a SQL technical report that you can check out on the slide right here.
00:03:39 [W] template, which is their implementation of Json on Pasquale.
00:03:47 [W] The idea is you can have Json or Json be but we use Json be because it's what indexing which means that it's easy to create the data and keep it in.
00:03:58 [W] That's it because we know that index create faster queries, right and it's easy to create.
00:04:05 [W] is just you can select data and I feel inside in this case date from the table and you will get the data.
00:04:14 [W] But one of the biggest reason is to use Json is that it is really really easy to export and using other apps. In this case. We can export Jason to any option or application.
00:04:27 [W] want to process data or to process lot from time to time or anything.
00:04:32 [W] how we can configure This Plane the main configuration you will need obviously the host because you will may not have possibly still running on localhost and the part people will usually don't change the poor, but maybe you will need to change it
00:04:47 [W] Password you can put it on the configuration, but with strongly recommend you Speedy pass file because it's the best option and secure for the in this case the database and a table the table will be created if it's not exist on the plane when you start up and
00:05:02 [W] Up.
00:04:52 [W] you don't need to create it and we support Congress to be using cockroach DB SQL through this is our Cooperative is support postgresql protocol, but some queries don't they don't support some functions and some queries make
00:05:07 [W] It created some special option for it.
00:05:07 [W] There's a full list of option for the plug-in some interest in some are not you can test them and please report any back on it.
00:05:16 [W] So how to query the data the data as we saved it for is stories on Jason with to feel start time and data containing the Json object.
00:05:29 [W] here is an example of data of one record from fluent bit.
00:05:35 [W] It using the tag CPU that 0 which is just using the input plug in from fluent bit CPU and limited to one you will see the data over there.
00:05:48 [W] It's nice easy and simple.
00:05:51 [W] But in this case with Apache logs, you can see something else more interesting in this case.
00:05:57 [W] We use the tag to separated the logs Toc Apache and you will see that we contain the code date everything that comes to using the Apache to parcel from through and beat. This is what using the tape plug-in into
00:06:12 [W] In this case, we use the tag to separated the logs.
00:06:13 [W] talk about you and you will see that we contain the code date everything that comes to using the Apache to parser from flu and beat this is what using the tail plug-in into some processing Pate locks,
00:06:32 [W] But it looks but dere's of blocks. We needed to analyze three years of Apache logs, which is a really really big tax because we have a around one terabyte of data and we need to process it in just two weeks.
00:06:45 [W] So for this we decided to use the tail plug-in which needed some updated and with added some option into the documentation to process the parsec UL the Apache logs into PSI squared.
00:06:59 [W] We see the pl/sql language the processing speed data into different.
00:07:02 [W] Tables which because otherwise we will have billions of rows insights just one table.
00:07:08 [W] But in our case we use partition tables per month with allow us to create proper indexes and query just once a month and this query for month took less than one second, which is really really amazing because you know, the
00:07:23 [W] More than one second because we have a lot of data.
00:07:26 [W] So let's deploy inside kubernative our fluent bit plus parsec to allow to plane will provide some URL on GitHub, which is open source, and you will be able to use customized to the employee inside. So let's have some fun.
00:07:40 [W] And the following configuration will be able to see the simple fluid configuration with the include statement to at the con files into the fluentd configuration.
00:07:53 [W] And in the file past rescuer customization is just a comfort material that will use the merge Behavior to add outputs postgresql come file into the flu and bit config map.
00:08:09 [W] And in the output pulses bol.com file, you will be able to see the host which is out of pure Nats deployment using a dummy password and the user flow and bit.
00:08:22 [W] For the database fluid and tablespoon beta will match everything to the output line.
00:08:30 [W] Okay, that was easy. But let's use some pl/sql language because we want all the data in a separate table because obviously we get locked from many places.
00:08:43 [W] Off file you will be able to see the cost which is out of pure Nats deployment using a dummy password and the user flow and bit.
00:08:44 [W] For the database fluid and devops will be double match everything to the output line.
00:08:52 [W] Okay, that was easy. But let's use some pl/sql language because we want all the data in a separate table because obviously we get locks from many places.
00:09:05 [W] So let's partition the table because maybe in the future we will need Partition by month year weeks or days and use some condition to fulfill the empty fields.
00:09:18 [W] So, let's see how this world.
00:09:24 [W] In our example code, we will first create our table with all the data. We want to store with a partition option that will be the useful in case we weren't able to partition our table later.
00:09:36 [W] It's important that our table it sounded by the fluid user side is the one inserting the data after that.
00:09:44 [W] We created before partition would be the one by default then we can create more partition after if you want.
00:09:53 [W] We now create our function that will do the final insert into the table.
00:09:59 [W] It's important that if the Json object doesn't come with a kubernative object we can discard that row and return the full Road since we want to start the data, even if it's not a Cuban it up toots.
00:10:12 [W] Then we go and start with the insert into our table.
00:10:17 [W] It's important to notice that we want a timestamp type and make sure it will be like that for that. We use the default column that comes with applying.
00:10:27 [W] Then we can insert the data. We want in our case it will contain.
00:10:33 [W] containerd image containerd name namespace and host
00:10:38 [W] we will add the labels and annotation just to prove that we can add Json data to
00:10:43 [W] in our
00:10:45 [W] Case it will contain containerd image containerd name namespace and host.
00:10:52 [W] we will add the labels and annotation just to prove that we can add Json data to
00:10:59 [W] we return a null value because we don't want to store the data in the default table, but the one we decided in in our trigger.
00:11:09 [W] Let's drop the trigger if exists and create our trigger for our default table.
00:11:14 [W] Distribute will be executed for each row inserted in the table.
00:11:44 [W] So for the record, we will let the functions the pl SQL function on the slide so you can take take them and use them later as an example, but you can see here that we can query the data using select distinct based on the containerd field in the kubernative
00:11:59 [W] We have file records, but there's one with an empty field.
00:12:02 [W] Maybe we need to look into this later and see that some objects will not come with the container name or something like that.
00:12:09 [W] Maybe that's a bad, but you can take a look and that's will be your task.
00:12:18 [W] But appeal SQL function can be more complicated because sometimes we may want to send the data into more than one just table.
00:12:26 [W] Okay?
00:12:26 [W] So let's see a fortune that can expedite that dependent on the tag a table the input doesn't matter tag send it to a default table. So we may be ending having three tables.
00:12:39 [W] So the following function will show you how to split between
00:12:45 [W] That's just with our budget and tax or the data comes with kubernative inside.
00:12:50 [W] You can use this function as example for later.
00:12:54 [W] go and have some fun because there's a lot of options you can use here to split your data and wear it later.
00:13:05 [W] We will see some this is a pre-recorded video and you will see some examples like this one carrying all the fields on kubernative lock table, which is not ideal, but we can select distinct containerd cymet from the kubernative
00:13:20 [W] The select the container Amite and count them.
00:13:21 [W] Obviously we need to group group by a fill this container image and see that we have a lot of container, but maybe we want to know what if we split the containers accountant by host.
00:13:34 [W] That's easy. Just add host Andrew pie host.
00:13:37 [W] Then we have all the containers split them using host. So yeah, this is our son icing.
00:13:46 [W] This is cool. But let's see something else.
00:14:06 [W] This case we are going to select all the fields from the kubernative slot where the continuity is fluent bit.
00:14:13 [W] Okay, that's a lot of data.
00:14:15 [W] Maybe that's not so useful, you know well, but you can see it's SQL. So let's do something different but about this thing host and come all the
00:14:30 [W] This case we are going to select all the fields from the kubernative lot where the Continuum which is fluent bit.
00:14:32 [W] Okay, that's a lot of data.
00:14:34 [W] Maybe that's not so useful, you know well, but you can see it's SQL. So let's do something different but about this thing host and count all the
00:15:07 [W] running on different hosts
00:15:13 [W] Okay, we have some good numbers here.
00:15:16 [W] I will ask why you have 13 just on Master 0-2, but that's up.
00:15:28 [W] In our work in the following case, we will see some kubernative low and speed all the things that is running on Master zero one with the containerd image fluent bit.
00:15:43 [W] okay, that's a lot of information again, but maybe we need to
00:15:50 [W] split it or work later.
00:15:51 [W] So let's see something else. What about the Apache locks?
00:15:55 [W] As you can see the example we used just for feel cause button code plus the time stamp, which is a lot of data. Maybe not so much data, but it will contain different fields.
00:16:06 [W] So as you can see there's a lot of data but not so useful. Let's Group by the pup and count them.
00:16:25 [W] Okay, this is a lot of data here.
00:16:27 [W] Hmm.
00:16:28 [W] no too much data.
00:16:31 [W] It doesn't say anything.
00:16:31 [W] Let's do something different.
00:16:34 [W] I didn't the host. But yeah, let's work with the host.
00:16:41 [W] Okay, what now? We have the host but still not So Much Information useful.
00:16:51 [W] So let's use something to split the data, but about part like, you know, WordPress.
00:17:07 [W] There's a lot of data with WordPress.
00:17:13 [W] But this is something that will happen. But we want everything that they call these 200 now that's a lot of 200 as you can see.
00:17:22 [W] This is a WordPress running there.
00:17:28 [W] So, let's see everything that it's not found.
00:17:31 [W] Okay.
00:17:32 [W] This is more nice.
00:17:34 [W] But you know.
00:17:37 [W] It's Apache logs.
00:17:38 [W] You can you will have a lot of data here. So let's see some other examples with different queries.
00:17:53 [W] But let's see now what is in the default?
00:17:57 [W] Table through and bit there's a lot of Records.
00:18:00 [W] Okay.
00:18:01 [W] that there
00:17:49 [W] And as you can see, we have a batch elotl maybe didn't feed on the filter and the CPU.
00:17:56 [W] So, let's see all the data that is has the tag CPU.
00:18:11 [W] OK you will see that there's a lot of data that didn't fit in our functions. So it was stored on the default table.
00:18:19 [W] That was the sense of having a default table because you may not want to lose any data at any moment of
00:18:28 [W] Your process so let's see some data for example data for the CPU as you can see.
00:18:33 [W] It's just like everything on fluent bit.
00:18:43 [W] As you'll see we can do a lot of stuff with this plug-in and master data is postgresql, but there's some ideas you may want to experiment right now like break the data using ravana, which is a
00:18:58 [W] To create graphs split the data per weeks not just month, or maybe per year. If you have that amount of time, maybe a day would be useful to start testing stuff. Great some script to
00:18:56 [W] Automatics report per month or per year that's also some idea you can get from here.
00:18:46 [W] Maybe there's something else you can add in the ideas.
00:18:51 [W] So please drop me a message right here after this top you are now able to use fluid plus parsec skewer in Scoville Edie's. We are now going to add SSL connection support for parsec ul and schema support.
00:19:06 [W] Be able to use SSL to connect the posture Squad.
00:19:07 [W] In the meantime. We have to get some feedback from the users you and nginx Dia to have to the plane.
00:19:14 [W] So please contact me on Twitter and let's go with the questions.
00:19:30 [W] Hello, everyone.
00:19:33 [W] Thanks you for watching.
00:19:34 [W] Okay.
00:19:35 [W] I have a couple question.
00:19:37 [W] I'd like to answer lie.
00:19:38 [W] First one is why are you using postgres?
00:19:42 [W] There are various tours to start this kind of data, right?
00:19:45 [W] Yeah.
00:19:46 [W] Yeah. Well actually work on a post is company to start so we supposed to explore a most everything that we can and we will able to store data like this for coming from looks like Apache or even posted.
00:20:01 [W] self easily when we have five years of data so posters turns out to have the partition tables, which is something really useful and this allows
00:20:17 [W] A lot of data in less time using less space.
00:20:13 [W] That's why we started this plane and the media because it is fast and easy to use and teach to someone else that is not in the cloud native War to use SQL language.
00:20:29 [W] So yeah, that's the main idea there.
00:20:19 [W] That's why we just posted for this another question.
00:20:24 [W] How about this realization?
00:20:26 [W] Why would you see what we'll use graph on a I'm taking the lfs 242 fluently course and one of the database use it was mongodb and still have the same question science.
00:20:38 [W] I've made a laugh. I also have a okay knowledge. Okay, this is yes, you saw one of the when
00:20:47 [W] This tunnel was recorded.
00:20:49 [W] The idea was using the funnel cake.
00:20:51 [W] You can use profanity pendant the data you have and you can create with the new version of Ralph Hanan really beautiful graphs.
00:20:59 [W] So Jess, the fauna is the main tool that you can use and also there's some other tools that you can connect to post SQL for business intelligence of the sky and for a security approach to social security measures that you
00:21:14 [W] Data or analysis. So yeah, there's a lot of things that you can do or choose to use with posters. So start with the fauna and inspect more. If you can please let us know another question.
00:21:26 [W] Did you use on the Json be data?
00:21:19 [W] Okay, this is a really good question because by default we use indexes on
00:21:29 [W] Jason be columns in parsec ql science version 13 or 12.
00:21:35 [W] I think I don't quite remember now we can use Petrie. If I don't quite remember that actually there's some thought relate it to Jason B type from my college buddies, which I'm going to point on the
00:21:50 [W] The cute kind of survivability in a few minutes after that also. You can take a look on how the Jason be data type behaves in parsec unit, which is actually really cool.
00:21:59 [W] How do you provide live Locke's view like Ivana those for elastic search.
00:22:05 [W] Yeah, you can do this in many ways with police ql there's actually using refined and you can do that and you can start.
00:22:16 [W] With stuff like using your own power Pi or business intelligence or any application you have on the web. Even your web application for your site.
00:22:30 [W] You can do that. But in this case, obviously the most recommended ways to use profanity is our Cloud native graphic.
00:22:39 [W] But for this for years old just use profanity.
00:22:45 [W] any more questions
00:23:29 [W] Okay, so if you have more questions, okay - Anderson provide the actual log message view like key benardos. Okay.
00:23:40 [W] Yes.
00:23:40 [W] That's that's true that there's other tools that you can we can use for that and the idea here is that you have the log pre-processing using postgresql. So
00:23:54 [W] You don't digest that.
00:23:56 [W] You don't need the full message, but you can process that message first.
00:23:59 [W] and so all the data but yes, laughs Anna doesn't provide a full log and maybe we can work out that and let's talk instance in slack about this Richard. So let me out then we can talk about this because yes, it's really important how to provide
00:24:14 [W] In actually see that looks like those you can do it with Gabbana.
00:24:04 [W] Johan is have you considered doing the splitting influent beat instead of the SPL?
00:24:11 [W] Yes, we thought about doing that and actually flowmill tosod really really good job on that but the idea started that having processing and parsec a lot of locks. The history was five years so
00:24:26 [W] You can do that really fast with throwing bit and let that they all work for processing and speed in the in different tables and do it again in a indexes on the posterior side. So
00:24:41 [W] Beat actually, it does Parts because it creates the Json.
00:24:45 [W] That is great.
00:24:48 [W] Okay, so you can pass with Brewing bit fast into a Json and assist, uh, just decide how to split the data on your own with your own code.
00:25:00 [W] Yeah, maybe it doesn't sounds like that that good now, but if you have to process more than one terabyte of logs and millions of five it makes sense to
00:25:11 [W] To use fluent with fast to just create a Json file and put it in posters and do the rest of the world the work there.
00:25:20 [W] so you have more questions, please reach me out in slack and the kubeflow no possibility Channel and we can talk more about this and with more examples that there's a lot of example we can tell when work on Okay,
00:25:35 [W] So thank you very much for watching. It was a great conference and talk to my
