Analyzing Operational Data at Scale Using ML at Intuit: TNTX-4574 - events@cncf.io - Friday, November 20, 2020 5:57 PM - 30 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Good afternoon, everyone.
00:00:01 [W] My name is Ahmad.
00:00:02 [W] Well, I'm here with my colleague widget Morris. And today we are going to talk about how we are using operational data at Intuit to provide meaningful insights and actionable insights.
00:00:13 [W] This is the overview of talk. We are going to cover today. We will go to start with the problem statement how we are solving it using operational data like talk about the applications that run on our of the operational data link get into a
00:00:29 [W] And then back about what we are doing next.
00:00:33 [W] First who we are me and Bridget both work for modern science came within into it. It's our platform team into it. As you folks might know has been around this film since 1983.
00:00:46 [W] We have five thousand-plus developers can 21 locations. And so more than 50 million Crystal here is kubernative at into it.
00:00:57 [W] around 100 Services currently running in Prague on 200.
00:01:02 [W] Blusters and then people as nodes.
00:01:07 [W] We are doing a lot of Open Source contributions including Argo which is a cncf information project and Kiko and Aguilar.
00:01:14 [W] So object of this initiative was how we can derive real-time actionable insights on the operational data you
00:01:25 [W] So when we started with this, there were few problems. We encounter we were generating lot of operational data, but they were in silos.
00:01:34 [W] There was no standard way to correlate this data and provide insight.
00:01:39 [W] Each team used to use their own dashboards to figure out insights in their own Silo and there was no easy way to provide a scalable mlperf form.
00:01:53 [W] I need white begin could be done right now as more and more of our services moves to kubernative.
00:01:59 [W] Is it increase the complexity due to the dynamic Cloud native platform as well. As you are deploying much more that increase the risk at the same time.
00:02:13 [W] would be the devops transformation which requires specialized data driven to learn.
00:02:20 [W] So how do we solve this?
00:02:23 [W] We created a platform called operational data wave operational data link is nothing a warehouse of a clean documented as Kuma ties operational data, which we collect and process in real pain.
00:02:36 [W] you collect this data a different life cycle of an application that includes development buildpacks production security except
00:02:47 [W] and then provide real-time analytics using mlr. There's another principle we wanted to follow is it democratize this operational data? So it's available through self-service for anybody at Intuit to use it.
00:03:04 [W] So our platform is divided into four parts one is collection. Second is processing third is real-time member and analytics and the fourth is storage and retrieval.
00:03:16 [W] Let's get little bit more detail into each of this in collections.
00:03:21 [W] We use graph paper or a real pain in the ocean.
00:03:24 [W] You guys are supposed badge using credible positive things like structured love and yes data governance is in Barrie and moderated by the hospital for processing. We do real-time processing using Apache pain.
00:03:40 [W] We have cataloging using Apaches at last we want to make sure everything is catalog and discoverable for folks who want to use this data.
00:03:49 [W] We also provide enrichment using golden egg PP. We use asset ID in our case on analytic side. We created a standardized mlperf form that highlights the anomalous behavior
00:04:05 [W] You need spray Valdez that enables us to provide a guided debug view option.
00:04:12 [W] As far as visualization is concerned. We created a standardized pattern for both visualization and gradual.
00:04:18 [W] We also offer an interactive exploration using joy and all this data is stored in a long time term store s t and E LK for matched pair.
00:04:30 [W] Let's go over high level of odl architecture on left hand side.
00:04:36 [W] we have set up of producers with includes our abilities.
00:04:43 [W] Which includes buildpacks form API Gateway we get security data elotl data.
00:04:48 [W] All this data is collected in real time through Kafka.
00:04:54 [W] We ensure that everything is bad luck.
00:04:56 [W] So so that the database will once the data is collected we process it using Apache Bean for different use cases. All this data is stored in different
00:05:11 [W] As well as data structure who sold these use cases.
00:05:15 [W] We have a query engine and support different bi tools like dialog click view so that people can create reports out of it. And on the right-hand side, you can see different consumers and use cases. We support including insecurity
00:05:30 [W] You know through blue cost optimization Etc.
00:05:34 [W] These are some of the applications that are currently using our operational data click platform and providing actionable Insight first.
00:05:44 [W] We have a security use case.
00:05:46 [W] We collect the data for related disability including lineage, but piece of software is running right from the time. We build the container until the end of the life cycle when it's running in production.
00:05:59 [W] We can figure out what CD effects which biggest piece of code not in just in building but at runtime and do work regime for that next is the process of reporting and Analysis. This helps us with different
00:06:14 [W] Rollers, which we have written it helps us attribute gas for any resources CPU memory to a particular service and an account owner not just for reporting but also optimizing the cause which into it's correct another major.
00:06:30 [W] UTS we are solving is development velocity. We get data from will get deployment platforms to figure out.
00:06:41 [W] what is our relation velocity and then how can provide meaningful insights into them how we can increase the development velocity at all and last but not the least is our observability application called fuzzy which we will go a little bit more
00:06:56 [W] The next segment the main objective of this fuzzy is can be reduced mpb. I am PPD for all services that are running at the input.
00:07:06 [W] Now over to widget who will go over our fuzzy observability application and show us a demo.
00:07:17 [W] Thank you.
00:07:17 [W] I'm with now. I'm going to talk about for seeing our also several with the application built on top of Oda.
00:07:25 [W] Why did we build for see we had we found a couple of issues in the current way of doing that meantime to detect is too long the most of the cases what we found out is would love to detect in a standardized way because either
00:07:40 [W] You wanted to detect when a customer is impactor either an internal external there should be a standard almost standard way to do that.
00:07:46 [W] As soon as we get into an incident the first thing the incident responder or the service owner looks for is how can we ascertain the customer back who are the customers who are impacted?
00:07:57 [W] What is the level of impact and which are the endpoints? They are being affected the percentages the numbers and so forth.
00:08:04 [W] Once we know that we would love to solve the problem that is isolate the source and the root cause Source could be the source service while the cause could be the cause element the root cause is little tricky.
00:08:18 [W] So for those some cases where we cannot find the root cause we would need the domain exposed to come in and debug or try as the problem.
00:08:28 [W] When the domain experts come in what they find out is there is a large latency in data retrieval.
00:08:35 [W] This is due to the exponential growth in the data as an organic grower.
00:08:42 [W] most systems are being added. So we wanted to have a real to me real time interactive system where they could explore the data and tries the problem.
00:08:52 [W] So this is why we built for see what's the start prophecy just for ci/cd three main objectives one is make abuse what services are affected.
00:09:03 [W] Second is what is the cost of service and third the course element?
00:09:08 [W] Once we have this we believe and we can show that anybody in any known expert will be able to try is the problem by nonospot what we mean is we don't need domain level export to be Triad.
00:09:22 [W] We should be able to isolate the problem very quickly. Then what is happening?
00:09:28 [W] We will talk about how am L is helping us in that and once we are able to reduce the mean time to isolate.
00:09:34 [W] We will reduce the mean time to resolve.
00:09:38 [W] How are we doing it? It will firstly being an ordeal app using the same four pillars of odl. We have collection processing mln analytics in collection.
00:09:48 [W] We collect all the data that is being exposed by the cloud provider in our case is available USB have AWS Cloud ovhcloud trial cloudevents all kind from the platform said that is we use kubernative. We get the audit logs we get the kubernative
00:10:04 [W] Objects object changes the events using data control out.
00:10:08 [W] In we have a standardized way of scraping the metrics.
00:10:13 [W] That is why I promise.
00:10:15 [W] So any application that runs on kubernative we can get the times it is Matrix out by scraping the copper kubernative Matthias, and we send that to Kafka.
00:10:24 [W] Recently, we also started getting sampled opentelemetry metric prices.
00:10:29 [W] Now that we collect not this all different data from different systems and applications. We processing windowing is the most important processing we do where we window the data to a fist or a
00:10:44 [W] Window. The reason we window is we want to make sure that customers of this data won't have trouble putting the Out of Water Events into order and so forth.
00:10:56 [W] So we put it into fixed granularity.
00:11:00 [W] Once we put it into fixed windows.
00:11:04 [W] We also make sure that there is a setting so that we can correlate all these metrics and join these metrics kubernative data will be very specific kubernative, but we have to inject a society.
00:11:17 [W] So we had to derive that that is one main job of processing tool.
00:11:21 [W] Once we have clean data, which is called a double v right into multiple different stores for different speeds of retrieval right is elastic service driven and so forth.
00:11:33 [W] Or mlperf unsupervised models that is trained to detect the anomalous measurements on these data. These member models are trained per service because each service is very unique in his behavior.
00:11:48 [W] Okay example would be for one application guide is cache misses are okay, but for another Michaud not okay, so it's tuned for surveys to be very precise.
00:12:00 [W] One analytics we use this mlc over the anomalies core as The Guiding factor for guided debugging when I said guided be bugging what we mean is let's say you can divide your application for segments
00:12:15 [W] Victor applications, you are AWS and your kubernative if you're seeing a high anomaly in your AWS side, you really don't have to debug the application side because it's clear that the problem is happening on AWS side this way
00:12:30 [W] User can narrow down to the problem very fast.
00:12:33 [W] And the guide is the guiding factor is the anomaly score which we generate our analytics platform also builds hierarchical view.
00:12:44 [W] So we could see the view from the individual level the be will scum level so we can see the impact radius.
00:12:52 [W] The data is very rich, and we would love to share this data with everybody at into it. So we expose the entire data over graphql for for consumption.
00:13:04 [W] The fuzzy architecture this architecture is very similar to the audio lecture because it's built on top of Orion.
00:13:09 [W] I highlighted using green to show what are the components, you know really used to buy fussy. We have IKS controllers that pulls in all the data 80 kg W AP Gateway in it was services that talk to each other always talk through
00:13:24 [W] Get dressed.
00:13:25 [W] We use Black Box in friends to gather data about how the interaction who are talking to each other what status course they are emitting what endpoints they do they talk to what is the latency and so forth. There is a plethora of information there.
00:13:40 [W] We use Argo CD and Argo rollouts and these generate data to help us understand.
00:13:46 [W] When did the deployment start when did if things have gone out of saying how fast is the rollout progressing and so for this helps us understand give lot of insights on the deployment.
00:13:56 [W] The portal is where we create service.
00:14:00 [W] That's a starting point for a developer.
00:14:02 [W] It has our golden entity. That is our asset ID.
00:14:05 [W] So we get data and we use that as a tidy for enriching or tell is our opentelemetry collector.
00:14:10 [W] This is very new all the data is being written to Kafka video curation clean up and store to the depot for
00:14:19 [W] Big Data analysis over a longer period of endo we every data is catalogued.
00:14:24 [W] We here on the processing side. You see SP petabyte-scale sers s PP is doing the most of the heavy lifting which is doing the windowing cleaning joining and so forth comparing crosses are very heavy share and chords written with the
00:14:39 [W] Into right to read is in different data structures and it is optimized for that.
00:14:44 [W] This main point of tumbling process is for the for zui to be able to slice and dice the data as the user required. So we'd write it in different formats so that we can users can slice and dice.
00:15:00 [W] I'll talk more about Emily in the coming slide. Then we of course have a graphql that exposed the entire data.
00:15:06 [W] We use cash different kind of cash dose based on the requirement and the mlr texture.
00:15:14 [W] So this architecture is built on kubernative because we wanted a scalable system that could run thousands of models. It uses Argo were frauds Argo City and I'll go events to make it scalable and
00:15:28 [W] and resilient
00:15:32 [W] What we do is in the dispatcher, it gets three aggregated clean data.
00:15:37 [W] It looks in the messages see which service does this message belong to and forward to the stream detector. Strimzi. Tekton has a model per service.
00:15:46 [W] So critic took things could actually happen. When s message comes in the Stream detector.
00:15:51 [W] It will see that.
00:15:52 [W] Hey, I already have a model for this in cash Ascend anime score other thing is it does not have a model. So it looks in a model store.
00:16:00 [W] Guess the latest model and assign us go.
00:16:03 [W] Some days you might not even find a model in a model store because is a newly on bottom application.
00:16:09 [W] We do create Dynamic models.
00:16:11 [W] That's the key thing.
00:16:11 [W] So it asks the on-demand training system to try to model and the old model trainer will write a model back to the dead newly trained model back to that model storage so that the service can be assigned a score
00:16:27 [W] When the late when the new message is come.
00:16:30 [W] The publish a doctor publish to multiple endpoints today.
00:16:33 [W] We read from Kafka and we published two Kafka that is the default. So we write the anomaly's gone back to Kafka topic. So others can consume it and they can set up use the data as they see fit.
00:16:47 [W] We also do gitops because we want to make sure that users can add new models without redeploying the entire thing.
00:16:55 [W] So maybe if somebody adds a new NLP based model, they just need to write it in gitops saying that hey, this is a new model for the surveys. Once it is merged a new model will be available Auto Train and be available for the
00:17:10 [W] I'll say this quarter it.
00:17:11 [W] demo
00:17:19 [W] Now let's get into details of fuzzy through a demo.
00:17:24 [W] This is The Incident Commander view of facing on the first page.
00:17:28 [W] The whole point of a see is it is it does not require any onboarding any user at indeed any service at in do it the moment they are on-boarded moment.
00:17:39 [W] They are created will get fuzzy for free.
00:17:43 [W] The front page of fuzzy what it shows is the top 10 services at Intuit that is behaving most anomalously out of thousands of services. We have the way to interpret. This is the score of zero means
00:17:58 [W] The score of 10 means it is most anomalous.
00:18:00 [W] From this user could understand that there are some anomalous services at in do it and they would like to go more to understand.
00:18:08 [W] What is the cost of service and the causal event that could have triggered this for this purpose there go to the detailed view of fuzzy.
00:18:17 [W] The most important information they look for and as an inch as a service owner is the radius impact. That's what they care about the most to understand who is being impacted because I have my application is behaving badly.
00:18:31 [W] For that we have an application dependency graph.
00:18:35 [W] Let's say I am the owner of application classic, right?
00:18:39 [W] My service has a score of 10.
00:18:41 [W] That means I am there is an issue.
00:18:43 [W] It clearly shows that who are the clients that are affected because of the anomalous behavior in my application.
00:18:49 [W] And what is the score all of them are behaving is being impacted because of it.
00:18:55 [W] We also show a service to service anomaly over I score over the edge on how how the coal used to be and how the cold piece and we highlight the score the 10 means
00:19:05 [W] It's a total impact.
00:19:07 [W] I could also find see that.
00:19:09 [W] Hey, I depend on entitlement and entitlement seems to an issue that could be the causal service that is triggering this incident.
00:19:17 [W] As an order of entitlement. What I would want to know is hey, what is the causal event?
00:19:22 [W] Assume this is the detailed view which is can be used to understand what's going on.
00:19:26 [W] Right?
00:19:26 [W] So the way to interpret this set of graphs or set of charts. Are we show as a segment as each hope so there are three major hopes we show as of today one is the Hope number one is the APA Gateway any to services at Intuit talk
00:19:41 [W] As a segment as each hope so there are three major hopes we show as of today one is the Hope number one is the APA Gateway any to services at Intuit talk to interact with each other via API Gateway, so it's clear
00:19:53 [W] Each other via a piguet to M. So it's clear that hey there are some issues you see a spike in errors and both of iot to and fire force and you could see the error rate. It has around eight percentage are right we are saying
00:20:08 [W] This data could be so we summarize this data and we show the on a heat map so that they could know what's happening. We could even actually if you see in here we could actually slice do a quick summarization by clicking over a span and C over a time of
00:20:24 [W] 10 minutes, what's the error distribution?
00:20:27 [W] Now that I see that hey there is lot of Errors.
00:20:30 [W] I would now like to know what's happening.
00:20:32 [W] Clearly.
00:20:33 [W] I can see that hey the load balancer which is serving the sit-in sitting in front of the service is also showing a spike in errors.
00:20:41 [W] user code clearly click into it and see whether it's a Target metric analog balance of whether it's being generated by the load balancer is clearly shown by the load balancer now, we would like to know what is triggering it that is where the where we look into in the kubernative
00:20:56 [W] We are we looking to in the kubernative namespace you see hey, how are they even is looking at the namespace level and we see that hey there is something at the deployment side. Something is happening. Once you click on it.
00:21:05 [W] It shows that hey somebody I didn't do it has run a restart on the deployment, which is causing the issue.
00:21:11 [W] This clearly shows a non-expert to be frank to see hey, I see an error.
00:21:16 [W] I see a deployment and what is causing the deployment?
00:21:18 [W] These are all interactive you could click on to see hey what's happening?
00:21:22 [W] Right?
00:21:22 [W] I have 26 even symporter. You could click on it and you can see what the sequence of events that happened and how we sit working since there are a lot of data.
00:21:31 [W] We also summarized it as an exclamation point so that this exclamation is all about short bubbling up the most causal reason which you might be interested in.
00:21:41 [W] Which could be triggering the incident, for example, if you click here like it shows that hey the is telling because the ports are unhealthy.
00:21:51 [W] Ideally, there should be only one exclamation point and we are which shows the real event and we are trying to improve our machine learning to do that to show the causal event rather than showing a set of exclamations.
00:22:02 [W] We also show a quick Insight onto the pot Matrix and how many ports are running so forth and what is the CPU usage for a while just to show this for the user to see what's happening they could search for her or they can see the okay.
00:22:16 [W] I am running five ports. And this is of the memory distribution is these are also color coded between cgroup.
00:22:20 [W] 200
00:22:22 [W] From an error AP get a error in the system right answer and we are able to find the root cause very fast now I will hand it over to our meat.
00:22:31 [W] for the closing
00:22:37 [W] Thank you widget as you can see in the demo.
00:22:42 [W] We have done very good progress on operational data where you can using that operational data to solve some of the use cases.
00:22:49 [W] So what's coming next?
00:22:51 [W] We want to make sure that we support customer picks.
00:22:56 [W] It's bring your own Matrix.
00:22:57 [W] expanding our self-service capabilities for open-ended be working also expanding our mlperf more on demand.
00:23:05 [W] Loose and we are planning to do open sores.
00:23:10 [W] Thank you for attending our talk.
00:23:18 [W] So, thank you everyone.
00:23:20 [W] I hope you found our infirmity you there are few questions.
00:23:24 [W] We will take those questions. The first question is how is into it Journey with kubernative and what's the biggest learning in your mind at Intuit scales?
00:23:34 [W] We see exponent initial growth of operational data. We have around 2000 plus services that are generating large parking lots and lots and operational data. So we one of the learning is we thought that we needed a standardized way to
00:23:47 [W] So thank you everyone. I hope you found our infirmity you there are few questions.
00:23:47 [W] We will take those questions. The first question is how is into it Journey with kubernative and what's the biggest learning in your mind at Intuit scales?
00:23:57 [W] We see exponent initial growth of operational data. We have around 2000 plus services that are generating large type lots and lots and operational data. So we one of the learning is we thought that we needed a standardized way to process and analyze.
00:24:11 [W] This data and hence this initiative.
00:24:17 [W] Next question I have is do you guys have a plan to open source the whole solution?
00:24:21 [W] Absolutely. We do plan to open source our this solution.
00:24:25 [W] We already have open source project Argo Eco Admiral if you have not seen them you should go and check it out. And if you like it start them this solution will also be out open source as part of that.
00:24:42 [W] Next question I have is is there a query engine used by bi tools into it created or it is clouded our Mark like the red shift is it you want to take that?
00:24:59 [W] low latency
00:25:22 [W] next question.
00:25:24 [W] I was whole Real Time real time are the fuzzy views near Real Time with the lack of minutes or even less.
00:25:39 [W] We did you undertake that.
00:25:41 [W] Used by bi tools into it created or it is clouded Ahmad like great chef is it you want to take that?
00:26:18 [W] Okay. Next question.
00:26:19 [W] I always hold real time.
00:26:20 [W] Next question I have is how real time are the fuzzy views near Real Time with the lack of minutes or even less?
00:26:35 [W] We did you want to take that?
00:27:12 [W] So I think so.
00:28:24 [W] So I will take the question so compliment.
00:28:53 [W] I'm so but we do kind of the reason why people
00:29:23 [W] the next question is how large is your team developing this platform the team that is actually working on the core of this platform is 628 engineers.
00:29:35 [W] Next question is how do you recommend getting started with something like this?
00:29:40 [W] I think the biggest part of doing something like this is collecting the appropriate data making sure that it is attributed and then figuring out what insights you can derive from those.
00:29:59 [W] I think that's about it.
00:30:01 [W] So thank you folks for attending our doc. We will be on the slack channel for answering any additional questions. How nice rest of your day.
