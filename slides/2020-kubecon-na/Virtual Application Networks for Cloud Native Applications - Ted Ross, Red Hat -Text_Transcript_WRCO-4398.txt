Virtual Application Networks for Cloud Native Applications: WRCO-4398 - events@cncf.io - Friday, November 20, 2020 4:02 PM - 33 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Hello, my name is Ted Ross. I'm a senior principal software engineer with a red hat out of Westford, Massachusetts.
00:00:44 [W] Hello, my name is Ted Ross. I'm a senior principal software engineer with red hat out of Westford, Massachusetts.
00:00:51 [W] I've spent most of my career working in embedded data networking systems and in network security and more recently. I've spent a lot of my time working on the more abstract Notions of communication like
00:01:58 [W] A lot of my time working on the more abstract Notions of communication like messaging and such.
00:02:06 [W] Today, what I'm going to talk to you about is some challenges with Cloud native interconnect.
00:02:13 [W] I'm going to introduce the notion of a virtual application Network and I'm going to do a demonstration of the Scupper project.
00:02:22 [W] So some terms before we get into the meat of everything here that I'm going to be using to make sure that you understand. First of all is a virtual application Network.
00:02:33 [W] Sometimes I will refer to this as a van.
00:02:36 [W] So this is really about multi-site hybrid Edge cloudevents connect. It's about connecting processes of services together. No matter where they are, even if they are on multiple sites or multiple clusters.
00:02:50 [W] It is a higher abstraction for prodyna.
00:02:52 [W] Just interconnect then for example, TCP IP Scupper is an open source project and it is an implementation of a virtual application no work and this is what my team at Red Hat is working on
00:03:07 [W] A little bit about internet and how its structured.
00:03:10 [W] So the internet is divided into two pieces.
00:03:15 [W] There's the public internet which is a public in addressing space everything in this space can be addressed from anywhere on the globe on the internet.
00:03:24 [W] There are private Edge networks as well and of this there are literally hundreds of millions of overlapping private Edge networks.
00:03:33 [W] They use the same addresses that just space overlapping and this is
00:03:37 [W] the reason why the internet scales as hugely as it does and the typical pattern of communication than that you see is this vertical communication where the clients in private Edge networks
00:03:52 [W] rivers that are in the public internet and that's that's a generalization but that's this is the way that the internet is basically structured so what this means is that any communication that occurs between
00:03:57 [W] and points in the edges with each other is actually an illusion because that traffic is actually going to a server than back down back down again that's the way that those applications are actually written so that's why I'm going to claim that the internet and client-server
00:04:12 [W] Hand in hand, they both grew up together and the internet is very well suited for client-server architecture.
00:04:13 [W] I will further claimed that cloud native architecture is not client-server architecture Cloud native wants to do things much more flexibly.
00:04:22 [W] We want to be able to talk the horizontal east west north south and every every such direction that might exist and we don't want to be constrained necessarily by where things are located.
00:04:35 [W] So let me then also talk a little bit about addressing as background.
00:04:41 [W] And as I'm sure you're all familiar with TCP IP and internet use a host address plus a port now. We don't generally talk about numeric host addresses.
00:04:52 [W] We actually use names and but those names are then locally mapped to addresses using a name lookup service like domain name service.
00:05:00 [W] So the name maps by DNS to host address the host address addresses a host of Port then says which process on that host in my
00:05:11 [W] wishing to communicate with
00:05:14 [W] Now by contrast a van uses a service address same name, but in this case the names are actually the address that are being used for routing across the network, the name is reference a process rather than a host
00:05:29 [W] So the name maps by DNS to host address the host address.
00:05:31 [W] I dress has a host the port then says which process on that host and my wishing to communicate with Now by contrast a van uses a service address same name, but in this case the names are actually the address
00:06:10 [W] processes rather than hosts
00:06:12 [W] and
00:06:14 [W] the van is natively multi-access rather than unicast and what this means is that it is expected that multiple services will be deployed with the same address and this is actually what we want as Cloud native developers
00:06:29 [W] Cloudbees of developers. We almost never want to create a single Singleton instance of a service. We almost always want to have multiple instances of service and we do this because we want to have high availability case one of them
00:06:44 [W] to be able to handle high high amounts of load so that we can spread the load across different instances of the service or we might be interested in locality where we want, you know a service in Asia Pacific to have a client in Asia Pacific and another service in
00:06:59 [W] no a service in asia-pacific to have a client in Asia Pacific and another service in East, you know Western Europe to handle service of the come from Western Europe and that makes for a better experience for for everybody involved so
00:07:13 [W] Multi-access comes in two flavors as the any caste which is about load balancing as I've just been talking about and there's multicast for distribution.
00:07:22 [W] So say for example the event distribution if I wish to create an event, but have that received by multiple consumers across my network, then I would use a multicast flavor of multi-access now, I should mention that you know
00:07:38 [W] Before are really about multi cluster multi-site interconnect.
00:07:41 [W] So this routing whether it be any caste load balancing or multicast distribution is network-wide.
00:07:49 [W] It's not constrained to a lan it's not constrained to a data center.
00:07:53 [W] It's not constrained in any way by the underlying Network. So if I want a multicast across the globe, that's what how my application is set up that I'm going to do be able to do that and how I look at balance across the globe.
00:08:03 [W] can do that as well.
00:08:06 [W] So a virtual application Network as the abstraction is a layer that we can insert in between our application processes and the well-known TCP IP network.
00:08:17 [W] So it utilizes a strength of the internet and doesn't ask the internet to do anything that it wasn't intended to do.
00:08:24 [W] So, it uses that you know that really strong can connectivity and communication capability but doesn't try to get it to do things like Global multicast the applications.
00:08:35 [W] Do not need to be modified.
00:08:37 [W] So if the application is written as an HTTP rest application, like I'm going to show you the Mai Mai demonstration or his grpc or uses some messaging mechanism or even if it's like using just a Homebrew TCP or UDP protocol or a
00:08:52 [W] DC. It can run across the van unmodified in the van is a natural Fade to contain our platforms that kubernative.
00:09:00 [W] He's Docker other things like Eclipse iot fog because of the way that they are very very flexibly handled local networking.
00:09:09 [W] So one of the important aspects of a virtual application network is the independence the orthogonaility so the shape of the application and the shape of the network are not related and they are independent from each other.
00:09:24 [W] Devops, we want to allocate our services to site for our business reasons.
00:09:15 [W] We don't want to do it because the network is constrained or demands that we do in a certain way.
00:09:20 [W] So for example, if we want to do test and development of a substance of right or maybe our entire system one who's at fault for small footprint for that if we were to purloin we want to add regions because we've started advertising and in a pack and we want to put up a front
00:09:35 [W] Or we can do that if we want to deploy our services on different public availability zones to protect ourselves from disappearing off the face of the Earth. If one of them fails for high availability if we want to
00:09:41 [W] Our compute capacity with the changes in demand of the offered load the demand we want to do that so that we can be efficient with the cost.
00:09:44 [W] don't want to over allocate services, but we want to have services on hand when we need them.
00:09:51 [W] We want our sensitive data to be located in our private data centers.
00:09:55 [W] We don't want to put them in public clouds. And in fact, it may be required by law for us to do this.
00:09:59 [W] So even though these data services may be needed by things outside. We don't want to locate them there.
00:10:06 [W] and then in terms of development, maybe we want to connect our laptop to advance so we can do development and debugging in context without having to actually use a container platform for that that process which is makes the development process much easier,
00:10:22 [W] Like a notional aspect of event what it might look like.
00:10:24 [W] We're I've got a number of public sites and I've got a raise of edge locations.
00:10:30 [W] maybe their storefronts maybe their factories, maybe their warehouses whatever, you know, whatever it might be that is driving my application and I've got a headquarters and they're all interconnected in a way that I designate so a couple of notes about this topology.
00:10:45 [W] Is driving my application and I've got a headquarters and they're all interconnected in a way that I designate so a couple notes about this topology.
00:10:46 [W] So the inter-site connections that are these arrows that I'm showing you how they all use Mutual TLS with a dedicated certificate authorities is very locked down from a security standpoint.
00:10:56 [W] So no socket supports are open to the public that don't use this m TL S so that you know, those connections are going across the internet, but they are protected. So the only time
00:11:06 [W] That this application would actually open a port to public is if they actually wish to do so love to provide an Ingress or a portal or a website. For example
00:11:15 [W] No vpns no ipsec.
00:11:18 [W] No sdn. Nothing but vanilla networking is used here and furthermore its developer accessible. So as a developer, I don't need admin privileges that are people cluster admin privileges.
00:11:30 [W] I don't need anything elevated.
00:11:31 [W] I don't need to make any phone calls to set this up.
00:11:33 [W] All I need is access to main spaces in these locations and I can hook them together using a van.
00:11:41 [W] The Redundant paths are recommended because they provide resilience to failure.
00:11:45 [W] I don't need a full meshmark. I do want to have redundancy in case in case there are failures somewhere in the network or of data centers go down.
00:11:53 [W] So what am I going to show you in the demonstration?
00:11:58 [W] So I'm going to show you a network of for kubernative clusters.
00:12:03 [W] I've got minikube running on my laptop.
00:12:07 [W] I've got OC fours openshift version for running in AWS.
00:12:13 [W] This is straight vanilla kubernative.
00:12:15 [W] 117 11 deployment. And I've also got a remote system in a remote data stata center that's running an old version of openshift 311.
00:12:23 [W] So and I'm going to hook them up in a network.
00:12:27 [W] So what I'm going to show you when I do this demonstration is AK native service, but I'm going to deploy on the laptop and AWS.
00:12:35 [W] Now I'm going to designate the laptop is being primary.
00:12:38 [W] This is the one I want to use by default.
00:12:40 [W] But idiom a to be less. There is a secondary it back up and it can also be used to handle load in case the the laptop service becomes backed up so it can load balancing pick up a load.
00:12:55 [W] It was cloudbees Ting.
00:12:38 [W] So I'm going to show edge to edge in direct connectivity.
00:12:42 [W] So I'm going to put my load generating client over here on remote and it's going to be able to use these services.
00:12:48 [W] One of which on the laptop is not directly accessible.
00:12:51 [W] It's got to be a to hop proposition to get there.
00:12:55 [W] And the other thing I'm going to show as I mentioned before is multi-culti cluster load balancing because I'm going to show that service being offered on the two places simultaneously.
00:13:05 [W] Painlessly, so let's get started.
00:13:08 [W] So what I'm showing you is a sort of my demonstration view on the upper left shows the topology and then I've got a command line terminal color-coded for each location so you can see what's going on there.
00:13:23 [W] Thing I do here is I first of all I have to get the Scupper executable from the Scupper project.
00:13:22 [W] But what I will then do is just issue this simple command.
00:13:34 [W] It in a WS so I'm just going to discover in it site name AWS and I'll do the same thing here called Azure the same thing here.
00:13:50 [W] Call remote the same thing here.
00:13:53 [W] I'll call it laptop.
00:13:55 [W] But one of the things I'm doing on laptop is I'm enabling a console because I want to show you this cover. Console.log Attic So, I'm turning off the console off for the purposes of this demonstration because I trust my
00:14:10 [W] beer
00:14:04 [W] called remote I'll do the same thing here.
00:14:08 [W] I'll call it laptop.
00:14:09 [W] But one of the things I'm doing on laptop is I'm enabling a console because I want to show you this cover console.log Attic So, I'm turning off the console off for the purposes of this demonstration because I trust my
00:14:39 [W] Attempting to hack it while I'm doing them straight.
00:14:41 [W] So this this now has enabled skopets injected the router into my name space Scupper router that can be used to set up this network.
00:14:51 [W] So the first thing I need to do for my to public sites is create a witch called a connection token. So I'll create a connection token for AWS now create one for Azure
00:15:07 [W] Means is this this is all the information needed to make a secure and TLS connection to this location.
00:15:12 [W] So I've made I've set up AWS and Azure to be connected to I'm going to secure copy those tokens over to my remote site because this is actually a remote connection.
00:15:26 [W] so I've transported those tokens securely over to my remote site so they can make a connection and then I will establish my first connection between Azure AWS so
00:15:41 [W] Scupper connect my AWS and configure it to make this connection. And the next thing I will do is I will configure both of my Edge systems my laptop on my remote to make redundant system Connections in
00:15:56 [W] Public locations. So let's see if I can get this to work right?
00:15:56 [W] I'll say that.
00:15:57 [W] Yes.
00:15:58 [W] Let's connect for AWS and azure.
00:16:03 [W] And then I will do the same in my remote DWS.
00:16:10 [W] measure
00:16:18 [W] and they are configured to connect and if it runs.
00:16:26 [W] All right. So while things are stabilizing here, let me talk a little bit about this picture.
00:16:32 [W] You'll see that there are arrowheads depicted in these connections. And these arrowheads are significant only in that. They as you pick the direction of the connection establishment. So AWS and Azure our public
00:16:47 [W] Dresses they are in the public side of the internet laptop and remote are in private networks.
00:16:37 [W] So there's no way to make a connection to them.
00:16:39 [W] They don't have public addresses and I'm not setting up anything fancy here like a VPN.
00:16:44 [W] So so what happens now is once those connections are established.
00:16:49 [W] The arrowheads are no longer significant because the connections are long-lived their established their secure and once they're in place, they operate bi-directionally. So this is my network now that is established.
00:17:01 [W] Published between the four different locations. So while I've been talking a give it a chance to stabilize.
00:17:09 [W] I'll see what happens here.
00:17:10 [W] I will ask my laptop to say sculptor status.
00:17:14 [W] What's the status here?
00:17:17 [W] It's going to tell me that is connected to three other sites.
00:17:21 [W] One indirectly that's kind of what we expect isn't it?
00:17:24 [W] Because it's connected to three sites, but one of them doesn't have a direct connection to it.
00:17:28 [W] Now, if I were to ask Azure the same question Scupper status and it should get back to me. Hopefully with something similar.
00:17:39 [W] Yes.
00:17:40 [W] It's connected to three other sites and none of them indirectly. So this is correct as your has a direct connection to all the other sites.
00:17:47 [W] Okay, so let's let's get the services.
00:17:54 [W] on my minikube on my laptop
00:17:57 [W] Copper controller.
00:17:48 [W] I'm going to grab his.
00:17:50 [W] External IP address.
00:17:52 [W] I'm going to go to a web browser web to this port 8080 as it's exposed. This is the Scupper console.
00:18:01 [W] And it's connecting up. If I go to the site's tab, this is going to tell me what's actually happening in my network and it looks kind of familiar.
00:18:10 [W] So this is a good sign that what we've set up manually is actually what we got.
00:18:16 [W] So here we have a network you saw the whole thing set up and it's all established in ready to go.
00:18:21 [W] So it's time to go on to the next step and before I do I'm just going to do a whole POC get Services here on my remote.
00:18:31 [W] For reference and I'm now going to and you'll see that there is the low Jen's the client loodse generating client.
00:18:39 [W] I talked about and there's a couple Services associated with discover deployment itself. So I'm now going to
00:18:48 [W] do a k apply service.
00:18:53 [W] I'm going to apply this K native service deploy here on my laptop, and I'm going to apply.
00:19:04 [W] I am of course cover which is just going to annotate that service so it can be exposed by it's cover and I do the same thing on AWS.
00:19:12 [W] all services associated with the Scupper deployment itself, so I'm now going to
00:19:05 [W] Do a k apply service.
00:19:10 [W] I'm going to apply this pink knative service deploy here on my laptop, and I'm going to apply.
00:19:21 [W] I am will force cover which is just going to annotate that service so it can be exposed by it's cover and I do the same thing on AWS.
00:19:29 [W] So here I'll say service you'll notice that the AWS being remote and in Europe runs quite a bit slower and I see apply -
00:19:55 [W] us you'll notice that the AWS being remote and in Europe runs quite a bit slower and I see apply -
00:20:08 [W] it's cover so catch up as a captures up.
00:20:15 [W] So while that's going let me now go back to remote and look at the service list again, so in this case.
00:20:24 [W] Okay, here's the new list.
00:20:26 [W] So I've got the same ones I had before but this is a new one called greeting.
00:20:29 [W] So greeting is a service for which there is no podcasting it or deployment backing it locally, but this is actually what has been done by Scott versus cup.
00:20:39 [W] I put these K native servers up on AWS and laptop.
00:20:44 [W] And then I Scupper eyes them.
00:20:47 [W] And now I have Services all four locations that can be used to access them.
00:20:50 [W] So think of this as a proxy service that can get to that load that remote place. So if I were to come over and look at Lucy get pods
00:21:05 [W] So I've got the greeting poddisruptionbudgets this comes up initially, but when it's not used K native will scale it to 0.
00:21:12 [W] Okay get pods same here and you'll see that since I did this in earlier.
00:21:18 [W] This one has already scaled down.
00:21:19 [W] So there is there's no pain running here. Even though this is the primary.
00:21:23 [W] So what I'm going to do now.
00:21:27 [W] Is I'm going to access myelogenous service and I'm going to set a load of once.
00:21:34 [W] And when I do that lastly load of 1 that means concurrency, that means one request in flight at a time so sends a request and response comes back.
00:21:45 [W] It sends another one and so it's like a synchronous process running and doing repeated requests.
00:21:51 [W] And if I look at the pods now in my primary, I see I've got a pod running for greeting. This is ZM L LH.
00:21:58 [W] So, let's see.
00:22:01 [W] I've got that running.
00:22:01 [W] That's what knocking look at the status from my load generated client and I'll see that of the last hundred items 100% were served by ZM L L8.
00:22:13 [W] L8. So that means that even though my client here on a remote. It's accessing the service deployed on laptop.
00:22:21 [W] And I f*** come back and get the pause here on AWS like presumably that one will be gone.
00:22:28 [W] And it is so because it's not needed I said I set a cost of 5 a threshold of 5, so the for it we fail over to AWS.
00:22:37 [W] So let's go have a look at the the console again, and we look at the deployments and you'll see that
00:22:45 [W] I've got a deployment in laptop that's serving a client in remote.
00:22:53 [W] That's all good.
00:22:56 [W] Let's increase load.
00:22:58 [W] time and when I do that I'm going to come over the threshold so I expect that in AWS I'm going to see a pod spin out and there it is so I will now go back to my status View and I'm going to see that I am
00:22:56 [W] twinsies MLL 8 which is on
00:22:47 [W] my laptop and the new one which is H5 F pH is what's running here.
00:22:53 [W] So I will see if there's a balance between these so of the last a hundred requests 52% were handled locally on my laptop and 48 percent were handled on AWS.
00:23:06 [W] So the balancing is not round robin.
00:23:10 [W] It's based on the actual completion rate of the services. So it balances dynamically to the services that are running fastest.
00:23:17 [W] And now if I go back to my console again, look at my deployment, I will see that they're being balance between AWS and laptop.
00:23:31 [W] So the same this the client doesn't see a difference doesn't know just it's just getting better service because it's being serviced by multiple instances.
00:23:39 [W] So if I were to come past come back here and reset my load back down to one.
00:23:44 [W] I will see what I look at my status that I'm now coming off that room that AWS and all my requests are now being handled Again by the laptop, which is my designated primary.
00:24:00 [W] So this is now running at lower load.
00:24:04 [W] I no longer need the resources of the public Cloud.
00:24:07 [W] It's just using my resources here on minikube. Now.
00:24:11 [W] I will look at the pods again AWS.
00:24:13 [W] It will still be here. But in a minute, it won't because K native will spin this back down to zero and if I look here again, you'll see that the numbers are increasing on my laptop.
00:24:25 [W] But they're not increasing on a us because it'll be us is no longer handling load because it is not needed.
00:24:35 [W] I'll take one more look over here see if pot still running but it'll take a minute to go down and be terminated.
00:24:43 [W] So what I'll mention right now is that if you go to Scupper dot IO and look in the GitHub repository associated with it.
00:24:52 [W] There are examples in there and there is an example in there.
00:24:56 [W] That is basically the the demo I'm showing you here for Kube con and a 20/20.
00:25:03 [W] It has all the mo of source code for everything that's being run in terms of my client and server and the instructions for doing all of this.
00:25:12 [W] So if you wish to replicate this experiment and demonstration yourself, everything you need is there and you can have a look at that.
00:25:20 [W] So you know that I've been talking long enough.
00:25:22 [W] we will see.
00:25:24 [W] Still me to zero and I'm no longer using those resources that are no longer needed.
00:25:17 [W] Okay with that. I am going to end my presentation. I'll provide you with some contact information here some information about the project and I will now open the open it up for.
00:25:32 [W] And discussion.
00:25:22 [W] Thank you very much.
00:25:31 [W] And hello everybody.
00:25:32 [W] I'm now live and I'm here to answer any questions or provide any additional information.
00:25:38 [W] Thank you for watching the recorded presentation on the virtual application Network since cover.
00:25:45 [W] So there's one thing I think I didn't mention that I ought to have mentioned is that the services that I used in that demonstration are severely load rate limited so they are limited to
00:25:59 [W] Ten requests per second or 10 responses per second.
00:26:02 [W] And the reason I do that is because it makes it very easy to show load balancing.
00:26:07 [W] You can obviously run this thing at a much higher rate if you wish to try yourself, so let's see what questions I have.
00:26:14 [W] I've got one here.
00:26:16 [W] How is it different from overlay networks?
00:26:19 [W] So I would actually say that this is an overlay Network.
00:26:23 [W] It might be different from others in that the addressing is at layer 7, so there's actually a
00:26:28 [W] A network.
00:26:30 [W] It's a no SPF like mechanism that is being used to create a topology and understanding where the services are. But the routing is done on the service name as I described in the presentation.
00:26:43 [W] Care to that of servicemeshcon is an interesting question. So there there's some similarity as you might see between the two but what I would say is van is actually a alternative
00:26:55 [W] Station substrate even so the thing I'm showing you is not providing you a lot of the servicemeshcon of the observability or some of the control or some of the actual control within protocols like
00:27:00 [W] but what it is giving you is seamless communication load balancing multicast across any any topology so any set of clusters, so I think that the two things are going
00:27:10 [W] At some point in some form of I think van has a lot to offer servicemeshcon thats going to look like can't predict at this time.
00:27:17 [W] See
00:27:23 [W] Okay.
00:27:23 [W] I've got a couple questions that are similar to that.
00:27:37 [W] Does it work with any cni-genie lending limitations?
00:27:41 [W] So it doesn't really care what the underlying networking is it tries to do the simplest thing.
00:27:48 [W] So it is basically all that you're seeing there is just really straight vanilla networking and in the case of the openshift Clusters, it's using routes in the case of the the kubernative Clusters where routes aren't available.
00:28:02 [W] It's a different concept of Ingress that's being used to make that connection inbound but there's really
00:28:07 [W] More than that going on because it's again.
00:28:11 [W] again. It's an overlay as bringing things up to a little bit higher layer of abstraction.
00:28:23 [W] I'm interested in connecting clusters with Legacy on-prem virtual machine Based Services.
00:28:28 [W] Is there any model where a van router can be deployed on a standalone VM?
00:28:32 [W] Of the the kubernative Clusters where routes aren't available.
00:28:32 [W] It's a different concept of Ingress that's being used to make that connection inbound but there's really nothing more than that going on because it's again.
00:28:41 [W] It's an overlay as bringing things up to a little bit higher layer of abstraction.
00:28:52 [W] I'm interested in connecting clusters with Legacy on-prem virtual machine Based Services.
00:28:57 [W] Is there any model where a van router can be deployed on a standalone VM?
00:29:01 [W] Yes.
00:29:02 [W] In fact if I'll try to put the link up actually on slack later on but there's actually a video we did where we show a cloud-based application being used to access a database running actually not even on
00:29:24 [W] I'll try to put the link up actually on slack later on but there's actually a video we did where we show a cloud-based application being used to access a database running actually not even on VM on bare metal, but it can be done the same way the VM so you
00:29:39 [W] Deploy a van router outside of kubernative on bare metal or VM and have it join the network.
00:30:04 [W] through again
00:30:16 [W] Would van work with other protocols than HTTP such as custom TCP UDP protocols.
00:30:21 [W] How is data transported on layer 7 over HTTP good question.
00:30:26 [W] So the answer your question is yes. I showed you HTTP because that one is obviously very popular. But we also support TCP at this moment at this time.
00:30:36 [W] So anything that runs over TCP that demonstration I talked to you before about database was actually jdbc and we will be
00:30:46 [W] We will be bringing UDP.
00:30:47 [W] We've actually prototype GDP but it's not in the released version of Scupper yet, but it will be coming in the near future.
00:30:53 [W] The data is actually transported over over the mqp protocol.
00:31:01 [W] It's not really a messaging product.
00:31:04 [W] But it uses the amqp protocol protocol underneath because the NPP protocol has a lot of very good properties with regard to addressing multiplexing and tracking the disposition of
00:31:15 [W] Balancing because it actually knows how many requests have actually been answered by a server so it can track things like backlog fairly straightforwardly.
00:31:06 [W] change the way this is sorting because it's
00:31:11 [W] in a multi
00:31:15 [W] Alright question for Stanley multi-tenant cluster environment.
00:31:21 [W] I would like to set up Van across the Pacific namespaces in a number of clusters with this approach be feasible at the namespace level another very good question. And the answer to that is yes, and that's in fact what I showed you so what I showed you deployed a
00:31:36 [W] Her name space and the scope of that then is within the namespace.
00:31:36 [W] You can also deploy per cluster but that requires Privileges and one of the things that we're really trying to emphasize at the outset is that you can do all these things without elevated privileges.
00:31:47 [W] Alright, we are getting low on time.
00:31:55 [W] And let me see if there's something quick I can answer. Otherwise, I'm happy to talk to you on slack for as long as is necessary.
00:32:07 [W] Okay, I'll do one last one here.
00:32:10 [W] I can see how this is working inside the van Network, which is what I showed you yes, would an Ingress hitting any cluster be able to Route traffic across the van to a running container pop possibly in another cluster.
00:32:23 [W] Yes again that I think that would be a common use case where either the Ingress could go straight to the van router and be routed someplace or the Ingress might come to a
00:32:35 [W] A front end in the front end with then via back in Port O'Call go to someplace else.
00:32:39 [W] But yes, it will allow you to Route traffic from the outside by an Ingress to anywhere basically anywhere you want to go. All right.
00:32:49 [W] Thank you very much.
00:32:51 [W] I really appreciate you attending and I really appreciate cncf for allowing me to have time to present here and I will see you all on Chef. Thank you very much.
00:33:00 [W] Ingress could go straight to the van router and be routed someplace or the Ingress might come to a
00:32:53 [W] front end in the front end with then via back and protocol go to someplace else. But yes, it will allow you to Route traffic from the outside by an Ingress to anywhere basically anywhere you want to go.
00:33:06 [W] All right.
00:33:07 [W] Thank you very much.
00:33:08 [W] I really appreciate you attending and I really appreciate cncf for allowing me to have time to present here and I will see you all on Chef.
00:33:17 [W] Thank you very much.
